{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84beb0aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Napster\\Desktop\\M2_ISI\\MLA\\CamemBERT\\MLA-CamemBERT\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "project_root = os.getenv(\"ROOT_DIR\")\n",
    "os.chdir(project_root)\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4912f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from transformers import CamembertTokenizer, CamembertForMaskedLM, logging\n",
    "from datasets import load_from_disk\n",
    "\n",
    "from src.dataset.oscar_dataset import OscarDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9b01e8b-990e-4ea4-89c4-739b0a8753be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le dataset Hugging Face sauvegardé\n",
    "mini_oscar_path = os.path.abspath(\"../../data/CamemBERT/data/mini_oscar/mini_dataset.arrow\")\n",
    "hf_dataset = load_from_disk(mini_oscar_path)\n",
    "\n",
    "tokenizer = CamembertTokenizer.from_pretrained(\"camembert-base\")\n",
    "\n",
    "dataset = OscarDataset(hf_dataset, tokenizer, max_length=512)\n",
    "dataloader = DataLoader(dataset, batch_size=8)\n",
    "\n",
    "# Boucle pour vérifier les données\n",
    "for batch in dataloader:\n",
    "    print(batch[\"input_ids\"].shape)  # Shape : (batch_size, max_length)\n",
    "    print(batch[\"attention_mask\"].shape)  # Shape : (batch_size, max_length)\n",
    "    print(batch['input_ids'][0])\n",
    "    print(batch['attention_mask'][0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1ae70f-8644-40bf-a311-5bcf99afacae",
   "metadata": {},
   "source": [
    "# Let's test CamemBERT :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "58b0819a-f5c6-4cf0-b206-aa856c9880d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "model_loaded\n",
      "dataset loaded\n",
      "datalaoder created\n"
     ]
    }
   ],
   "source": [
    "logging.set_verbosity_error()\n",
    "\n",
    "# Vérifier si un GPU est disponible\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 1. Charger le tokenizer et le modèle\n",
    "tokenizer = CamembertTokenizer.from_pretrained(\"camembert-base\")\n",
    "model = CamembertForMaskedLM.from_pretrained(\"camembert-base\")\n",
    "model = model.to(device)\n",
    "\n",
    "# 2. Charger le dataset\n",
    "data_path = os.path.abspath(\"../../data/CamemBERT/data/mini_oscar/mini_dataset.arrow\")\n",
    "hf_dataset = load_from_disk(data_path)\n",
    "\n",
    "# 3. Créer le DataLoader\n",
    "oscar_dataset = OscarDataset(hf_dataset, tokenizer, max_length=512)\n",
    "dataloader = DataLoader(oscar_dataset, batch_size=4)  #  shuffle=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17dfa1bd-b6d3-492b-8df1-4d3408cb5f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e9a09b-df42-4daa-aa98-89a9c0fde888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Tester le modèle avec un batch\n",
    "model.eval()  # Mode évaluation\n",
    "for batch in dataloader:\n",
    "    input_ids = batch[\"input_ids\"].to(device)  # (B, 512)\n",
    "    attention_mask = batch[\"attention_mask\"].to(device)  # (B, 512)\n",
    "\n",
    "    # Passer le batch dans le modèle\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "    # Afficher les résultats\n",
    "    print(\"Logits shape:\", outputs.logits.shape)  # (B, 512, vocab_size)\n",
    "    break  # Une seule itération pour tester\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0a674806-ce68-4fee-af59-3bbda04c1dc9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CamembertForMaskedLM(\n",
      "  (roberta): CamembertModel(\n",
      "    (embeddings): CamembertEmbeddings(\n",
      "      (word_embeddings): Embedding(32005, 768, padding_idx=1)\n",
      "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
      "      (token_type_embeddings): Embedding(1, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): CamembertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-11): 12 x CamembertLayer(\n",
      "          (attention): CamembertAttention(\n",
      "            (self): CamembertSdpaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): CamembertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): CamembertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): CamembertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (lm_head): CamembertLMHead(\n",
      "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "    (decoder): Linear(in_features=768, out_features=32005, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "74f93c89-5b44-4883-b848-9c8845835500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Output Shapes:\n",
      "Logits: torch.Size([2, 512, 32005])\n"
     ]
    }
   ],
   "source": [
    "# Create dummy inputs to check input-output shapes\n",
    "batch_size = 2\n",
    "seq_length = 512\n",
    "input_ids = torch.randint(0, model.config.vocab_size, (batch_size, seq_length))\n",
    "attention_mask = torch.ones_like(input_ids)\n",
    "\n",
    "# Pass dummy inputs through the model\n",
    "outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "# Print the shapes of the outputs\n",
    "print(\"\\nOutput Shapes:\")\n",
    "print(f\"Logits: {outputs.logits.shape}\")  # Logits for masked LM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1048046-21a3-4655-a8b6-8c208109a22f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# CamembertForMaskedLM Architecture with Input and Output Shapes\n",
    "\n",
    "### **Model Input:**\n",
    "- **Input Shape:** `(batch_size, sequence_length)`\n",
    "\n",
    "---\n",
    "\n",
    "### **Embeddings:**\n",
    "1. **Word Embeddings**: \n",
    "   - **Input:** `(batch_size, sequence_length)` (token IDs, vocab size = 32,005)\n",
    "   - **Output:** `(batch_size, sequence_length, 768)` (embedding dimension)\n",
    "\n",
    "2. **Position Embeddings**:\n",
    "   - **Input:** `(batch_size, sequence_length)` (positions in sequence, max = 514)\n",
    "   - **Output:** `(batch_size, sequence_length, 768)` (embedding dimension)\n",
    "\n",
    "3. **Token Type Embeddings**:\n",
    "   - **Input:** `(batch_size, sequence_length)` (token type IDs, type size = 1)\n",
    "   - **Output:** `(batch_size, sequence_length, 768)` (embedding dimension)\n",
    "\n",
    "4. **Layer Normalization**:\n",
    "   - **Input:** `(batch_size, sequence_length, 768)`\n",
    "   - **Output:** `(batch_size, sequence_length, 768)`\n",
    "\n",
    "5. **Dropout**:\n",
    "   - **Input:** `(batch_size, sequence_length, 768)`\n",
    "   - **Output:** `(batch_size, sequence_length, 768)`\n",
    "\n",
    "---\n",
    "\n",
    "### **Encoder (CamembertEncoder):**\n",
    "- Composed of **12 CamembertLayer** modules.\n",
    "\n",
    "**For each CamembertLayer:**\n",
    "\n",
    "#### **Attention (Self-Attention + Output):**\n",
    "6. **Self-Attention Query, Key, Value:**\n",
    "   - **Input:** `(batch_size, sequence_length, 768)`\n",
    "   - **Output:** `(batch_size, sequence_length, 768)` (attention heads combined)\n",
    "\n",
    "7. **Self-Attention Output (Dense + LayerNorm):**\n",
    "   - **Input:** `(batch_size, sequence_length, 768)`\n",
    "   - **Output:** `(batch_size, sequence_length, 768)`\n",
    "\n",
    "#### **Intermediate Layer:**\n",
    "8. **Dense + GELU Activation:**\n",
    "   - **Input:** `(batch_size, sequence_length, 768)`\n",
    "   - **Output:** `(batch_size, sequence_length, 3072)` (intermediate dimension)\n",
    "\n",
    "#### **Output Layer:**\n",
    "9. **Dense + LayerNorm:**\n",
    "   - **Input:** `(batch_size, sequence_length, 3072)`\n",
    "   - **Output:** `(batch_size, sequence_length, 768)` (back to embedding dimension)\n",
    "\n",
    "---\n",
    "\n",
    "### **LM Head (CamembertLMHead):**\n",
    "10. **Dense**:\n",
    "    - **Input:** `(batch_size, sequence_length, 768)`\n",
    "    - **Output:** `(batch_size, sequence_length, 768)`\n",
    "\n",
    "11. **LayerNorm**:\n",
    "    - **Input:** `(batch_size, sequence_length, 768)`\n",
    "    - **Output:** `(batch_size, sequence_length, 768)`\n",
    "\n",
    "12. **Decoder (Final Linear Layer):**\n",
    "    - **Input:** `(batch_size, sequence_length, 768)`\n",
    "    - **Output:** `(batch_size, sequence_length, 32005)` (logits for vocabulary)\n",
    "\n",
    "---\n",
    "\n",
    "### **Model Output:**\n",
    "- **Logits Shape**: `(batch_size, sequence_length, 32005)` (vocabulary scores for each token in the sequence).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4bff7a0a-6b85-48d1-b4fe-03866f470fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens prédits pour les positions masquées :\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Exemple avec un batch de deux phrases\n",
    "texts = [\n",
    "    \"La programmation en [MASK] est fascinante et facile.\",\n",
    "    \"J'aime apprendre avec [MASK].\"\n",
    "]\n",
    "\n",
    "# Tokenisation\n",
    "inputs = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "# Envoyer au modèle\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "# Récupérer les logits\n",
    "logits = outputs.logits  # Shape: (batch_size, sequence_length, vocab_size)\n",
    "\n",
    "# Trouver les indices des tokens [MASK]\n",
    "mask_token_index = (inputs[\"input_ids\"] == tokenizer.mask_token_id).nonzero(as_tuple=True)\n",
    "\n",
    "# Extraire les logits uniquement pour les positions [MASK]\n",
    "mask_logits = logits[mask_token_index]  # Shape: (num_masked_tokens, vocab_size)\n",
    "\n",
    "# Prédictions pour chaque [MASK]\n",
    "predicted_ids = mask_logits.argmax(dim=-1)  # Shape: (num_masked_tokens,)\n",
    "predicted_tokens = tokenizer.decode(predicted_ids)\n",
    "\n",
    "print(\"Tokens prédits pour les positions masquées :\")\n",
    "print(predicted_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "149b834d-967f-4f96-a4e8-1c2117a09e61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    5,    61,  4732,    22,   403,  3654,   229,   707,   374,    30,\n",
       "         25094,    14,   811,     9,     6],\n",
       "        [    5,   121,    11,   660,  1891,    42,   403,  3654,   229,   707,\n",
       "          2805,     6,     1,     1,     1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]])}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "37163ec9-f950-45ba-90d6-a7a23d660f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 22.6741,  -3.2752,   6.6612,  ...,  -6.5251,  -2.7296,   5.9366],\n",
      "         [  4.9040,  -3.4535,  15.1498,  ...,  -9.6906,  -0.9981,   7.8614],\n",
      "         [  5.1116,  -3.5781,   3.1757,  ..., -15.3700, -10.0413,   0.2270],\n",
      "         ...,\n",
      "         [  3.2980,  -7.6721,   4.0967,  ...,  -6.3892,  -8.3578,   5.3333],\n",
      "         [  5.6675,  -7.0110,   6.9816,  ...,  -5.7003,  -6.4600,   6.2704],\n",
      "         [  3.8989,  -3.5776,  27.2475,  ...,  -9.1564,  -5.2341,   5.9207]],\n",
      "\n",
      "        [[ 22.8516,  -3.5508,   8.0211,  ...,  -5.7155,  -2.0732,   6.0353],\n",
      "         [ -2.1751,  -4.6412,  15.2779,  ..., -13.9153,  -0.7081,  -2.5885],\n",
      "         [  2.0429,  -6.4475,   2.5401,  ..., -11.6387,  -7.5492,   1.1310],\n",
      "         ...,\n",
      "         [  7.7672,  -3.3566,  27.2912,  ...,  -8.2482,  -3.4188,   6.0584],\n",
      "         [  7.7672,  -3.3566,  27.2912,  ...,  -8.2482,  -3.4188,   6.0584],\n",
      "         [  7.7672,  -3.3566,  27.2912,  ...,  -8.2482,  -3.4188,   6.0584]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 15, 32005])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = outputs.logits\n",
    "print(logits)\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "68847929-bb55-41c4-92ae-d5381b790da1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([], dtype=torch.int64), tensor([], dtype=torch.int64))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_token_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c03c1bae-eafd-48df-916d-0216b2e22be0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32004"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.mask_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8147080f-af40-46d5-8435-ad1b04560dbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([], size=(0, 32005))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f5d23f87-5102-46f8-b61c-c116826654eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phrase originale : La programmation en <MASK> est fascinante.\n",
      "Mot prédit pour [MASK] : \n",
      "Phrase reconstruite : La programmation en <MASK> est fascinante.\n"
     ]
    }
   ],
   "source": [
    "from transformers import CamembertTokenizer, CamembertForMaskedLM\n",
    "import torch\n",
    "\n",
    "# Charger le tokenizer et le modèle\n",
    "tokenizer = CamembertTokenizer.from_pretrained(\"camembert-base\")\n",
    "model = CamembertForMaskedLM.from_pretrained(\"camembert-base\")\n",
    "\n",
    "# Phrase avec un token masqué\n",
    "text = \"La programmation en <MASK> est fascinante.\"\n",
    "\n",
    "# Tokenisation\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "# Inférence pour obtenir les logits\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "# Récupérer les logits\n",
    "logits = outputs.logits  # Shape: (batch_size, sequence_length, vocab_size)\n",
    "\n",
    "# Trouver la position du token [MASK]\n",
    "mask_token_index = torch.where(inputs.input_ids == tokenizer.mask_token_id)[1]\n",
    "\n",
    "# Extraire les logits pour le token [MASK]\n",
    "mask_logits = logits[0, mask_token_index, :]  # Shape: (num_masked_tokens, vocab_size)\n",
    "\n",
    "# Trouver l'ID du token prédit\n",
    "predicted_token_id = mask_logits.argmax(dim=-1)\n",
    "\n",
    "# Décoder l'ID pour obtenir le mot prédict\n",
    "predicted_token = tokenizer.decode(predicted_token_id)\n",
    "\n",
    "# Remplacer le token [MASK] par le mot prédit\n",
    "reconstructed_text = text.replace(tokenizer.mask_token, predicted_token)\n",
    "\n",
    "# Afficher les résultats\n",
    "print(f\"Phrase originale : {text}\")\n",
    "print(f\"Mot prédit pour [MASK] : {predicted_token}\")\n",
    "print(f\"Phrase reconstruite : {reconstructed_text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4a6cc06f-e7b6-4eb7-a299-8f7b4fda5e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phrase originale : La programmation en <mask> est fascinante.\n",
      "Mot prédit pour <mask> : ligne\n",
      "Phrase reconstruite : La programmation en ligne est fascinante.\n"
     ]
    }
   ],
   "source": [
    "# Charger le tokenizer et le modèle\n",
    "tokenizer = CamembertTokenizer.from_pretrained(\"camembert-base\")\n",
    "model = CamembertForMaskedLM.from_pretrained(\"camembert-base\")\n",
    "\n",
    "# Phrase avec un token masqué\n",
    "text = \"La programmation en <mask> est fascinante.\"\n",
    "\n",
    "# Tokenisation\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "# Inférence pour obtenir les logits\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "# Récupérer les logits\n",
    "logits = outputs.logits  # Shape: (batch_size, sequence_length, vocab_size)\n",
    "\n",
    "# Trouver la position du token <mask>\n",
    "mask_token_index = torch.where(inputs.input_ids == tokenizer.mask_token_id)[1]\n",
    "\n",
    "# Extraire les logits pour le token <mask>\n",
    "mask_logits = logits[0, mask_token_index, :]  # Shape: (num_masked_tokens, vocab_size)\n",
    "\n",
    "# Trouver l'ID du token prédit\n",
    "predicted_token_id = mask_logits.argmax(dim=-1)\n",
    "\n",
    "# Décoder l'ID pour obtenir le mot prédit\n",
    "predicted_token = tokenizer.decode(predicted_token_id)\n",
    "\n",
    "# Remplacer le token <mask> par le mot prédit\n",
    "reconstructed_text = text.replace(\"<mask>\", predicted_token)\n",
    "\n",
    "# Afficher les résultats\n",
    "print(f\"Phrase originale : {text}\")\n",
    "print(f\"Mot prédit pour <mask> : {predicted_token}\")\n",
    "print(f\"Phrase reconstruite : {reconstructed_text}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
