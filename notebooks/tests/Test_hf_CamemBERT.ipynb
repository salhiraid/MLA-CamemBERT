{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c07abd24-c2f6-46dc-b534-4b259e19f6f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/amine/CamemBERT/src\n",
      "Chemins disponibles pour Python : ['/usr/lib/python310.zip', '/usr/lib/python3.10', '/usr/lib/python3.10/lib-dynload', '', '/home/amine/.local/lib/python3.10/site-packages', '/usr/local/lib/python3.10/dist-packages', '/usr/lib/python3/dist-packages', '/home/amine/CamemBERT/src']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Chemin vers le dossier contenant \"src\"\n",
    "project_root = os.path.abspath(\"..\")\n",
    "print(project_root)\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "print(\"Chemins disponibles pour Python :\", sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfefe516-6245-44f6-b13c-d5b1299a3dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import CamembertTokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_from_disk\n",
    "from dataset import OscarDataset\n",
    "import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9b01e8b-990e-4ea4-89c4-739b0a8753be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ec2fb0ed2e94f349858d18b5a709e04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "248575ce3523402692a12621132e334a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/811k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3178522af5cb447da048eff2e36ba355",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.40M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "537ae7d1114b4774a16fa25b423e914e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/508 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 512])\n",
      "torch.Size([8, 512])\n",
      "tensor([    5, 23213,    17,    12,  4255,    32,   208,    19,  1004, 12358,\n",
      "           32,    16,   939,    22,   818,    42,    75,   587,     9,   180,\n",
      "         2646, 10929,    20,  1004,  9143,    10,    37,    19,  5548,    65,\n",
      "           99,    20,  4019, 11453,  6030,     8,   140,  8416,     9,   363,\n",
      "         2592,  2523,    31,   774,     8,    13,   445,  2646,    20,  4019,\n",
      "         9241,   257,    12,   169,    13,  3848,    20, 21611,    10,     9,\n",
      "        10265, 15321,  7740, 19771,   324,   163,    19, 11453,  6030,    20,\n",
      "         1517,  1148, 14413,     7,  4651,    14,  8712,     9, 13836, 19945,\n",
      "         1933,  7996, 12553, 20071,    10, 26559, 15378,  2376, 11462,   309,\n",
      "        20270, 26904,     3,     7,    28,   932,  2772,   135,  5648,    30,\n",
      "           28,  2985,     8,  1006,  4141,     9,    61,  1588,   135,  5648,\n",
      "           30,    46,    11,  3462,    11,   265,     7,    40,    27,   283,\n",
      "            7,    19,  1977,   750,  5120,    29,    20,  1898,    10,  5577,\n",
      "          147,    19,  3020,    56,  8451,    20, 14232,     9,  1664,    25,\n",
      "          132, 14181,    10,  8070,  7610,    26,  1474,  8329,  3886,    43,\n",
      "         3455,  7976,   727,  6630,   417, 13945, 10919,   158,  1340,    22,\n",
      "          319,    40,    32,   127,   932, 15378,  2376, 11462,   309, 20270,\n",
      "        26904,     3,   106,  4231,  1357,  4731,    16,  2738,   642,    26,\n",
      "         1568,     7,    23,     8,   166,  3510,  7020,  1002,    42,    39,\n",
      "          736,     9,  5357,  1363, 26080,  2157,  8219, 25790,  1166,  1363,\n",
      "        13049,  1363,  6232,  1363,    67, 21313,   108,    67,  4217,  4428,\n",
      "           35,    18,    12, 12149,  5335,   243,  1419,    20, 14277,    32,\n",
      "           19,  4241,   399,  8910,    81,    32,    23,   327,    15,   894,\n",
      "         5114,  6937,     8,  4032, 16024,    43,   568,   291,  1419,   127,\n",
      "        25670, 30572,    19,  4044,   642,    26,  1568,    24,  1653,   127,\n",
      "        25670,     9,  5357,  1363,  8666,  4514, 25790,  1166,  1363, 13049,\n",
      "         2157,  1363,  8219, 12057,    81,    28,  9346, 30572,    19,  4044,\n",
      "          642,    26,  1568,     7,    63,    39, 31148,   273,   736,     9,\n",
      "         5357,  1363, 26080, 25790,  1166,  1363, 13049,  1363,  2157,  1363,\n",
      "         8219,  1363,  5661,     8,  3864,     8,    75,   327,  1363,    67,\n",
      "        21313,   108,    67, 23793,   124,    14,   135,   250, 23793,   135,\n",
      "           14,   260,   250, 23793,   260,   250,    14,   124,   674,  5076,\n",
      "           18,    12,   367,   674,  9382,     8,   749, 12022,  7610,    26,\n",
      "         1474,   158,  1340,    22,   319,    40,    32,   127,   932, 15378,\n",
      "         2376, 11462,   309, 20270, 26904,     3,   106,  4231,  1357,  4731,\n",
      "           16,  2738,   642,    26,  1568,     7,    23,     8,   166,  3510,\n",
      "         7020,  1002,    42,    39,   736,     9,     6,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1])\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "# Charger le dataset Hugging Face sauvegardÃ©\n",
    "mini_oscar_path = os.path.abspath(\"../../data/CamemBERT/data/mini_oscar/mini_dataset.arrow\")\n",
    "hf_dataset = load_from_disk(mini_oscar_path)\n",
    "\n",
    "tokenizer = CamembertTokenizer.from_pretrained(\"camembert-base\")\n",
    "\n",
    "dataset = OscarDataset(hf_dataset, tokenizer, max_length=512)\n",
    "dataloader = DataLoader(dataset, batch_size=8)\n",
    "\n",
    "# Boucle pour vÃ©rifier les donnÃ©es\n",
    "for batch in dataloader:\n",
    "    print(batch[\"input_ids\"].shape)  # Shape : (batch_size, max_length)\n",
    "    print(batch[\"attention_mask\"].shape)  # Shape : (batch_size, max_length)\n",
    "    print(batch['input_ids'][0])\n",
    "    print(batch['attention_mask'][0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1ae70f-8644-40bf-a311-5bcf99afacae",
   "metadata": {},
   "source": [
    "# Let's test CamemBERT :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "58b0819a-f5c6-4cf0-b206-aa856c9880d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "model_loaded\n",
      "dataset loaded\n",
      "datalaoder created\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import CamembertTokenizer, CamembertForMaskedLM, logging\n",
    "from dataset import OscarDataset  # Votre classe personnalisÃ©e\n",
    "from datasets import load_from_disk\n",
    "\n",
    "logging.set_verbosity_error()\n",
    "\n",
    "# VÃ©rifier si un GPU est disponible\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 1. Charger le tokenizer et le modÃ¨le\n",
    "tokenizer = CamembertTokenizer.from_pretrained(\"camembert-base\")\n",
    "model = CamembertForMaskedLM.from_pretrained(\"camembert-base\")\n",
    "model = model.to(device)\n",
    "\n",
    "# 2. Charger le dataset\n",
    "data_path = os.path.abspath(\"../../data/CamemBERT/data/mini_oscar/mini_dataset.arrow\")\n",
    "hf_dataset = load_from_disk(data_path)\n",
    "\n",
    "# 3. CrÃ©er le DataLoader\n",
    "oscar_dataset = OscarDataset(hf_dataset, tokenizer, max_length=512)\n",
    "dataloader = DataLoader(oscar_dataset, batch_size=4)  #  shuffle=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17dfa1bd-b6d3-492b-8df1-4d3408cb5f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e9a09b-df42-4daa-aa98-89a9c0fde888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Tester le modÃ¨le avec un batch\n",
    "model.eval()  # Mode Ã©valuation\n",
    "for batch in dataloader:\n",
    "    input_ids = batch[\"input_ids\"].to(device)  # (B, 512)\n",
    "    attention_mask = batch[\"attention_mask\"].to(device)  # (B, 512)\n",
    "\n",
    "    # Passer le batch dans le modÃ¨le\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "    # Afficher les rÃ©sultats\n",
    "    print(\"Logits shape:\", outputs.logits.shape)  # (B, 512, vocab_size)\n",
    "    break  # Une seule itÃ©ration pour tester\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0a674806-ce68-4fee-af59-3bbda04c1dc9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CamembertForMaskedLM(\n",
      "  (roberta): CamembertModel(\n",
      "    (embeddings): CamembertEmbeddings(\n",
      "      (word_embeddings): Embedding(32005, 768, padding_idx=1)\n",
      "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
      "      (token_type_embeddings): Embedding(1, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): CamembertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-11): 12 x CamembertLayer(\n",
      "          (attention): CamembertAttention(\n",
      "            (self): CamembertSdpaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): CamembertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): CamembertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): CamembertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (lm_head): CamembertLMHead(\n",
      "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "    (decoder): Linear(in_features=768, out_features=32005, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from transformers import CamembertForMaskedLM\n",
    "import torch\n",
    "\n",
    "# Load the model\n",
    "model = CamembertForMaskedLM.from_pretrained(\"camembert-base\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "74f93c89-5b44-4883-b848-9c8845835500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Output Shapes:\n",
      "Logits: torch.Size([2, 512, 32005])\n"
     ]
    }
   ],
   "source": [
    "# Create dummy inputs to check input-output shapes\n",
    "batch_size = 2\n",
    "seq_length = 512\n",
    "input_ids = torch.randint(0, model.config.vocab_size, (batch_size, seq_length))\n",
    "attention_mask = torch.ones_like(input_ids)\n",
    "\n",
    "# Pass dummy inputs through the model\n",
    "outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "# Print the shapes of the outputs\n",
    "print(\"\\nOutput Shapes:\")\n",
    "print(f\"Logits: {outputs.logits.shape}\")  # Logits for masked LM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1048046-21a3-4655-a8b6-8c208109a22f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# CamembertForMaskedLM Architecture with Input and Output Shapes\n",
    "\n",
    "### **Model Input:**\n",
    "- **Input Shape:** `(batch_size, sequence_length)`\n",
    "\n",
    "---\n",
    "\n",
    "### **Embeddings:**\n",
    "1. **Word Embeddings**: \n",
    "   - **Input:** `(batch_size, sequence_length)` (token IDs, vocab size = 32,005)\n",
    "   - **Output:** `(batch_size, sequence_length, 768)` (embedding dimension)\n",
    "\n",
    "2. **Position Embeddings**:\n",
    "   - **Input:** `(batch_size, sequence_length)` (positions in sequence, max = 514)\n",
    "   - **Output:** `(batch_size, sequence_length, 768)` (embedding dimension)\n",
    "\n",
    "3. **Token Type Embeddings**:\n",
    "   - **Input:** `(batch_size, sequence_length)` (token type IDs, type size = 1)\n",
    "   - **Output:** `(batch_size, sequence_length, 768)` (embedding dimension)\n",
    "\n",
    "4. **Layer Normalization**:\n",
    "   - **Input:** `(batch_size, sequence_length, 768)`\n",
    "   - **Output:** `(batch_size, sequence_length, 768)`\n",
    "\n",
    "5. **Dropout**:\n",
    "   - **Input:** `(batch_size, sequence_length, 768)`\n",
    "   - **Output:** `(batch_size, sequence_length, 768)`\n",
    "\n",
    "---\n",
    "\n",
    "### **Encoder (CamembertEncoder):**\n",
    "- Composed of **12 CamembertLayer** modules.\n",
    "\n",
    "**For each CamembertLayer:**\n",
    "\n",
    "#### **Attention (Self-Attention + Output):**\n",
    "6. **Self-Attention Query, Key, Value:**\n",
    "   - **Input:** `(batch_size, sequence_length, 768)`\n",
    "   - **Output:** `(batch_size, sequence_length, 768)` (attention heads combined)\n",
    "\n",
    "7. **Self-Attention Output (Dense + LayerNorm):**\n",
    "   - **Input:** `(batch_size, sequence_length, 768)`\n",
    "   - **Output:** `(batch_size, sequence_length, 768)`\n",
    "\n",
    "#### **Intermediate Layer:**\n",
    "8. **Dense + GELU Activation:**\n",
    "   - **Input:** `(batch_size, sequence_length, 768)`\n",
    "   - **Output:** `(batch_size, sequence_length, 3072)` (intermediate dimension)\n",
    "\n",
    "#### **Output Layer:**\n",
    "9. **Dense + LayerNorm:**\n",
    "   - **Input:** `(batch_size, sequence_length, 3072)`\n",
    "   - **Output:** `(batch_size, sequence_length, 768)` (back to embedding dimension)\n",
    "\n",
    "---\n",
    "\n",
    "### **LM Head (CamembertLMHead):**\n",
    "10. **Dense**:\n",
    "    - **Input:** `(batch_size, sequence_length, 768)`\n",
    "    - **Output:** `(batch_size, sequence_length, 768)`\n",
    "\n",
    "11. **LayerNorm**:\n",
    "    - **Input:** `(batch_size, sequence_length, 768)`\n",
    "    - **Output:** `(batch_size, sequence_length, 768)`\n",
    "\n",
    "12. **Decoder (Final Linear Layer):**\n",
    "    - **Input:** `(batch_size, sequence_length, 768)`\n",
    "    - **Output:** `(batch_size, sequence_length, 32005)` (logits for vocabulary)\n",
    "\n",
    "---\n",
    "\n",
    "### **Model Output:**\n",
    "- **Logits Shape**: `(batch_size, sequence_length, 32005)` (vocabulary scores for each token in the sequence).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4bff7a0a-6b85-48d1-b4fe-03866f470fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens prÃ©dits pour les positions masquÃ©es :\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import CamembertTokenizer, CamembertForMaskedLM\n",
    "import torch\n",
    "\n",
    "# Charger le tokenizer et le modÃ¨le\n",
    "tokenizer = CamembertTokenizer.from_pretrained(\"camembert-base\")\n",
    "model = CamembertForMaskedLM.from_pretrained(\"camembert-base\")\n",
    "\n",
    "# Exemple avec un batch de deux phrases\n",
    "texts = [\n",
    "    \"La programmation en [MASK] est fascinante et facile.\",\n",
    "    \"J'aime apprendre avec [MASK].\"\n",
    "]\n",
    "\n",
    "# Tokenisation\n",
    "inputs = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "# Envoyer au modÃ¨le\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "# RÃ©cupÃ©rer les logits\n",
    "logits = outputs.logits  # Shape: (batch_size, sequence_length, vocab_size)\n",
    "\n",
    "# Trouver les indices des tokens [MASK]\n",
    "mask_token_index = (inputs[\"input_ids\"] == tokenizer.mask_token_id).nonzero(as_tuple=True)\n",
    "\n",
    "# Extraire les logits uniquement pour les positions [MASK]\n",
    "mask_logits = logits[mask_token_index]  # Shape: (num_masked_tokens, vocab_size)\n",
    "\n",
    "# PrÃ©dictions pour chaque [MASK]\n",
    "predicted_ids = mask_logits.argmax(dim=-1)  # Shape: (num_masked_tokens,)\n",
    "predicted_tokens = tokenizer.decode(predicted_ids)\n",
    "\n",
    "print(\"Tokens prÃ©dits pour les positions masquÃ©es :\")\n",
    "print(predicted_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "149b834d-967f-4f96-a4e8-1c2117a09e61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    5,    61,  4732,    22,   403,  3654,   229,   707,   374,    30,\n",
       "         25094,    14,   811,     9,     6],\n",
       "        [    5,   121,    11,   660,  1891,    42,   403,  3654,   229,   707,\n",
       "          2805,     6,     1,     1,     1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]])}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "37163ec9-f950-45ba-90d6-a7a23d660f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 22.6741,  -3.2752,   6.6612,  ...,  -6.5251,  -2.7296,   5.9366],\n",
      "         [  4.9040,  -3.4535,  15.1498,  ...,  -9.6906,  -0.9981,   7.8614],\n",
      "         [  5.1116,  -3.5781,   3.1757,  ..., -15.3700, -10.0413,   0.2270],\n",
      "         ...,\n",
      "         [  3.2980,  -7.6721,   4.0967,  ...,  -6.3892,  -8.3578,   5.3333],\n",
      "         [  5.6675,  -7.0110,   6.9816,  ...,  -5.7003,  -6.4600,   6.2704],\n",
      "         [  3.8989,  -3.5776,  27.2475,  ...,  -9.1564,  -5.2341,   5.9207]],\n",
      "\n",
      "        [[ 22.8516,  -3.5508,   8.0211,  ...,  -5.7155,  -2.0732,   6.0353],\n",
      "         [ -2.1751,  -4.6412,  15.2779,  ..., -13.9153,  -0.7081,  -2.5885],\n",
      "         [  2.0429,  -6.4475,   2.5401,  ..., -11.6387,  -7.5492,   1.1310],\n",
      "         ...,\n",
      "         [  7.7672,  -3.3566,  27.2912,  ...,  -8.2482,  -3.4188,   6.0584],\n",
      "         [  7.7672,  -3.3566,  27.2912,  ...,  -8.2482,  -3.4188,   6.0584],\n",
      "         [  7.7672,  -3.3566,  27.2912,  ...,  -8.2482,  -3.4188,   6.0584]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 15, 32005])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = outputs.logits\n",
    "print(logits)\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "68847929-bb55-41c4-92ae-d5381b790da1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([], dtype=torch.int64), tensor([], dtype=torch.int64))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_token_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c03c1bae-eafd-48df-916d-0216b2e22be0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32004"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.mask_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8147080f-af40-46d5-8435-ad1b04560dbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([], size=(0, 32005))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f5d23f87-5102-46f8-b61c-c116826654eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phrase originale : La programmation en <MASK> est fascinante.\n",
      "Mot prÃ©dit pour [MASK] : \n",
      "Phrase reconstruite : La programmation en <MASK> est fascinante.\n"
     ]
    }
   ],
   "source": [
    "from transformers import CamembertTokenizer, CamembertForMaskedLM\n",
    "import torch\n",
    "\n",
    "# Charger le tokenizer et le modÃ¨le\n",
    "tokenizer = CamembertTokenizer.from_pretrained(\"camembert-base\")\n",
    "model = CamembertForMaskedLM.from_pretrained(\"camembert-base\")\n",
    "\n",
    "# Phrase avec un token masquÃ©\n",
    "text = \"La programmation en <MASK> est fascinante.\"\n",
    "\n",
    "# Tokenisation\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "# InfÃ©rence pour obtenir les logits\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "# RÃ©cupÃ©rer les logits\n",
    "logits = outputs.logits  # Shape: (batch_size, sequence_length, vocab_size)\n",
    "\n",
    "# Trouver la position du token [MASK]\n",
    "mask_token_index = torch.where(inputs.input_ids == tokenizer.mask_token_id)[1]\n",
    "\n",
    "# Extraire les logits pour le token [MASK]\n",
    "mask_logits = logits[0, mask_token_index, :]  # Shape: (num_masked_tokens, vocab_size)\n",
    "\n",
    "# Trouver l'ID du token prÃ©dit\n",
    "predicted_token_id = mask_logits.argmax(dim=-1)\n",
    "\n",
    "# DÃ©coder l'ID pour obtenir le mot prÃ©dict\n",
    "predicted_token = tokenizer.decode(predicted_token_id)\n",
    "\n",
    "# Remplacer le token [MASK] par le mot prÃ©dit\n",
    "reconstructed_text = text.replace(tokenizer.mask_token, predicted_token)\n",
    "\n",
    "# Afficher les rÃ©sultats\n",
    "print(f\"Phrase originale : {text}\")\n",
    "print(f\"Mot prÃ©dit pour [MASK] : {predicted_token}\")\n",
    "print(f\"Phrase reconstruite : {reconstructed_text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4a6cc06f-e7b6-4eb7-a299-8f7b4fda5e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phrase originale : La programmation en <mask> est fascinante.\n",
      "Mot prÃ©dit pour <mask> : ligne\n",
      "Phrase reconstruite : La programmation en ligne est fascinante.\n"
     ]
    }
   ],
   "source": [
    "from transformers import CamembertTokenizer, CamembertForMaskedLM\n",
    "import torch\n",
    "\n",
    "# Charger le tokenizer et le modÃ¨le\n",
    "tokenizer = CamembertTokenizer.from_pretrained(\"camembert-base\")\n",
    "model = CamembertForMaskedLM.from_pretrained(\"camembert-base\")\n",
    "\n",
    "# Phrase avec un token masquÃ©\n",
    "text = \"La programmation en <mask> est fascinante.\"\n",
    "\n",
    "# Tokenisation\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "# InfÃ©rence pour obtenir les logits\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "# RÃ©cupÃ©rer les logits\n",
    "logits = outputs.logits  # Shape: (batch_size, sequence_length, vocab_size)\n",
    "\n",
    "# Trouver la position du token <mask>\n",
    "mask_token_index = torch.where(inputs.input_ids == tokenizer.mask_token_id)[1]\n",
    "\n",
    "# Extraire les logits pour le token <mask>\n",
    "mask_logits = logits[0, mask_token_index, :]  # Shape: (num_masked_tokens, vocab_size)\n",
    "\n",
    "# Trouver l'ID du token prÃ©dit\n",
    "predicted_token_id = mask_logits.argmax(dim=-1)\n",
    "\n",
    "# DÃ©coder l'ID pour obtenir le mot prÃ©dit\n",
    "predicted_token = tokenizer.decode(predicted_token_id)\n",
    "\n",
    "# Remplacer le token <mask> par le mot prÃ©dit\n",
    "reconstructed_text = text.replace(\"<mask>\", predicted_token)\n",
    "\n",
    "# Afficher les rÃ©sultats\n",
    "print(f\"Phrase originale : {text}\")\n",
    "print(f\"Mot prÃ©dit pour <mask> : {predicted_token}\")\n",
    "print(f\"Phrase reconstruite : {reconstructed_text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28a26d3-6c9a-4ab2-a509-0f80a993d4da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
