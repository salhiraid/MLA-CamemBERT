{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Evaluating model at: ./my_camembert_pos_model_fr_gsd on dataset: fr_gsd ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from C:\\Users\\rlarabi\\.cache\\huggingface\\modules\\datasets_modules\\datasets\\universal_dependencies\\1ac001f0e8a0021f19388e810c94599f3ac13cc45d6b5b8c69f7847b2188bdf7 (last modified on Sun Dec 22 01:48:43 2024) since it couldn't be found locally at universal_dependencies, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a2f0c4867eb4bc1853e44b832a18f32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/14449 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5785cfe6dca4cadbdf6013bb736ff79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1476 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdf7a055e1fb426db395c0335d1cb753",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/416 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0793 | Test Accuracy: 0.9786\n",
      "\n",
      "=== Evaluating model at: ./my_camembert_pos_model_fr_ftb on dataset: fr_ftb ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from C:\\Users\\rlarabi\\.cache\\huggingface\\modules\\datasets_modules\\datasets\\universal_dependencies\\1ac001f0e8a0021f19388e810c94599f3ac13cc45d6b5b8c69f7847b2188bdf7 (last modified on Sun Dec 22 01:48:43 2024) since it couldn't be found locally at universal_dependencies, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a83f97552e9041d1a48e49aac438dc54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/14759 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec9e7191ee834478b914c0d13a6e82c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1235 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a999de6131a84aadbf3a4906609c64bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2541 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 2.1138 | Test Accuracy: 0.2826\n",
      "\n",
      "=== Evaluating model at: ./my_camembert_pos_model_fr_partut on dataset: fr_partut ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from C:\\Users\\rlarabi\\.cache\\huggingface\\modules\\datasets_modules\\datasets\\universal_dependencies\\1ac001f0e8a0021f19388e810c94599f3ac13cc45d6b5b8c69f7847b2188bdf7 (last modified on Sun Dec 22 01:48:43 2024) since it couldn't be found locally at universal_dependencies, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42932881165a4c28a672a916624e8505",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/803 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abbe96e350594087b75b0bff82a65b84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/107 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f645bb9605424bcb9fea97d93f30042f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/110 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.8896 | Test Accuracy: 0.9689\n",
      "\n",
      "=== Evaluating model at: ./my_camembert_pos_model_squioa on dataset: fr_sequoia ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from C:\\Users\\rlarabi\\.cache\\huggingface\\modules\\datasets_modules\\datasets\\universal_dependencies\\1ac001f0e8a0021f19388e810c94599f3ac13cc45d6b5b8c69f7847b2188bdf7 (last modified on Sun Dec 22 01:48:43 2024) since it couldn't be found locally at universal_dependencies, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "576fd57dd898450aafd476bae784e61f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2231 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ad737992f4142d7b1496567ca2034aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/412 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94d5fdec878e48639d45701c02d97c2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/456 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.4097 | Test Accuracy: 0.9837\n",
      "\n",
      "=== Evaluating model at: ./my_camembert_pos_model_fr_spoken on dataset: fr_spoken ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from C:\\Users\\rlarabi\\.cache\\huggingface\\modules\\datasets_modules\\datasets\\universal_dependencies\\1ac001f0e8a0021f19388e810c94599f3ac13cc45d6b5b8c69f7847b2188bdf7 (last modified on Sun Dec 22 01:48:43 2024) since it couldn't be found locally at universal_dependencies, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d21cb8c522dc491c9ae794f4ad4e9130",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1167 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4508b92d85664a72923a5cd9a9165aba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/909 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dd14cfc30e645c39fd75ce460ff4d7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/730 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.7796 | Test Accuracy: 0.9674\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, SequentialSampler\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    CamembertForTokenClassification,\n",
    "    DataCollatorForTokenClassification\n",
    ")\n",
    "from datasets import load_dataset\n",
    "\n",
    "import os\n",
    "\n",
    "# -------------------------\n",
    "# Reuse tokenize_and_align_labels function\n",
    "# -------------------------\n",
    "def tokenize_and_align_labels(examples, tokenizer):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"tokens\"],\n",
    "        is_split_into_words=True,\n",
    "        truncation=True\n",
    "    )\n",
    "\n",
    "    all_labels = []\n",
    "    for i in range(len(examples[\"tokens\"])):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        labels = []\n",
    "        for word_id in word_ids:\n",
    "            if word_id is None:\n",
    "                labels.append(-100)  # ignore special tokens\n",
    "            else:\n",
    "                upos_id = examples[\"upos\"][i][word_id]\n",
    "                labels.append(upos_id)\n",
    "        all_labels.append(labels)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = all_labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "def evaluate_model_on_dataset(\n",
    "    model_dir,           # e.g. \"./my_camembert_pos_model_fr_gsd\"\n",
    "    ud_subset_name,      # e.g. \"fr_gsd\", \"fr_ftb\", etc.\n",
    "    batch_size=16\n",
    "):\n",
    "    \"\"\"\n",
    "    Loads the saved model/tokenizer from model_dir,\n",
    "    downloads the UD dataset (ud_subset_name),\n",
    "    tokenizes the test set,\n",
    "    and computes test accuracy.\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"\\n=== Evaluating model at: {model_dir} on dataset: {ud_subset_name} ===\")\n",
    "\n",
    "    # 1) Load the dataset\n",
    "    dataset = load_dataset(\n",
    "        \"universal_dependencies\",\n",
    "        ud_subset_name,\n",
    "        trust_remote_code=True\n",
    "    )\n",
    "\n",
    "    # 2) Inspect labels (UPOS)\n",
    "    upos_feature = dataset[\"train\"].features[\"upos\"]\n",
    "    all_label_strings = upos_feature.feature.names\n",
    "    num_labels = len(all_label_strings)\n",
    "\n",
    "    # 3) Load the tokenizer and model from disk\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "    model = CamembertForTokenClassification.from_pretrained(model_dir)\n",
    "    model.eval()\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    # 4) Tokenize the dataset\n",
    "    def my_map_fn(examples):\n",
    "        return tokenize_and_align_labels(examples, tokenizer)\n",
    "\n",
    "    tokenized_dataset = dataset.map(\n",
    "        my_map_fn,\n",
    "        batched=True\n",
    "    )\n",
    "\n",
    "    # Convert to PyTorch format\n",
    "    tokenized_dataset.set_format(\n",
    "        type=\"torch\",\n",
    "        columns=[\"input_ids\", \"attention_mask\", \"labels\"]\n",
    "    )\n",
    "\n",
    "    # 5) Create a DataLoader for the test set\n",
    "    test_dataset = tokenized_dataset[\"test\"]\n",
    "    data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer, padding=True)\n",
    "\n",
    "    test_dataloader = DataLoader(\n",
    "        test_dataset,\n",
    "        sampler=SequentialSampler(test_dataset),\n",
    "        batch_size=batch_size,\n",
    "        collate_fn=data_collator\n",
    "    )\n",
    "\n",
    "    # 6) Loop over test set to compute loss & accuracy\n",
    "    test_loss = 0.0\n",
    "    test_correct = 0\n",
    "    test_total   = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_dataloader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "\n",
    "            # Accumulate test loss\n",
    "            test_loss += outputs.loss.item()\n",
    "\n",
    "            # Compute predictions\n",
    "            logits = outputs.logits\n",
    "            preds = logits.argmax(dim=-1)\n",
    "            labels = batch[\"labels\"]\n",
    "\n",
    "            # Only consider positions where label != -100\n",
    "            mask = labels != -100\n",
    "            test_correct += (preds[mask] == labels[mask]).sum().item()\n",
    "            test_total   += mask.sum().item()\n",
    "\n",
    "    avg_test_loss = test_loss / len(test_dataloader)\n",
    "    test_accuracy = test_correct / test_total if test_total > 0 else 0.0\n",
    "\n",
    "    print(f\"Test Loss: {avg_test_loss:.4f} | Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "    return avg_test_loss, test_accuracy\n",
    "\n",
    "# -------------------------\n",
    "# Example usage:\n",
    "# -------------------------\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    models_and_datasets = [\n",
    "        (\"./my_camembert_pos_model_fr_gsd\",     \"fr_gsd\"),\n",
    "        (\"./my_camembert_pos_model_fr_ftb\",     \"fr_ftb\"),\n",
    "        (\"./my_camembert_pos_model_fr_partut\",  \"fr_partut\"),\n",
    "        (\"./my_camembert_pos_model_squioa\",     \"fr_sequoia\"),  \n",
    "        (\"./my_camembert_pos_model_fr_spoken\", \"fr_spoken\")   \n",
    "    ]\n",
    "\n",
    "    for model_dir, ud_subset in models_and_datasets:\n",
    "        evaluate_model_on_dataset(model_dir, ud_subset)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
