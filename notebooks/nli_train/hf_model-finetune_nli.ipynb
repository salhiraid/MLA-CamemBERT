{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook: CamemBERT Finetuning on Natural Language Inference (NLI) \n",
    "\n",
    "- **Date**: January 2025  \n",
    "- **Description**: This notebook focuses on fine-tuning a pre-trained **CamemBERT** model on the **Natural Language Inference (NLI)** task using the **XNLI** dataset. \n",
    "- **Data Source**: [Hugging Face Datasets - NLI](https://huggingface.co/datasets/xnli) (392,702 examples in French).  \n",
    "- **Tools Used**: PyTorch, PyTorch Lightning, Transformers & Datasets libraries.  \n",
    "- **GPU Used**: Quadro RTX 6000  \n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Inference (NLI)\n",
    "\n",
    "### What’s the Deal?\n",
    "NLI is all about figuring out the relationship between two sentences:  \n",
    "- A **premise** (what you already know), and  \n",
    "- A **hypothesis** (what you're trying to verify).\n",
    "\n",
    "Think of it as your model playing detective: Does the hypothesis make sense, is it unrelated, or is it flat-out wrong?\n",
    "\n",
    "### Why Should We Care?  \n",
    "NLI is a big deal in NLP because it tests how well a model actually *understands* language, instead of just parroting back what it’s seen.  \n",
    "\n",
    "In the real world, NLI powers applications like **chatbots** that can handle nuanced customer support queries and **search engines** that understand the intent behind your questions to provide smarter, context-aware results.  \n",
    "\n",
    "Let’s keep it simple: The goal is to fine-tune the model and check how often it nails the correct verdict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress unnecessary warnings and set verbosity for Transformers\n",
    "import warnings\n",
    "import transformers\n",
    "transformers.logging.set_verbosity_error()\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# PyTorch core libraries\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from torch.nn.functional import softmax\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "# Transformers and Datasets\n",
    "from transformers import CamembertModel, CamembertTokenizer, CamembertConfig\n",
    "from datasets import load_dataset\n",
    "\n",
    "# PyTorch Lightning and Metrics\n",
    "import pytorch_lightning as pl\n",
    "from torchmetrics import Accuracy\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "# Visualization and DataFrame utilities\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This section prepares the XNLI dataset for training. But before diving in, let’s explore the dataset: how to download it and take a look at some examples.\n",
    "\n",
    "The XNLI (Cross-lingual Natural Language Inference) dataset is used for classification tasks involving logical relationships between pairs of sentences. It contains three main columns:\n",
    "\n",
    "1. **Premises**:\n",
    "   - The base sentence (premise) that serves as the starting point for inference.\n",
    "\n",
    "2. **Hypotheses**:\n",
    "   - The hypothesis sentence to be compared with the premise.\n",
    "\n",
    "3. **Label**:\n",
    "   - Indicates the logical relationship between the premise and the hypothesis. The possible labels are:\n",
    "     - **0: entailment** (the premise implies the hypothesis).\n",
    "     - **1: neutral** (the premise and hypothesis are unrelated or have no direct logical link).\n",
    "     - **2: contradiction** (the premise contradicts the hypothesis).\n",
    "\n",
    "### Example:\n",
    "\n",
    "| Premises                       | Hypotheses                       | Label             |\n",
    "|--------------------------------|----------------------------------|-------------------|\n",
    "| \"Cats sleep a lot.\"            | \"Cats never sleep.\"              | 2 (contradiction) |\n",
    "| \"The sun is shining.\"          | \"It’s a beautiful day outside.\"  | 0 (entailment)    |\n",
    "| \"A man is reading a book.\"     | \"A woman is watching TV.\"        | 1 (neutral)       |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = CamembertTokenizer.from_pretrained('camembert-base')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following class provides a PyTorch-compatible dataset wrapper for the XNLI dataset. \n",
    "It handles loading, tokenizing, and preparing premise-hypothesis pairs with their corresponding labels for training, validation, or testing. \n",
    "The dataset is dynamically downloaded and cached if not already present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XNLIDataset(Dataset):\n",
    "    def __init__(self, cache_directory, split=\"train\", language=\"fr\", tokenizer=tokenizer, max_length=64):\n",
    "        \"\"\"\n",
    "        PyTorch-compatible dataset for the XNLI dataset.\n",
    "\n",
    "        Args:\n",
    "            split (str): Data split to load (\"train\", \"test\", or \"validation\").\n",
    "            language (str): Target language for the dataset.\n",
    "            cache_directory (str): Directory to cache the downloaded dataset.\n",
    "            max_length (int): Maximum sequence length for padding/truncation.\n",
    "        \"\"\"\n",
    "        super(XNLIDataset, self).__init__()\n",
    "        self.split = split\n",
    "        self.language = language\n",
    "        self.cache_directory = cache_directory\n",
    "        self.max_length = max_length\n",
    "\n",
    "        # Load the data and the tokenizer\n",
    "        self.data = load_dataset(\n",
    "            \"facebook/xnli\",\n",
    "            name=self.language,\n",
    "            cache_dir=self.cache_directory\n",
    "        )[self.split]  # Load the specified data split\n",
    "\n",
    "        self.tokenizer = tokenizer  # CamembertTokenizer.from_pretrained(\"camembert-base\")\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Returns the size of the dataset.\"\"\"\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Retrieve a specific sample from the dataset.\n",
    "\n",
    "        Args:\n",
    "            idx (int): Index of the sample.\n",
    "\n",
    "        Returns:\n",
    "            dict: Contains `input_ids`, `attention_mask`, and `label`.\n",
    "        \"\"\"\n",
    "        example = self.data[idx]\n",
    "        inputs = self.tokenizer(\n",
    "            example[\"premise\"],\n",
    "            example[\"hypothesis\"],\n",
    "            max_length=self.max_length,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        # Add the labels\n",
    "        inputs = {key: val.squeeze(0) for key, val in inputs.items()}  # Remove batch dimension\n",
    "        inputs[\"label\"] = torch.tensor(example[\"label\"], dtype=torch.long)\n",
    "\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the Role of the Dataset Class:\n",
    "Let’s explain how our **XNLIDataset** class works and how it processes the raw data. To do this, we’ll take a raw example from the dataset before it’s passed through the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Premise : Et il a dit, maman, je suis à la maison.\n",
      "Hypothesis : Il a dit à sa mère qu'il était rentré.\n",
      "Label : 0 (entailment)\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"facebook/xnli\", name='fr', cache_dir=\"../../../data/xnli\")\n",
    "\n",
    "# Display some examples from the dataset\n",
    "print(f\"Premise : {dataset['validation'][2]['premise']}\")\n",
    "print(f\"Hypothesis : {dataset['validation'][2]['hypothesis']}\")\n",
    "print(f\"Label : {dataset['validation'][2]['label']} (entailment)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This snippet displays the premise, hypothesis, and label before any preprocessing is applied.  \n",
    "Here, the label `0` corresponds to **entailment**, meaning the hypothesis logically follows from the premise.  \n",
    "\n",
    "However, the model cannot directly process raw text like the premise and hypothesis. These sentences must be transformed into numerical tensors that the model can understand.  \n",
    "\n",
    "This is where the `XNLIDataset` class comes into play:  \n",
    "\n",
    "- It **tokenizes** both the premise and hypothesis into a single input.  \n",
    "- The two sentences are separated by a special token, `</s>`.  \n",
    "- The `</s>` token acts as a delimiter, marking the end of the premise and the beginning of the hypothesis.  \n",
    "\n",
    "This transformation ensures the model can effectively reason about the relationship between the sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch shape: torch.Size([256, 64])\n",
      "Token IDs (example):\n",
      "tensor([    5,   139,    51,    33,   227,     7,  2699,     7,    50,   146,\n",
      "           15,    13,   269,     9,     6,     6,    69,    33,   227,    15,\n",
      "           77,   907,    46,    11,    62,   149, 10540,     9,     6,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1]) \n",
      "\n",
      "Decoded text (example):\n",
      "<s> Et il a dit, maman, je suis à la maison.</s></s> Il a dit à sa mère qu'il était rentré.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../../../data/xnli\"\n",
    "\n",
    "xnli_train_dataset = XNLIDataset(split=\"train\", language=\"fr\", cache_directory=data_path, max_length=64)\n",
    "xnli_val_dataset = XNLIDataset(split=\"validation\", language=\"fr\", cache_directory=data_path, max_length=64)\n",
    "\n",
    "train_loader = DataLoader(xnli_train_dataset, batch_size=256, shuffle=True)\n",
    "val_loader = DataLoader(xnli_val_dataset, batch_size=256, shuffle=False)\n",
    "\n",
    "\n",
    "batch = next(iter(val_loader))\n",
    "print(f\"Batch shape: {batch['input_ids'].shape}\")\n",
    "print(f\"Token IDs (example):\\n{batch['input_ids'][2]} \\n\")\n",
    "decoded_text = tokenizer.decode(batch['input_ids'][2])\n",
    "print(f\"Decoded text (example):\\n{decoded_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code showcases the preprocessing of the XNLI dataset after being tokenized and loaded into a DataLoader. Here's the breakdown:\n",
    "\n",
    "1. **Shape of the Batch**:  \n",
    "   `torch.Size([256, 64])` indicates that the batch contains 256 samples, each with a maximum sequence length of 64 tokens. This padding ensures that all sequences are of uniform length for batch processing.\n",
    "\n",
    "2. **Tokenized Example**:  \n",
    "   - The tensor output represents the tokenized version of a sentence pair (premise and hypothesis) using the CamemBERT tokenizer. Each number corresponds to a specific token ID in the tokenizer's vocabulary:\n",
    "     ```\n",
    "     5,   139,    51,    33,   227,     7,  2699,     7,    50,   146,\n",
    "     15,    13,   269,     9,     6,     6,    69,    33,   227,    15,\n",
    "     77,   907,    46,    11,    62,   149, 10540,     9,     6,     1,\n",
    "      1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
    "      1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
    "      1,     1,     1,     1,     1,     1,     1,     1,     1,     1\n",
    "     ```\n",
    "   - Notice the padding tokens (`1`) at the end to fill sequences shorter than 128 tokens.\n",
    "\n",
    "3. **Decoded Tokens**:  \n",
    "   - Using `tokenizer.decode`, the token IDs are converted back into a human-readable format:  \n",
    "     ```\n",
    "     <s> Et il a dit, maman, je suis à la maison.</s></s> Il a dit à sa mère qu'il était rentré.</s><pad><pad><pad>...\n",
    "     ```\n",
    "   - The `<s>` and `</s>` tags indicate sentence boundaries, while `<pad>` represents the padding added for uniformity.\n",
    "\n",
    "4. **Key Insight**:  \n",
    "   This example demonstrates how the premise and hypothesis are combined into a single input separated by special tokens (`</s>`). This structure ensures the model processes the relationship between the two sentences effectively.\n",
    "\n",
    "**Once we have these token IDs and the attention mask (to ignore the padding tokens), we can feed them into our model for training or inference.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare the model :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CamemBERTBaseModel(nn.Module):\n",
    "    def __init__(self, model_path: str, trainable: bool = False):\n",
    "        \"\"\"\n",
    "        Initialize the base CamemBERT model.\n",
    "        param model_path: Path to the pre-trained CamemBERT model.\n",
    "        \"\"\"\n",
    "        super(CamemBERTBaseModel, self).__init__()\n",
    "        self.base_model = CamembertModel.from_pretrained(model_path)\n",
    "        self.tranaible = trainable\n",
    "        self.config = CamembertConfig()\n",
    " \n",
    "        if not trainable:\n",
    "            for param in self.base_model.parameters():\n",
    "                param.requires_grad = False\n",
    "            self.base_model.eval()\n",
    "        else :\n",
    "            self.base_model.train()\n",
    "\n",
    "    def forward(self, input_ids: torch.Tensor, attention_mask: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass through the base model.\n",
    "        param input_ids: Tensor of token IDs.\n",
    "        param attention_mask: Tensor of attention masks.\n",
    "        return: Last hidden states from the base model.\n",
    "        \"\"\"\n",
    "        outputs = self.base_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        return outputs.last_hidden_state\n",
    "\n",
    "    def get_hidden_size(self) -> int:\n",
    "        return self.config.hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NLIFinetuningModel(nn.Module):\n",
    "    def __init__(self, base_model: CamemBERTBaseModel, num_labels: int = 3):\n",
    "        \"\"\"\n",
    "        Initialize the NLI fine-tuning model.\n",
    "        :param base_model: Instance of the base CamemBERT model.\n",
    "        :param num_labels: Number of labels for NLI.\n",
    "        \"\"\"\n",
    "        super(NLIFinetuningModel, self).__init__()\n",
    "        self.base_model = base_model \n",
    "\n",
    "        self.hidden_size = base_model.get_hidden_size()\n",
    "        self.num_labels = num_labels\n",
    "\n",
    "        self.nli_head = nn.Linear(self.hidden_size, num_labels)\n",
    "        # self.nli_head = NLIHead(base_model.get_hidden_size(), num_labels)\n",
    "\n",
    "    def forward(self, input_ids: torch.Tensor, attention_mask: torch.Tensor, labels: torch.Tensor = None):\n",
    "        \"\"\"\n",
    "        Forward pass for NLI fine-tuning.\n",
    "        :param input_ids: Tensor of token IDs.\n",
    "        :param attention_mask: Tensor of attention masks.\n",
    "        :param labels: Optional tensor of labels (batch_size).\n",
    "        :return: Dictionary containing logits and optionally loss.\n",
    "        \"\"\"\n",
    "        # Get last hidden states from the base model\n",
    "        hidden_states = self.base_model(input_ids=input_ids, attention_mask=attention_mask) # (batch_size, seq_len, hidden_size) -> (batch_size, seq_len, hidden_size)\n",
    "\n",
    "        # Extract the [CLS] token's representation\n",
    "        cls_output = hidden_states[:, 0, :]  # Shape: (batch_size, hidden_size)\n",
    "\n",
    "        # Pass through the NLI head\n",
    "        logits = self.nli_head(cls_output)  # Shape: (batch_size, num_labels)\n",
    "\n",
    "        # Compute loss if labels are provided\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fn = nn.CrossEntropyLoss()\n",
    "            loss = loss_fn(logits, labels)\n",
    "\n",
    "        return {\"logits\": logits, \"loss\": loss}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Design Logic:\n",
    "\n",
    "#### 1. **Base Model: `CamemBERTBaseModel`**\n",
    "The first class, `CamemBERTBaseModel`, handles the **base model**, which is essentially the output of the pretraining phase (like Masked Language Modeling - MLM). \n",
    "\n",
    "- It takes care of loading the pre-trained weights for CamemBERT, either from **Hugging Face** or a model we fine-tuned ourselves.\n",
    "- By including the option to **freeze** the base model's parameters (`trainable=False`), we can easily switch between:\n",
    "  - Using the pre-trained features directly.\n",
    "  - Fine-tuning the base model for downstream tasks.\n",
    "- The `get_hidden_size` method allows us to dynamically retrieve the size of the hidden states, making it flexible for different architectures.\n",
    "\n",
    "#### 2. **Fine-tuning Model: `NLIFinetuningModel`**\n",
    "The second class, `NLIFinetuningModel`, builds on the base model to create the full architecture needed for the **Natural Language Inference (NLI)** task.\n",
    "\n",
    "- It adds a **classification head** (`nli_head`), which is a simple linear layer mapping the hidden size to the number of NLI labels (3 in this case: Entailment, Neutral, Contradiction).\n",
    "- The forward pass processes the tokenized input using the base model, extracts the hidden state of the `[CLS]` token (first token), and passes it through the classification head.\n",
    "\n",
    "#### 3. **Why This Design?**\n",
    "We chose to split the logic into two classes for **modularity** and **flexibility**:\n",
    "- It allows us to test **different base models** (e.g., the CamemBERT downloaded from Hugging Face versus one we pre-trained ourselves).\n",
    "- It simplifies experimentation, making it easy to:\n",
    "  - Swap out the base model.\n",
    "  - Use the same fine-tuning logic for other pre-trained models.  \n",
    "\n",
    "This structure ensures our code is clean, reusable, and ready for a variety of tasks or models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Finetune the model for Natural Language Inference :\n",
    "\n",
    "### Why PyTorch Lightning?\n",
    "\n",
    "We decided to use PyTorch Lightning because it simplifies model training by abstracting repetitive tasks like logging, checkpointing, and optimizer configuration. This allows us to focus on the logic of our model and training steps without getting bogged down by boilerplate code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NLI(pl.LightningModule):\n",
    "    def __init__(self, model, lr=5e-5):\n",
    "        \"\"\"\n",
    "        NLI model for training with PyTorch Lightning.\n",
    "        :param model: Instance of the fine-tuning model.\n",
    "        :param lr: Learning rate.\n",
    "        \"\"\"\n",
    "        super(NLI, self).__init__()\n",
    "        self.model = model\n",
    "        self.lr = lr\n",
    "\n",
    "        # Accuracy metrics for training and validation\n",
    "        self.train_accuracy = Accuracy(task=\"multiclass\", num_classes=3)\n",
    "        self.val_accuracy = Accuracy(task=\"multiclass\", num_classes=3)\n",
    "\n",
    "        # Metrics tracked per step\n",
    "        self.train_losses_step = []\n",
    "        self.train_accuracies_step = []\n",
    "        self.val_losses_step = []\n",
    "        self.val_accuracies_step = []\n",
    "\n",
    "        # Metrics tracked per epoch\n",
    "        self.train_losses_epoch = []\n",
    "        self.train_accuracies_epoch = []\n",
    "        self.val_losses_epoch = []\n",
    "        self.val_accuracies_epoch = []\n",
    "\n",
    "    def forward(self, batch):\n",
    "        \"\"\"\n",
    "        Forward pass for inference.\n",
    "        :param batch: Input batch containing input IDs, attention masks, and labels.\n",
    "        :return: Model logits.\n",
    "        \"\"\"\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        outputs = self.model(input_ids, attention_mask, labels)\n",
    "        return outputs[\"logits\"]\n",
    "\n",
    "    def training_step(self, batch, batch_index):\n",
    "        \"\"\"\n",
    "        Performs a single training step.\n",
    "        :param batch: Input batch containing input IDs, attention masks, and labels.\n",
    "        :param batch_index: Index of the batch.\n",
    "        :return: Training loss.\n",
    "        \"\"\"\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        labels = batch[\"label\"]\n",
    "\n",
    "        outputs = self.model(input_ids, attention_mask, labels)\n",
    "        loss = outputs[\"loss\"]\n",
    "\n",
    "        # Compute accuracy\n",
    "        preds = torch.argmax(outputs[\"logits\"], dim=1)\n",
    "        acc = self.train_accuracy(preds, labels)\n",
    "\n",
    "        # Store step metrics\n",
    "        self.train_losses_step.append(loss.item())\n",
    "        self.train_accuracies_step.append(acc.item())\n",
    "\n",
    "        # Log metrics for progress bar\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, on_step=True, on_epoch=False)\n",
    "        self.log(\"train_acc\", acc, prog_bar=True, on_step=True, on_epoch=False)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        \"\"\"\n",
    "        Computes and stores epoch-level training metrics at the end of each epoch.\n",
    "        \"\"\"\n",
    "        avg_loss = torch.tensor(self.train_losses_step).mean().item()\n",
    "        avg_acc = torch.tensor(self.train_accuracies_step).mean().item()\n",
    "\n",
    "        self.train_losses_epoch.append(avg_loss)\n",
    "        self.train_accuracies_epoch.append(avg_acc)\n",
    "\n",
    "        # Display epoch results\n",
    "        print(f\"[Epoch {self.current_epoch}] Train Loss: {avg_loss:.4f}, Train Accuracy: {avg_acc:.4f}\")\n",
    "\n",
    "        # Clear step metrics to prepare for the next epoch\n",
    "        self.train_losses_step.clear()\n",
    "        self.train_accuracies_step.clear()\n",
    "\n",
    "    def validation_step(self, batch, batch_index):\n",
    "        \"\"\"\n",
    "        Performs a single validation step.\n",
    "        :param batch: Input batch containing input IDs, attention masks, and labels.\n",
    "        :param batch_index: Index of the batch.\n",
    "        :return: Validation loss.\n",
    "        \"\"\"\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        labels = batch[\"label\"]\n",
    "\n",
    "        outputs = self.model(input_ids, attention_mask, labels)\n",
    "        loss = outputs[\"loss\"]\n",
    "\n",
    "        # Compute accuracy\n",
    "        preds = torch.argmax(outputs[\"logits\"], dim=1)\n",
    "        acc = self.val_accuracy(preds, labels)\n",
    "\n",
    "        # Store step metrics\n",
    "        self.val_losses_step.append(loss.item())\n",
    "        self.val_accuracies_step.append(acc.item())\n",
    "\n",
    "        # Log metrics for progress bar\n",
    "        self.log(\"val_loss\", loss, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        self.log(\"val_acc\", acc, prog_bar=True, on_step=False, on_epoch=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        \"\"\"\n",
    "        Computes and stores epoch-level validation metrics at the end of each epoch.\n",
    "        \"\"\"\n",
    "        avg_loss = torch.tensor(self.val_losses_step).mean().item()\n",
    "        avg_acc = torch.tensor(self.val_accuracies_step).mean().item()\n",
    "\n",
    "        self.val_losses_epoch.append(avg_loss)\n",
    "        self.val_accuracies_epoch.append(avg_acc)\n",
    "\n",
    "        # Display epoch results\n",
    "        print(f\"[Epoch {self.current_epoch}] Val Loss: {avg_loss:.4f}, Val Accuracy: {avg_acc:.4f}\")\n",
    "\n",
    "        # Clear step metrics to prepare for the next epoch\n",
    "        self.val_losses_step.clear()\n",
    "        self.val_accuracies_step.clear()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"\n",
    "        Configures the optimizer and learning rate scheduler.\n",
    "        :return: Dictionary containing the optimizer and scheduler configurations.\n",
    "        \"\"\"\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.lr)\n",
    "\n",
    "        # Dynamically calculate the total number of steps\n",
    "        steps_per_epoch = 1534\n",
    "        total_steps = steps_per_epoch * self.trainer.max_epochs\n",
    "\n",
    "        scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "            optimizer,\n",
    "            max_lr=self.lr,\n",
    "            total_steps=total_steps,\n",
    "            pct_start=0.1,\n",
    "            anneal_strategy=\"linear\",\n",
    "        )\n",
    "        return {\"optimizer\": optimizer, \"lr_scheduler\": {\"scheduler\": scheduler, \"interval\": \"step\"}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logic Behind the `NLI` Class\n",
    "\n",
    "The `NLI` class is built to manage the training and validation process for our NLI model efficiently:\n",
    "\n",
    "1. **Modularity**: \n",
    "   - The class integrates the fine-tuned model and handles both forward passes and the training logic.\n",
    "   - Metrics (loss and accuracy) are tracked at both step and epoch levels, enabling detailed analysis of model performance.\n",
    "\n",
    "2. **Training and Validation**: \n",
    "   - The `training_step` and `validation_step` methods define the behavior for each batch during training and validation, respectively. \n",
    "   - These steps include loss computation, accuracy calculation, and logging metrics for real-time progress updates.\n",
    "\n",
    "3. **Epoch-Level Summaries**: \n",
    "   - At the end of each epoch, average metrics are computed (`on_train_epoch_end` and `on_validation_epoch_end`).\n",
    "   - This ensures we monitor model performance holistically over entire epochs.\n",
    "\n",
    "4. **Optimizer and Scheduler**: \n",
    "   - The `configure_optimizers` method sets up AdamW as the optimizer and a `OneCycleLR` learning rate scheduler, which dynamically adjusts the learning rate for smoother convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "steps_per_epoch = len(train_loader)\n",
    "\n",
    "# Define the path to the pre-trained model\n",
    "model_path = \"../../../models/oscar_4gb\"  # Path to the Hugging Face pre-trained model\n",
    "\n",
    "# Step 1: Create the fine-tuning model\n",
    "nli_camembert = NLIFinetuningModel(\n",
    "    base_model=CamemBERTBaseModel(model_path, trainable=True),  # Use a trainable base model\n",
    "    num_labels=3  # Classes: entailment, neutral, contradiction\n",
    ")\n",
    "\n",
    "# Step 2: Configure the PyTorch Lightning module for training\n",
    "nb_epochs = 3\n",
    "nb_steps_per_epoch = len(train_loader)\n",
    "pl_camembert = NLI(\n",
    "    model=nli_camembert\n",
    ")\n",
    "\n",
    "# Step 3: Set up model checkpointing\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=\"val_loss\",           # Metric to monitor (validation loss)\n",
    "    dirpath=\"checkpoints/\",       # Directory for saving model checkpoints\n",
    "    filename=\"nli-{epoch:02d}-{val_loss:.2f}\",  # Format for checkpoint filenames\n",
    "    save_top_k=2,                 # Save only the top 2 models with the best validation loss\n",
    "    mode=\"min\"                    # Minimize the monitored metric\n",
    ")\n",
    "\n",
    "# Step 4: Set up TensorBoard logging\n",
    "logger = TensorBoardLogger(\n",
    "    save_dir=\"my_logs\",           # Directory for saving logs\n",
    "    name=\"final-experiment\"       # Name for the experiment\n",
    ")\n",
    "\n",
    "# Step 5: Initialize the PyTorch Lightning Trainer\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=5,                 # Number of training epochs\n",
    "    accelerator=\"gpu\",            # Use GPU for training (if available)\n",
    "    devices=1,                    # Number of GPUs to use\n",
    "    callbacks=[checkpoint_callback],  # Add checkpointing callback\n",
    "    logger=logger                 # Use the configured TensorBoard logger\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1534"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xnli_train_dataset = XNLIDataset(split=\"train\", language=\"fr\", cache_directory=data_path, max_length=64)\n",
    "xnli_val_dataset = XNLIDataset(split=\"validation\", language=\"fr\", cache_directory=data_path, max_length=64)\n",
    "\n",
    "train_loader = DataLoader(xnli_train_dataset, batch_size=256, shuffle=True)\n",
    "val_loader = DataLoader(xnli_val_dataset, batch_size=256, shuffle=False)\n",
    "\n",
    "steps_per_epoch = len(train_loader)\n",
    "steps_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type               | Params | Mode \n",
      "--------------------------------------------------------------\n",
      "0 | model          | NLIFinetuningModel | 110 M  | train\n",
      "1 | train_accuracy | MulticlassAccuracy | 0      | train\n",
      "2 | val_accuracy   | MulticlassAccuracy | 0      | train\n",
      "--------------------------------------------------------------\n",
      "110 M     Trainable params\n",
      "0         Non-trainable params\n",
      "110 M     Total params\n",
      "442.497   Total estimated model params size (MB)\n",
      "233       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0] Val Loss: 1.1032, Val Accuracy: 0.3340\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "092bd30167374f02a5214e49a7385b32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0] Val Loss: 0.5163, Val Accuracy: 0.7956\n",
      "[Epoch 0] Train Loss: 0.6583, Train Accuracy: 0.7151\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Val Loss: 0.4847, Val Accuracy: 0.8191\n",
      "[Epoch 1] Train Loss: 0.4853, Train Accuracy: 0.8083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3] Val Loss: 0.5698, Val Accuracy: 0.8073\n",
      "[Epoch 3] Train Loss: 0.3073, Train Accuracy: 0.8847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4] Val Loss: 0.6112, Val Accuracy: 0.8077\n",
      "[Epoch 4] Train Loss: 0.2436, Train Accuracy: 0.9118\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(pl_camembert, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results by Epoch:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Train Loss</th>\n",
       "      <th>Val Loss</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Val Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.658302</td>\n",
       "      <td>0.516347</td>\n",
       "      <td>0.715135</td>\n",
       "      <td>0.795632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.485290</td>\n",
       "      <td>0.484715</td>\n",
       "      <td>0.808292</td>\n",
       "      <td>0.819124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.390026</td>\n",
       "      <td>0.530201</td>\n",
       "      <td>0.849947</td>\n",
       "      <td>0.811261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.307304</td>\n",
       "      <td>0.569847</td>\n",
       "      <td>0.884712</td>\n",
       "      <td>0.807304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.243646</td>\n",
       "      <td>0.611163</td>\n",
       "      <td>0.911783</td>\n",
       "      <td>0.807745</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Epoch  Train Loss  Val Loss  Train Accuracy  Val Accuracy\n",
       "0      1    0.658302  0.516347        0.715135      0.795632\n",
       "1      2    0.485290  0.484715        0.808292      0.819124\n",
       "2      3    0.390026  0.530201        0.849947      0.811261\n",
       "3      4    0.307304  0.569847        0.884712      0.807304\n",
       "4      5    0.243646  0.611163        0.911783      0.807745"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def generate_epoch_table(model):\n",
    "    \"\"\"\n",
    "    Generate and display a table of training and validation metrics by epoch.\n",
    "    \"\"\"\n",
    "    epochs = range(1, len(model.train_losses_epoch) + 1)\n",
    "\n",
    "    # Créer un DataFrame pour les résultats\n",
    "    results_df = pd.DataFrame({\n",
    "        \"Epoch\": epochs,\n",
    "        \"Train Loss\": model.train_losses_epoch,\n",
    "        \"Val Loss\": model.val_losses_epoch[1:],  # Ignorer la première validation\n",
    "        \"Train Accuracy\": model.train_accuracies_epoch,\n",
    "        \"Val Accuracy\": model.val_accuracies_epoch[1:]  # Ignorer la première validation\n",
    "    })\n",
    "\n",
    "    # Afficher la table\n",
    "    print(\"Training Results by Epoch:\")\n",
    "    return results_df\n",
    "\n",
    "\n",
    "table = generate_epoch_table(pl_camembert)\n",
    "display(table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of Training Results\n",
    "\n",
    "Fine-tuning requires fewer epochs since the model starts with pre-trained weights, focusing on adapting to the specific task rather than learning from scratch. From the results, we observe that the second epoch achieves the best validation accuracy. Beyond this point, the model begins to overfit, as indicated by the increasing training accuracy and declining validation performance.\n",
    "\n",
    "To ensure optimal generalization, we will use the model from the second epoch, which strikes the best balance between training and validation accuracy. Thanks to PyTorch Lightning, this model can be easily retrieved from the saved checkpoints.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Get Test Accuracy Score :\n",
    "\n",
    "Using the same process as for training, we prepare the test dataset to evaluate the final accuracy. The test set consists of 5010 examples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 5010 examples in the test dataset\n"
     ]
    }
   ],
   "source": [
    "xnli_test_dataset = XNLIDataset(split=\"test\", language=\"fr\", cache_directory=data_path, max_length=64)\n",
    "test_loader = DataLoader(xnli_train_dataset, batch_size=256, shuffle=False)\n",
    "print(f\"We have {len(xnli_test_dataset)} examples in the test dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the best model from checkpoints :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "best_checkpoint = '../../../notebooks/trainings/nli_train/checkpoints/nli-epoch=01-val_loss=0.49.ckpt'\n",
    "\n",
    "model = NLI.load_from_checkpoint(best_checkpoint, model=nli_camembert, lr=5e-5)\n",
    "model.eval()\n",
    "print(\"Checkpoint loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.8568\n"
     ]
    }
   ],
   "source": [
    "# Initialize the accuracy metric\n",
    "test_accuracy = Accuracy(task=\"multiclass\", num_classes=3).to(device)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Disable gradient calculations for inference\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        # Move batch data to the same device as the model\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"label\"].to(device)\n",
    "\n",
    "        # Get predictions from the model\n",
    "        logits = model.model(input_ids=input_ids, attention_mask=attention_mask)[\"logits\"]\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "        # Update the accuracy metric\n",
    "        test_accuracy.update(preds, labels)\n",
    "\n",
    "# Compute the final accuracy\n",
    "final_accuracy = test_accuracy.compute().item()\n",
    "print(f\"Final Accuracy: {final_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final accuracy obtained on the test dataset is **85.68%**, which is higher than the reported score of **82.06%** in the paper. This improvement may be attributed to differences in fine-tuning strategies, hyperparameter choices, or pre-processing steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Results\n",
    "\n",
    "The final accuracy obtained on the test dataset is **85.68%**, which is significantly higher than the reported score of **82.06%** in the paper. This discrepancy could be explained by differences in fine-tuning strategies. Specifically, the increase in batch size to 256 and the fine-tuning performed on the full dataset containing over 392,702 examples may have contributed to the improved performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Comments:\n",
    "\n",
    "- We use accuracy as the evaluation metric because the classes in the NLI dataset are balanced, as stated in the dataset documentation on Hugging Face. If this were not the case, alternative metrics like the F1 score or a confusion matrix would be more appropriate.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
