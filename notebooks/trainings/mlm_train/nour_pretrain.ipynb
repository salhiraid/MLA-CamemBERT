{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Napster\\\\Desktop\\\\M2_ISI\\\\MLA\\\\CamemBERT\\\\MLA-CamemBERT'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "os.chdir(os.path.abspath(\"../../../\"))\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. discover the camembert models :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    CamembertForMaskedLM, \n",
    "    CamembertModel, \n",
    "    CamembertForSequenceClassification,\n",
    "    CamembertForMultipleChoice,\n",
    "    CamembertForTokenClassification,\n",
    "    ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CamembertModel(\n",
       "  (embeddings): CamembertEmbeddings(\n",
       "    (word_embeddings): Embedding(32005, 768, padding_idx=1)\n",
       "    (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "    (token_type_embeddings): Embedding(1, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): CamembertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x CamembertLayer(\n",
       "        (attention): CamembertAttention(\n",
       "          (self): CamembertSdpaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): CamembertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): CamembertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): CamembertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): CamembertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CamembertModel.from_pretrained('camembert-base')\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at camembert-base were not used when initializing CamembertForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing CamembertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CamembertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CamembertForMaskedLM(\n",
       "  (roberta): CamembertModel(\n",
       "    (embeddings): CamembertEmbeddings(\n",
       "      (word_embeddings): Embedding(32005, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): CamembertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x CamembertLayer(\n",
       "          (attention): CamembertAttention(\n",
       "            (self): CamembertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): CamembertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): CamembertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): CamembertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lm_head): CamembertLMHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (decoder): Linear(in_features=768, out_features=32005, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlm_model = CamembertForMaskedLM.from_pretrained('camembert-base')\n",
    "mlm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CamembertForSequenceClassification(\n",
       "  (roberta): CamembertModel(\n",
       "    (embeddings): CamembertEmbeddings(\n",
       "      (word_embeddings): Embedding(32005, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): CamembertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x CamembertLayer(\n",
       "          (attention): CamembertAttention(\n",
       "            (self): CamembertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): CamembertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): CamembertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): CamembertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): CamembertClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sequence_classification = CamembertForSequenceClassification.from_pretrained('camembert-base')\n",
    "model_sequence_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of CamembertForMultipleChoice were not initialized from the model checkpoint at camembert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CamembertForMultipleChoice(\n",
       "  (roberta): CamembertModel(\n",
       "    (embeddings): CamembertEmbeddings(\n",
       "      (word_embeddings): Embedding(32005, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): CamembertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x CamembertLayer(\n",
       "          (attention): CamembertAttention(\n",
       "            (self): CamembertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): CamembertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): CamembertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): CamembertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): CamembertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_CamembertForMultipleChoice = CamembertForMultipleChoice.from_pretrained('camembert-base')\n",
    "model_CamembertForMultipleChoice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of CamembertForTokenClassification were not initialized from the model checkpoint at camembert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CamembertForTokenClassification(\n",
       "  (roberta): CamembertModel(\n",
       "    (embeddings): CamembertEmbeddings(\n",
       "      (word_embeddings): Embedding(32005, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): CamembertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x CamembertLayer(\n",
       "          (attention): CamembertAttention(\n",
       "            (self): CamembertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): CamembertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): CamembertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): CamembertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_CamembertForTokenClassification = CamembertForTokenClassification.from_pretrained('camembert-base')\n",
    "model_CamembertForTokenClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. visualise the model's weights :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(model)\n",
    "model.pooler\n",
    "model.named_modules\n",
    "model.encoder\n",
    "model.embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CamembertSdpaSelfAttention(\n",
       "  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.encoder.layer[0].attention.self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings.word_embeddings.weight torch.Size([32005, 768])\n",
      "embeddings.position_embeddings.weight torch.Size([514, 768])\n",
      "embeddings.token_type_embeddings.weight torch.Size([1, 768])\n",
      "embeddings.LayerNorm.weight torch.Size([768])\n",
      "embeddings.LayerNorm.bias torch.Size([768])\n",
      "encoder.layer.0.attention.self.query.weight torch.Size([768, 768])\n",
      "encoder.layer.0.attention.self.query.bias torch.Size([768])\n",
      "encoder.layer.0.attention.self.key.weight torch.Size([768, 768])\n",
      "encoder.layer.0.attention.self.key.bias torch.Size([768])\n",
      "encoder.layer.0.attention.self.value.weight torch.Size([768, 768])\n",
      "encoder.layer.0.attention.self.value.bias torch.Size([768])\n",
      "encoder.layer.0.attention.output.dense.weight torch.Size([768, 768])\n",
      "encoder.layer.0.attention.output.dense.bias torch.Size([768])\n",
      "encoder.layer.0.attention.output.LayerNorm.weight torch.Size([768])\n",
      "encoder.layer.0.attention.output.LayerNorm.bias torch.Size([768])\n",
      "encoder.layer.0.intermediate.dense.weight torch.Size([3072, 768])\n",
      "encoder.layer.0.intermediate.dense.bias torch.Size([3072])\n",
      "encoder.layer.0.output.dense.weight torch.Size([768, 3072])\n",
      "encoder.layer.0.output.dense.bias torch.Size([768])\n",
      "encoder.layer.0.output.LayerNorm.weight torch.Size([768])\n",
      "encoder.layer.0.output.LayerNorm.bias torch.Size([768])\n",
      "encoder.layer.1.attention.self.query.weight torch.Size([768, 768])\n",
      "encoder.layer.1.attention.self.query.bias torch.Size([768])\n",
      "encoder.layer.1.attention.self.key.weight torch.Size([768, 768])\n",
      "encoder.layer.1.attention.self.key.bias torch.Size([768])\n",
      "encoder.layer.1.attention.self.value.weight torch.Size([768, 768])\n",
      "encoder.layer.1.attention.self.value.bias torch.Size([768])\n",
      "encoder.layer.1.attention.output.dense.weight torch.Size([768, 768])\n",
      "encoder.layer.1.attention.output.dense.bias torch.Size([768])\n",
      "encoder.layer.1.attention.output.LayerNorm.weight torch.Size([768])\n",
      "encoder.layer.1.attention.output.LayerNorm.bias torch.Size([768])\n",
      "encoder.layer.1.intermediate.dense.weight torch.Size([3072, 768])\n",
      "encoder.layer.1.intermediate.dense.bias torch.Size([3072])\n",
      "encoder.layer.1.output.dense.weight torch.Size([768, 3072])\n",
      "encoder.layer.1.output.dense.bias torch.Size([768])\n",
      "encoder.layer.1.output.LayerNorm.weight torch.Size([768])\n",
      "encoder.layer.1.output.LayerNorm.bias torch.Size([768])\n",
      "encoder.layer.2.attention.self.query.weight torch.Size([768, 768])\n",
      "encoder.layer.2.attention.self.query.bias torch.Size([768])\n",
      "encoder.layer.2.attention.self.key.weight torch.Size([768, 768])\n",
      "encoder.layer.2.attention.self.key.bias torch.Size([768])\n",
      "encoder.layer.2.attention.self.value.weight torch.Size([768, 768])\n",
      "encoder.layer.2.attention.self.value.bias torch.Size([768])\n",
      "encoder.layer.2.attention.output.dense.weight torch.Size([768, 768])\n",
      "encoder.layer.2.attention.output.dense.bias torch.Size([768])\n",
      "encoder.layer.2.attention.output.LayerNorm.weight torch.Size([768])\n",
      "encoder.layer.2.attention.output.LayerNorm.bias torch.Size([768])\n",
      "encoder.layer.2.intermediate.dense.weight torch.Size([3072, 768])\n",
      "encoder.layer.2.intermediate.dense.bias torch.Size([3072])\n",
      "encoder.layer.2.output.dense.weight torch.Size([768, 3072])\n",
      "encoder.layer.2.output.dense.bias torch.Size([768])\n",
      "encoder.layer.2.output.LayerNorm.weight torch.Size([768])\n",
      "encoder.layer.2.output.LayerNorm.bias torch.Size([768])\n",
      "encoder.layer.3.attention.self.query.weight torch.Size([768, 768])\n",
      "encoder.layer.3.attention.self.query.bias torch.Size([768])\n",
      "encoder.layer.3.attention.self.key.weight torch.Size([768, 768])\n",
      "encoder.layer.3.attention.self.key.bias torch.Size([768])\n",
      "encoder.layer.3.attention.self.value.weight torch.Size([768, 768])\n",
      "encoder.layer.3.attention.self.value.bias torch.Size([768])\n",
      "encoder.layer.3.attention.output.dense.weight torch.Size([768, 768])\n",
      "encoder.layer.3.attention.output.dense.bias torch.Size([768])\n",
      "encoder.layer.3.attention.output.LayerNorm.weight torch.Size([768])\n",
      "encoder.layer.3.attention.output.LayerNorm.bias torch.Size([768])\n",
      "encoder.layer.3.intermediate.dense.weight torch.Size([3072, 768])\n",
      "encoder.layer.3.intermediate.dense.bias torch.Size([3072])\n",
      "encoder.layer.3.output.dense.weight torch.Size([768, 3072])\n",
      "encoder.layer.3.output.dense.bias torch.Size([768])\n",
      "encoder.layer.3.output.LayerNorm.weight torch.Size([768])\n",
      "encoder.layer.3.output.LayerNorm.bias torch.Size([768])\n",
      "encoder.layer.4.attention.self.query.weight torch.Size([768, 768])\n",
      "encoder.layer.4.attention.self.query.bias torch.Size([768])\n",
      "encoder.layer.4.attention.self.key.weight torch.Size([768, 768])\n",
      "encoder.layer.4.attention.self.key.bias torch.Size([768])\n",
      "encoder.layer.4.attention.self.value.weight torch.Size([768, 768])\n",
      "encoder.layer.4.attention.self.value.bias torch.Size([768])\n",
      "encoder.layer.4.attention.output.dense.weight torch.Size([768, 768])\n",
      "encoder.layer.4.attention.output.dense.bias torch.Size([768])\n",
      "encoder.layer.4.attention.output.LayerNorm.weight torch.Size([768])\n",
      "encoder.layer.4.attention.output.LayerNorm.bias torch.Size([768])\n",
      "encoder.layer.4.intermediate.dense.weight torch.Size([3072, 768])\n",
      "encoder.layer.4.intermediate.dense.bias torch.Size([3072])\n",
      "encoder.layer.4.output.dense.weight torch.Size([768, 3072])\n",
      "encoder.layer.4.output.dense.bias torch.Size([768])\n",
      "encoder.layer.4.output.LayerNorm.weight torch.Size([768])\n",
      "encoder.layer.4.output.LayerNorm.bias torch.Size([768])\n",
      "encoder.layer.5.attention.self.query.weight torch.Size([768, 768])\n",
      "encoder.layer.5.attention.self.query.bias torch.Size([768])\n",
      "encoder.layer.5.attention.self.key.weight torch.Size([768, 768])\n",
      "encoder.layer.5.attention.self.key.bias torch.Size([768])\n",
      "encoder.layer.5.attention.self.value.weight torch.Size([768, 768])\n",
      "encoder.layer.5.attention.self.value.bias torch.Size([768])\n",
      "encoder.layer.5.attention.output.dense.weight torch.Size([768, 768])\n",
      "encoder.layer.5.attention.output.dense.bias torch.Size([768])\n",
      "encoder.layer.5.attention.output.LayerNorm.weight torch.Size([768])\n",
      "encoder.layer.5.attention.output.LayerNorm.bias torch.Size([768])\n",
      "encoder.layer.5.intermediate.dense.weight torch.Size([3072, 768])\n",
      "encoder.layer.5.intermediate.dense.bias torch.Size([3072])\n",
      "encoder.layer.5.output.dense.weight torch.Size([768, 3072])\n",
      "encoder.layer.5.output.dense.bias torch.Size([768])\n",
      "encoder.layer.5.output.LayerNorm.weight torch.Size([768])\n",
      "encoder.layer.5.output.LayerNorm.bias torch.Size([768])\n",
      "encoder.layer.6.attention.self.query.weight torch.Size([768, 768])\n",
      "encoder.layer.6.attention.self.query.bias torch.Size([768])\n",
      "encoder.layer.6.attention.self.key.weight torch.Size([768, 768])\n",
      "encoder.layer.6.attention.self.key.bias torch.Size([768])\n",
      "encoder.layer.6.attention.self.value.weight torch.Size([768, 768])\n",
      "encoder.layer.6.attention.self.value.bias torch.Size([768])\n",
      "encoder.layer.6.attention.output.dense.weight torch.Size([768, 768])\n",
      "encoder.layer.6.attention.output.dense.bias torch.Size([768])\n",
      "encoder.layer.6.attention.output.LayerNorm.weight torch.Size([768])\n",
      "encoder.layer.6.attention.output.LayerNorm.bias torch.Size([768])\n",
      "encoder.layer.6.intermediate.dense.weight torch.Size([3072, 768])\n",
      "encoder.layer.6.intermediate.dense.bias torch.Size([3072])\n",
      "encoder.layer.6.output.dense.weight torch.Size([768, 3072])\n",
      "encoder.layer.6.output.dense.bias torch.Size([768])\n",
      "encoder.layer.6.output.LayerNorm.weight torch.Size([768])\n",
      "encoder.layer.6.output.LayerNorm.bias torch.Size([768])\n",
      "encoder.layer.7.attention.self.query.weight torch.Size([768, 768])\n",
      "encoder.layer.7.attention.self.query.bias torch.Size([768])\n",
      "encoder.layer.7.attention.self.key.weight torch.Size([768, 768])\n",
      "encoder.layer.7.attention.self.key.bias torch.Size([768])\n",
      "encoder.layer.7.attention.self.value.weight torch.Size([768, 768])\n",
      "encoder.layer.7.attention.self.value.bias torch.Size([768])\n",
      "encoder.layer.7.attention.output.dense.weight torch.Size([768, 768])\n",
      "encoder.layer.7.attention.output.dense.bias torch.Size([768])\n",
      "encoder.layer.7.attention.output.LayerNorm.weight torch.Size([768])\n",
      "encoder.layer.7.attention.output.LayerNorm.bias torch.Size([768])\n",
      "encoder.layer.7.intermediate.dense.weight torch.Size([3072, 768])\n",
      "encoder.layer.7.intermediate.dense.bias torch.Size([3072])\n",
      "encoder.layer.7.output.dense.weight torch.Size([768, 3072])\n",
      "encoder.layer.7.output.dense.bias torch.Size([768])\n",
      "encoder.layer.7.output.LayerNorm.weight torch.Size([768])\n",
      "encoder.layer.7.output.LayerNorm.bias torch.Size([768])\n",
      "encoder.layer.8.attention.self.query.weight torch.Size([768, 768])\n",
      "encoder.layer.8.attention.self.query.bias torch.Size([768])\n",
      "encoder.layer.8.attention.self.key.weight torch.Size([768, 768])\n",
      "encoder.layer.8.attention.self.key.bias torch.Size([768])\n",
      "encoder.layer.8.attention.self.value.weight torch.Size([768, 768])\n",
      "encoder.layer.8.attention.self.value.bias torch.Size([768])\n",
      "encoder.layer.8.attention.output.dense.weight torch.Size([768, 768])\n",
      "encoder.layer.8.attention.output.dense.bias torch.Size([768])\n",
      "encoder.layer.8.attention.output.LayerNorm.weight torch.Size([768])\n",
      "encoder.layer.8.attention.output.LayerNorm.bias torch.Size([768])\n",
      "encoder.layer.8.intermediate.dense.weight torch.Size([3072, 768])\n",
      "encoder.layer.8.intermediate.dense.bias torch.Size([3072])\n",
      "encoder.layer.8.output.dense.weight torch.Size([768, 3072])\n",
      "encoder.layer.8.output.dense.bias torch.Size([768])\n",
      "encoder.layer.8.output.LayerNorm.weight torch.Size([768])\n",
      "encoder.layer.8.output.LayerNorm.bias torch.Size([768])\n",
      "encoder.layer.9.attention.self.query.weight torch.Size([768, 768])\n",
      "encoder.layer.9.attention.self.query.bias torch.Size([768])\n",
      "encoder.layer.9.attention.self.key.weight torch.Size([768, 768])\n",
      "encoder.layer.9.attention.self.key.bias torch.Size([768])\n",
      "encoder.layer.9.attention.self.value.weight torch.Size([768, 768])\n",
      "encoder.layer.9.attention.self.value.bias torch.Size([768])\n",
      "encoder.layer.9.attention.output.dense.weight torch.Size([768, 768])\n",
      "encoder.layer.9.attention.output.dense.bias torch.Size([768])\n",
      "encoder.layer.9.attention.output.LayerNorm.weight torch.Size([768])\n",
      "encoder.layer.9.attention.output.LayerNorm.bias torch.Size([768])\n",
      "encoder.layer.9.intermediate.dense.weight torch.Size([3072, 768])\n",
      "encoder.layer.9.intermediate.dense.bias torch.Size([3072])\n",
      "encoder.layer.9.output.dense.weight torch.Size([768, 3072])\n",
      "encoder.layer.9.output.dense.bias torch.Size([768])\n",
      "encoder.layer.9.output.LayerNorm.weight torch.Size([768])\n",
      "encoder.layer.9.output.LayerNorm.bias torch.Size([768])\n",
      "encoder.layer.10.attention.self.query.weight torch.Size([768, 768])\n",
      "encoder.layer.10.attention.self.query.bias torch.Size([768])\n",
      "encoder.layer.10.attention.self.key.weight torch.Size([768, 768])\n",
      "encoder.layer.10.attention.self.key.bias torch.Size([768])\n",
      "encoder.layer.10.attention.self.value.weight torch.Size([768, 768])\n",
      "encoder.layer.10.attention.self.value.bias torch.Size([768])\n",
      "encoder.layer.10.attention.output.dense.weight torch.Size([768, 768])\n",
      "encoder.layer.10.attention.output.dense.bias torch.Size([768])\n",
      "encoder.layer.10.attention.output.LayerNorm.weight torch.Size([768])\n",
      "encoder.layer.10.attention.output.LayerNorm.bias torch.Size([768])\n",
      "encoder.layer.10.intermediate.dense.weight torch.Size([3072, 768])\n",
      "encoder.layer.10.intermediate.dense.bias torch.Size([3072])\n",
      "encoder.layer.10.output.dense.weight torch.Size([768, 3072])\n",
      "encoder.layer.10.output.dense.bias torch.Size([768])\n",
      "encoder.layer.10.output.LayerNorm.weight torch.Size([768])\n",
      "encoder.layer.10.output.LayerNorm.bias torch.Size([768])\n",
      "encoder.layer.11.attention.self.query.weight torch.Size([768, 768])\n",
      "encoder.layer.11.attention.self.query.bias torch.Size([768])\n",
      "encoder.layer.11.attention.self.key.weight torch.Size([768, 768])\n",
      "encoder.layer.11.attention.self.key.bias torch.Size([768])\n",
      "encoder.layer.11.attention.self.value.weight torch.Size([768, 768])\n",
      "encoder.layer.11.attention.self.value.bias torch.Size([768])\n",
      "encoder.layer.11.attention.output.dense.weight torch.Size([768, 768])\n",
      "encoder.layer.11.attention.output.dense.bias torch.Size([768])\n",
      "encoder.layer.11.attention.output.LayerNorm.weight torch.Size([768])\n",
      "encoder.layer.11.attention.output.LayerNorm.bias torch.Size([768])\n",
      "encoder.layer.11.intermediate.dense.weight torch.Size([3072, 768])\n",
      "encoder.layer.11.intermediate.dense.bias torch.Size([3072])\n",
      "encoder.layer.11.output.dense.weight torch.Size([768, 3072])\n",
      "encoder.layer.11.output.dense.bias torch.Size([768])\n",
      "encoder.layer.11.output.LayerNorm.weight torch.Size([768])\n",
      "encoder.layer.11.output.LayerNorm.bias torch.Size([768])\n",
      "pooler.dense.weight torch.Size([768, 768])\n",
      "pooler.dense.bias torch.Size([768])\n"
     ]
    }
   ],
   "source": [
    "for name, params in model.named_parameters():\n",
    "    print(name, params.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. save the model's weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.state_dict donne un dictionnaire avec tous modules comme clés et les poids comme valeurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['embeddings.word_embeddings.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.LayerNorm.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.LayerNorm.bias', 'pooler.dense.weight', 'pooler.dense.bias'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([32005, 768])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model.state_dict().keys())\n",
    "LIST = list(model.state_dict().values())\n",
    "LIST[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.save(model.state_dict(), 'camembert-base.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Napster\\AppData\\Local\\Temp\\ipykernel_10356\\2577785934.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load('camembert-base.pth')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict = torch.load('camembert-base.pth')\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "number of parameters :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 110621952\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Randomly initialise the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "def init_weights(module):\n",
    "    if isinstance(module, (nn.Linear, nn.Embedding)):\n",
    "        print(f\"Initializing {module.__class__.__name__} with Xavier Uniform\")\n",
    "        nn.init.xavier_uniform_(module.weight)\n",
    "    elif isinstance(module, nn.LayerNorm):\n",
    "        print(f\"Initializing {module.__class__.__name__} with Constant Weights\")\n",
    "        nn.init.constant_(module.bias, 0)\n",
    "        nn.init.constant_(module.weight, 1)\n",
    "    if hasattr(module, 'bias') and module.bias is not None:\n",
    "        print(f\"Initializing Bias for {module.__class__.__name__}\")\n",
    "        nn.init.constant_(module.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at camembert-base were not used when initializing CamembertForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing CamembertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CamembertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0574,  0.0302,  0.0032,  ...,  0.1065,  0.0107, -0.0412],\n",
      "        [ 0.0034, -0.0558, -0.0055,  ..., -0.0320, -0.0056, -0.0277],\n",
      "        [-0.0134,  0.1370,  0.0675,  ...,  0.0010,  0.0781,  0.0418],\n",
      "        ...,\n",
      "        [-0.0314,  0.1143,  0.0729,  ...,  0.0191,  0.1501, -0.1471],\n",
      "        [-0.1260, -0.1190, -0.0851,  ..., -0.1236,  0.0079, -0.1979],\n",
      "        [ 0.0143, -0.0271,  0.0035,  ..., -0.0069,  0.0107, -0.0072]],\n",
      "       requires_grad=True)\n",
      "\n",
      "Parameter containing:\n",
      "tensor([[-0.0574,  0.0302,  0.0032,  ...,  0.1065,  0.0107, -0.0412],\n",
      "        [ 0.0034, -0.0558, -0.0055,  ..., -0.0320, -0.0056, -0.0277],\n",
      "        [-0.0134,  0.1370,  0.0675,  ...,  0.0010,  0.0781,  0.0418],\n",
      "        ...,\n",
      "        [-0.0314,  0.1143,  0.0729,  ...,  0.0191,  0.1501, -0.1471],\n",
      "        [-0.1260, -0.1190, -0.0851,  ..., -0.1236,  0.0079, -0.1979],\n",
      "        [ 0.0143, -0.0271,  0.0035,  ..., -0.0069,  0.0107, -0.0072]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "mlm_model = CamembertForMaskedLM.from_pretrained('camembert-base')\n",
    "\n",
    "mlm_model\n",
    "print(mlm_model.lm_head.decoder.weight)\n",
    "print()\n",
    "print(mlm_model.roberta.embeddings.word_embeddings.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Embedding with Xavier Uniform\n",
      "Initializing Embedding with Xavier Uniform\n",
      "Initializing Embedding with Xavier Uniform\n",
      "Initializing LayerNorm with Constant Weights\n",
      "Initializing Bias for LayerNorm\n",
      "Initializing Linear with Xavier Uniform\n",
      "Initializing Bias for Linear\n",
      "Initializing Linear with Xavier Uniform\n",
      "Initializing Bias for Linear\n",
      "Initializing Linear with Xavier Uniform\n",
      "Initializing Bias for Linear\n",
      "Initializing Linear with Xavier Uniform\n",
      "Initializing Bias for Linear\n",
      "Initializing LayerNorm with Constant Weights\n",
      "Initializing Bias for LayerNorm\n",
      "Initializing Linear with Xavier Uniform\n",
      "Initializing Bias for Linear\n",
      "Initializing Linear with Xavier Uniform\n",
      "Initializing Bias for Linear\n",
      "Initializing LayerNorm with Constant Weights\n",
      "Initializing Bias for LayerNorm\n",
      "Initializing Linear with Xavier Uniform\n",
      "Initializing Bias for Linear\n",
      "Initializing Linear with Xavier Uniform\n",
      "Initializing Bias for Linear\n",
      "Initializing Linear with Xavier Uniform\n",
      "Initializing Bias for Linear\n",
      "Initializing Linear with Xavier Uniform\n",
      "Initializing Bias for Linear\n",
      "Initializing LayerNorm with Constant Weights\n",
      "Initializing Bias for LayerNorm\n",
      "Initializing Linear with Xavier Uniform\n",
      "Initializing Bias for Linear\n",
      "Initializing Linear with Xavier Uniform\n",
      "Initializing Bias for Linear\n",
      "Initializing LayerNorm with Constant Weights\n",
      "Initializing Bias for LayerNorm\n",
      "Initializing Linear with Xavier Uniform\n",
      "Initializing Bias for Linear\n",
      "Initializing Linear with Xavier Uniform\n",
      "Initializing Bias for Linear\n",
      "Initializing Linear with Xavier Uniform\n",
      "Initializing Bias for Linear\n",
      "Initializing Linear with Xavier Uniform\n",
      "Initializing Bias for Linear\n",
      "Initializing LayerNorm with Constant Weights\n",
      "Initializing Bias for LayerNorm\n",
      "Initializing Linear with Xavier Uniform\n",
      "Initializing Bias for Linear\n",
      "Initializing Linear with Xavier Uniform\n",
      "Initializing Bias for Linear\n",
      "Initializing LayerNorm with Constant Weights\n",
      "Initializing Bias for LayerNorm\n",
      "Initializing Linear with Xavier Uniform\n",
      "Initializing Bias for Linear\n",
      "Initializing Linear with Xavier Uniform\n",
      "Initializing Bias for Linear\n",
      "Initializing Linear with Xavier Uniform\n",
      "Initializing Bias for Linear\n",
      "Initializing Linear with Xavier Uniform\n",
      "Initializing Bias for Linear\n",
      "Initializing LayerNorm with Constant Weights\n",
      "Initializing Bias for LayerNorm\n",
      "Initializing Linear with Xavier Uniform\n",
      "Initializing Bias for Linear\n",
      "Initializing Linear with Xavier Uniform\n",
      "Initializing Bias for Linear\n",
      "Initializing LayerNorm with Constant Weights\n",
      "Initializing Bias for LayerNorm\n",
      "Initializing Linear with Xavier Uniform\n",
      "Initializing Bias for Linear\n",
      "Initializing Linear with Xavier Uniform\n",
      "Initializing Bias for Linear\n",
      "Initializing Linear with Xavier Uniform\n",
      "Initializing Bias for Linear\n",
      "Initializing Linear with Xavier Uniform\n",
      "Initializing Bias for Linear\n",
      "Initializing LayerNorm with Constant Weights\n",
      "Initializing Bias for LayerNorm\n",
      "Initializing Linear with Xavier Uniform\n",
      "Initializing Bias for Linear\n",
      "Initializing Linear with Xavier Uniform\n",
      "Initializing Bias for Linear\n",
      "Initializing LayerNorm with Constant Weights\n",
      "Initializing Bias for LayerNorm\n",
      "Initializing Linear with Xavier Uniform\n",
      "Initializing Bias for Linear\n",
      "Initializing Linear with Xavier Uniform\n",
      "Initializing Bias for Linear\n",
      "Initializing Linear with Xavier Uniform\n",
      "Initializing Bias for Linear\n",
      "Initializing Linear with Xavier Uniform\n",
      "Initializing Bias for Linear\n",
      "Initializing LayerNorm with Constant Weights\n",
      "Initializing Bias for LayerNorm\n",
      "Initializing Linear with Xavier Uniform\n",
      "Initializing Bias for Linear\n",
      "Initializing Linear with Xavier Uniform\n",
      "Initializing Bias for Linear\n",
      "Initializing LayerNorm with Constant Weights\n",
      "Initializing Bias for LayerNorm\n",
      "Initializing Linear with Xavier Uniform\n",
      "Initializing Bias for Linear\n",
      "Initializing Linear with Xavier Uniform\n",
      "Initializing Bias for Linear\n",
      "Initializing Linear with Xavier Uniform\n",
      "Initializing Bias for Linear\n",
      "Initializing Linear with Xavier Uniform\n",
      "Initializing Bias for Linear\n",
      "Initializing LayerNorm with Constant Weights\n",
      "Initializing Bias for LayerNorm\n",
      "Initializing Linear with Xavier Uniform\n",
      "Initializing Bias for Linear\n",
      "Initializing Linear with Xavier Uniform\n",
      "Initializing Bias for Linear\n",
      "Initializing LayerNorm with Constant Weights\n",
      "Initializing Bias for LayerNorm\n",
      "Initializing Linear with Xavier Uniform\n",
      "Initializing Bias for Linear\n",
      "Initializing Linear with Xavier Uniform\n",
      "Initializing Bias for Linear\n",
      "Initializing Linear with Xavier Uniform\n",
      "Initializing Bias for Linear\n",
      "Initializing Linear with Xavier Uniform\n",
      "Initializing Bias for Linear\n",
      "Initializing LayerNorm with Constant Weights\n",
      "Initializing Bias for LayerNorm\n",
      "Initializing Linear with Xavier Uniform\n",
      "Initializing Bias for Linear\n",
      "Initializing Linear with Xavier Uniform\n",
      "Initializing Bias for Linear\n",
      "Initializing LayerNorm with Constant Weights\n",
      "Initializing Bias for LayerNorm\n",
      "Initializing Linear with Xavier Uniform\n",
      "Initializing Bias for Linear\n",
      "Initializing Linear with Xavier Uniform\n",
      "Initializing Bias for Linear\n",
      "Initializing Linear with Xavier Uniform\n",
      "Initializing Bias for Linear\n",
      "Initializing Linear with Xavier Uniform\n",
      "Initializing Bias for Linear\n",
      "Initializing LayerNorm with Constant Weights\n",
      "Initializing Bias for LayerNorm\n",
      "Initializing Linear with Xavier Uniform\n",
      "Initializing Bias for Linear\n",
      "Initializing Linear with Xavier Uniform\n",
      "Initializing Bias for Linear\n",
      "Initializing LayerNorm with Constant Weights\n",
      "Initializing Bias for LayerNorm\n",
      "Initializing Linear with Xavier Uniform\n",
      "Initializing Bias for Linear\n",
      "Initializing Linear with Xavier Uniform\n",
      "Initializing Bias for Linear\n",
      "Initializing Linear with Xavier Uniform\n",
      "Initializing Bias for Linear\n",
      "Initializing Linear with Xavier Uniform\n",
      "Initializing Bias for Linear\n",
      "Initializing LayerNorm with Constant Weights\n",
      "Initializing Bias for LayerNorm\n",
      "Initializing Linear with Xavier Uniform\n",
      "Initializing Bias for Linear\n",
      "Initializing Linear with Xavier Uniform\n",
      "Initializing Bias for Linear\n",
      "Initializing LayerNorm with Constant Weights\n",
      "Initializing Bias for LayerNorm\n",
      "Initializing Linear with Xavier Uniform\n",
      "Initializing Bias for Linear\n",
      "Initializing Linear with Xavier Uniform\n",
      "Initializing Bias for Linear\n",
      "Initializing Linear with Xavier Uniform\n",
      "Initializing Bias for Linear\n",
      "Initializing Linear with Xavier Uniform\n",
      "Initializing Bias for Linear\n",
      "Initializing LayerNorm with Constant Weights\n",
      "Initializing Bias for LayerNorm\n",
      "Initializing Linear with Xavier Uniform\n",
      "Initializing Bias for Linear\n",
      "Initializing Linear with Xavier Uniform\n",
      "Initializing Bias for Linear\n",
      "Initializing LayerNorm with Constant Weights\n",
      "Initializing Bias for LayerNorm\n",
      "Initializing Linear with Xavier Uniform\n",
      "Initializing Bias for Linear\n",
      "Initializing Linear with Xavier Uniform\n",
      "Initializing Bias for Linear\n",
      "Initializing Linear with Xavier Uniform\n",
      "Initializing Bias for Linear\n",
      "Initializing Linear with Xavier Uniform\n",
      "Initializing Bias for Linear\n",
      "Initializing LayerNorm with Constant Weights\n",
      "Initializing Bias for LayerNorm\n",
      "Initializing Linear with Xavier Uniform\n",
      "Initializing Bias for Linear\n",
      "Initializing Linear with Xavier Uniform\n",
      "Initializing Bias for Linear\n",
      "Initializing LayerNorm with Constant Weights\n",
      "Initializing Bias for LayerNorm\n",
      "Initializing Linear with Xavier Uniform\n",
      "Initializing Bias for Linear\n",
      "Parameter containing:\n",
      "tensor([[-0.0574,  0.0302,  0.0032,  ...,  0.1065,  0.0107, -0.0412],\n",
      "        [ 0.0034, -0.0558, -0.0055,  ..., -0.0320, -0.0056, -0.0277],\n",
      "        [-0.0134,  0.1370,  0.0675,  ...,  0.0010,  0.0781,  0.0418],\n",
      "        ...,\n",
      "        [-0.0314,  0.1143,  0.0729,  ...,  0.0191,  0.1501, -0.1471],\n",
      "        [-0.1260, -0.1190, -0.0851,  ..., -0.1236,  0.0079, -0.1979],\n",
      "        [ 0.0143, -0.0271,  0.0035,  ..., -0.0069,  0.0107, -0.0072]],\n",
      "       requires_grad=True)\n",
      "\n",
      "Parameter containing:\n",
      "tensor([[-0.0574,  0.0302,  0.0032,  ...,  0.1065,  0.0107, -0.0412],\n",
      "        [ 0.0034, -0.0558, -0.0055,  ..., -0.0320, -0.0056, -0.0277],\n",
      "        [-0.0134,  0.1370,  0.0675,  ...,  0.0010,  0.0781,  0.0418],\n",
      "        ...,\n",
      "        [-0.0314,  0.1143,  0.0729,  ...,  0.0191,  0.1501, -0.1471],\n",
      "        [-0.1260, -0.1190, -0.0851,  ..., -0.1236,  0.0079, -0.1979],\n",
      "        [ 0.0143, -0.0271,  0.0035,  ..., -0.0069,  0.0107, -0.0072]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "model.apply(init_weights)\n",
    "print(mlm_model.lm_head.decoder.weight)\n",
    "print()\n",
    "print(mlm_model.roberta.embeddings.word_embeddings.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at camembert-base were not used when initializing CamembertForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing CamembertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CamembertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre total de modules : 202\n",
      "Nombre de modules modifiés : 76\n",
      "\n",
      "roberta.embeddings.word_embeddings.weight: Changed\n",
      "roberta.embeddings.position_embeddings.weight: Changed\n",
      "roberta.embeddings.token_type_embeddings.weight: Changed\n",
      "roberta.embeddings.LayerNorm.weight: Unchanged\n",
      "roberta.embeddings.LayerNorm.bias: Unchanged\n",
      "roberta.encoder.layer.0.attention.self.query.weight: Changed\n",
      "roberta.encoder.layer.0.attention.self.query.bias: Unchanged\n",
      "roberta.encoder.layer.0.attention.self.key.weight: Changed\n",
      "roberta.encoder.layer.0.attention.self.key.bias: Unchanged\n",
      "roberta.encoder.layer.0.attention.self.value.weight: Changed\n",
      "roberta.encoder.layer.0.attention.self.value.bias: Unchanged\n",
      "roberta.encoder.layer.0.attention.output.dense.weight: Changed\n",
      "roberta.encoder.layer.0.attention.output.dense.bias: Unchanged\n",
      "roberta.encoder.layer.0.attention.output.LayerNorm.weight: Unchanged\n",
      "roberta.encoder.layer.0.attention.output.LayerNorm.bias: Unchanged\n",
      "roberta.encoder.layer.0.intermediate.dense.weight: Changed\n",
      "roberta.encoder.layer.0.intermediate.dense.bias: Unchanged\n",
      "roberta.encoder.layer.0.output.dense.weight: Changed\n",
      "roberta.encoder.layer.0.output.dense.bias: Unchanged\n",
      "roberta.encoder.layer.0.output.LayerNorm.weight: Unchanged\n",
      "roberta.encoder.layer.0.output.LayerNorm.bias: Unchanged\n",
      "roberta.encoder.layer.1.attention.self.query.weight: Changed\n",
      "roberta.encoder.layer.1.attention.self.query.bias: Unchanged\n",
      "roberta.encoder.layer.1.attention.self.key.weight: Changed\n",
      "roberta.encoder.layer.1.attention.self.key.bias: Unchanged\n",
      "roberta.encoder.layer.1.attention.self.value.weight: Changed\n",
      "roberta.encoder.layer.1.attention.self.value.bias: Unchanged\n",
      "roberta.encoder.layer.1.attention.output.dense.weight: Changed\n",
      "roberta.encoder.layer.1.attention.output.dense.bias: Unchanged\n",
      "roberta.encoder.layer.1.attention.output.LayerNorm.weight: Unchanged\n",
      "roberta.encoder.layer.1.attention.output.LayerNorm.bias: Unchanged\n",
      "roberta.encoder.layer.1.intermediate.dense.weight: Changed\n",
      "roberta.encoder.layer.1.intermediate.dense.bias: Unchanged\n",
      "roberta.encoder.layer.1.output.dense.weight: Changed\n",
      "roberta.encoder.layer.1.output.dense.bias: Unchanged\n",
      "roberta.encoder.layer.1.output.LayerNorm.weight: Unchanged\n",
      "roberta.encoder.layer.1.output.LayerNorm.bias: Unchanged\n",
      "roberta.encoder.layer.2.attention.self.query.weight: Changed\n",
      "roberta.encoder.layer.2.attention.self.query.bias: Unchanged\n",
      "roberta.encoder.layer.2.attention.self.key.weight: Changed\n",
      "roberta.encoder.layer.2.attention.self.key.bias: Unchanged\n",
      "roberta.encoder.layer.2.attention.self.value.weight: Changed\n",
      "roberta.encoder.layer.2.attention.self.value.bias: Unchanged\n",
      "roberta.encoder.layer.2.attention.output.dense.weight: Changed\n",
      "roberta.encoder.layer.2.attention.output.dense.bias: Unchanged\n",
      "roberta.encoder.layer.2.attention.output.LayerNorm.weight: Unchanged\n",
      "roberta.encoder.layer.2.attention.output.LayerNorm.bias: Unchanged\n",
      "roberta.encoder.layer.2.intermediate.dense.weight: Changed\n",
      "roberta.encoder.layer.2.intermediate.dense.bias: Unchanged\n",
      "roberta.encoder.layer.2.output.dense.weight: Changed\n",
      "roberta.encoder.layer.2.output.dense.bias: Unchanged\n",
      "roberta.encoder.layer.2.output.LayerNorm.weight: Unchanged\n",
      "roberta.encoder.layer.2.output.LayerNorm.bias: Unchanged\n",
      "roberta.encoder.layer.3.attention.self.query.weight: Changed\n",
      "roberta.encoder.layer.3.attention.self.query.bias: Unchanged\n",
      "roberta.encoder.layer.3.attention.self.key.weight: Changed\n",
      "roberta.encoder.layer.3.attention.self.key.bias: Unchanged\n",
      "roberta.encoder.layer.3.attention.self.value.weight: Changed\n",
      "roberta.encoder.layer.3.attention.self.value.bias: Unchanged\n",
      "roberta.encoder.layer.3.attention.output.dense.weight: Changed\n",
      "roberta.encoder.layer.3.attention.output.dense.bias: Unchanged\n",
      "roberta.encoder.layer.3.attention.output.LayerNorm.weight: Unchanged\n",
      "roberta.encoder.layer.3.attention.output.LayerNorm.bias: Unchanged\n",
      "roberta.encoder.layer.3.intermediate.dense.weight: Changed\n",
      "roberta.encoder.layer.3.intermediate.dense.bias: Unchanged\n",
      "roberta.encoder.layer.3.output.dense.weight: Changed\n",
      "roberta.encoder.layer.3.output.dense.bias: Unchanged\n",
      "roberta.encoder.layer.3.output.LayerNorm.weight: Unchanged\n",
      "roberta.encoder.layer.3.output.LayerNorm.bias: Unchanged\n",
      "roberta.encoder.layer.4.attention.self.query.weight: Changed\n",
      "roberta.encoder.layer.4.attention.self.query.bias: Unchanged\n",
      "roberta.encoder.layer.4.attention.self.key.weight: Changed\n",
      "roberta.encoder.layer.4.attention.self.key.bias: Unchanged\n",
      "roberta.encoder.layer.4.attention.self.value.weight: Changed\n",
      "roberta.encoder.layer.4.attention.self.value.bias: Unchanged\n",
      "roberta.encoder.layer.4.attention.output.dense.weight: Changed\n",
      "roberta.encoder.layer.4.attention.output.dense.bias: Unchanged\n",
      "roberta.encoder.layer.4.attention.output.LayerNorm.weight: Unchanged\n",
      "roberta.encoder.layer.4.attention.output.LayerNorm.bias: Unchanged\n",
      "roberta.encoder.layer.4.intermediate.dense.weight: Changed\n",
      "roberta.encoder.layer.4.intermediate.dense.bias: Unchanged\n",
      "roberta.encoder.layer.4.output.dense.weight: Changed\n",
      "roberta.encoder.layer.4.output.dense.bias: Unchanged\n",
      "roberta.encoder.layer.4.output.LayerNorm.weight: Unchanged\n",
      "roberta.encoder.layer.4.output.LayerNorm.bias: Unchanged\n",
      "roberta.encoder.layer.5.attention.self.query.weight: Changed\n",
      "roberta.encoder.layer.5.attention.self.query.bias: Unchanged\n",
      "roberta.encoder.layer.5.attention.self.key.weight: Changed\n",
      "roberta.encoder.layer.5.attention.self.key.bias: Unchanged\n",
      "roberta.encoder.layer.5.attention.self.value.weight: Changed\n",
      "roberta.encoder.layer.5.attention.self.value.bias: Unchanged\n",
      "roberta.encoder.layer.5.attention.output.dense.weight: Changed\n",
      "roberta.encoder.layer.5.attention.output.dense.bias: Unchanged\n",
      "roberta.encoder.layer.5.attention.output.LayerNorm.weight: Unchanged\n",
      "roberta.encoder.layer.5.attention.output.LayerNorm.bias: Unchanged\n",
      "roberta.encoder.layer.5.intermediate.dense.weight: Changed\n",
      "roberta.encoder.layer.5.intermediate.dense.bias: Unchanged\n",
      "roberta.encoder.layer.5.output.dense.weight: Changed\n",
      "roberta.encoder.layer.5.output.dense.bias: Unchanged\n",
      "roberta.encoder.layer.5.output.LayerNorm.weight: Unchanged\n",
      "roberta.encoder.layer.5.output.LayerNorm.bias: Unchanged\n",
      "roberta.encoder.layer.6.attention.self.query.weight: Changed\n",
      "roberta.encoder.layer.6.attention.self.query.bias: Unchanged\n",
      "roberta.encoder.layer.6.attention.self.key.weight: Changed\n",
      "roberta.encoder.layer.6.attention.self.key.bias: Unchanged\n",
      "roberta.encoder.layer.6.attention.self.value.weight: Changed\n",
      "roberta.encoder.layer.6.attention.self.value.bias: Unchanged\n",
      "roberta.encoder.layer.6.attention.output.dense.weight: Changed\n",
      "roberta.encoder.layer.6.attention.output.dense.bias: Unchanged\n",
      "roberta.encoder.layer.6.attention.output.LayerNorm.weight: Unchanged\n",
      "roberta.encoder.layer.6.attention.output.LayerNorm.bias: Unchanged\n",
      "roberta.encoder.layer.6.intermediate.dense.weight: Changed\n",
      "roberta.encoder.layer.6.intermediate.dense.bias: Unchanged\n",
      "roberta.encoder.layer.6.output.dense.weight: Changed\n",
      "roberta.encoder.layer.6.output.dense.bias: Unchanged\n",
      "roberta.encoder.layer.6.output.LayerNorm.weight: Unchanged\n",
      "roberta.encoder.layer.6.output.LayerNorm.bias: Unchanged\n",
      "roberta.encoder.layer.7.attention.self.query.weight: Changed\n",
      "roberta.encoder.layer.7.attention.self.query.bias: Unchanged\n",
      "roberta.encoder.layer.7.attention.self.key.weight: Changed\n",
      "roberta.encoder.layer.7.attention.self.key.bias: Unchanged\n",
      "roberta.encoder.layer.7.attention.self.value.weight: Changed\n",
      "roberta.encoder.layer.7.attention.self.value.bias: Unchanged\n",
      "roberta.encoder.layer.7.attention.output.dense.weight: Changed\n",
      "roberta.encoder.layer.7.attention.output.dense.bias: Unchanged\n",
      "roberta.encoder.layer.7.attention.output.LayerNorm.weight: Unchanged\n",
      "roberta.encoder.layer.7.attention.output.LayerNorm.bias: Unchanged\n",
      "roberta.encoder.layer.7.intermediate.dense.weight: Changed\n",
      "roberta.encoder.layer.7.intermediate.dense.bias: Unchanged\n",
      "roberta.encoder.layer.7.output.dense.weight: Changed\n",
      "roberta.encoder.layer.7.output.dense.bias: Unchanged\n",
      "roberta.encoder.layer.7.output.LayerNorm.weight: Unchanged\n",
      "roberta.encoder.layer.7.output.LayerNorm.bias: Unchanged\n",
      "roberta.encoder.layer.8.attention.self.query.weight: Changed\n",
      "roberta.encoder.layer.8.attention.self.query.bias: Unchanged\n",
      "roberta.encoder.layer.8.attention.self.key.weight: Changed\n",
      "roberta.encoder.layer.8.attention.self.key.bias: Unchanged\n",
      "roberta.encoder.layer.8.attention.self.value.weight: Changed\n",
      "roberta.encoder.layer.8.attention.self.value.bias: Unchanged\n",
      "roberta.encoder.layer.8.attention.output.dense.weight: Changed\n",
      "roberta.encoder.layer.8.attention.output.dense.bias: Unchanged\n",
      "roberta.encoder.layer.8.attention.output.LayerNorm.weight: Unchanged\n",
      "roberta.encoder.layer.8.attention.output.LayerNorm.bias: Unchanged\n",
      "roberta.encoder.layer.8.intermediate.dense.weight: Changed\n",
      "roberta.encoder.layer.8.intermediate.dense.bias: Unchanged\n",
      "roberta.encoder.layer.8.output.dense.weight: Changed\n",
      "roberta.encoder.layer.8.output.dense.bias: Unchanged\n",
      "roberta.encoder.layer.8.output.LayerNorm.weight: Unchanged\n",
      "roberta.encoder.layer.8.output.LayerNorm.bias: Unchanged\n",
      "roberta.encoder.layer.9.attention.self.query.weight: Changed\n",
      "roberta.encoder.layer.9.attention.self.query.bias: Unchanged\n",
      "roberta.encoder.layer.9.attention.self.key.weight: Changed\n",
      "roberta.encoder.layer.9.attention.self.key.bias: Unchanged\n",
      "roberta.encoder.layer.9.attention.self.value.weight: Changed\n",
      "roberta.encoder.layer.9.attention.self.value.bias: Unchanged\n",
      "roberta.encoder.layer.9.attention.output.dense.weight: Changed\n",
      "roberta.encoder.layer.9.attention.output.dense.bias: Unchanged\n",
      "roberta.encoder.layer.9.attention.output.LayerNorm.weight: Unchanged\n",
      "roberta.encoder.layer.9.attention.output.LayerNorm.bias: Unchanged\n",
      "roberta.encoder.layer.9.intermediate.dense.weight: Changed\n",
      "roberta.encoder.layer.9.intermediate.dense.bias: Unchanged\n",
      "roberta.encoder.layer.9.output.dense.weight: Changed\n",
      "roberta.encoder.layer.9.output.dense.bias: Unchanged\n",
      "roberta.encoder.layer.9.output.LayerNorm.weight: Unchanged\n",
      "roberta.encoder.layer.9.output.LayerNorm.bias: Unchanged\n",
      "roberta.encoder.layer.10.attention.self.query.weight: Changed\n",
      "roberta.encoder.layer.10.attention.self.query.bias: Unchanged\n",
      "roberta.encoder.layer.10.attention.self.key.weight: Changed\n",
      "roberta.encoder.layer.10.attention.self.key.bias: Unchanged\n",
      "roberta.encoder.layer.10.attention.self.value.weight: Changed\n",
      "roberta.encoder.layer.10.attention.self.value.bias: Unchanged\n",
      "roberta.encoder.layer.10.attention.output.dense.weight: Changed\n",
      "roberta.encoder.layer.10.attention.output.dense.bias: Unchanged\n",
      "roberta.encoder.layer.10.attention.output.LayerNorm.weight: Unchanged\n",
      "roberta.encoder.layer.10.attention.output.LayerNorm.bias: Unchanged\n",
      "roberta.encoder.layer.10.intermediate.dense.weight: Changed\n",
      "roberta.encoder.layer.10.intermediate.dense.bias: Unchanged\n",
      "roberta.encoder.layer.10.output.dense.weight: Changed\n",
      "roberta.encoder.layer.10.output.dense.bias: Unchanged\n",
      "roberta.encoder.layer.10.output.LayerNorm.weight: Unchanged\n",
      "roberta.encoder.layer.10.output.LayerNorm.bias: Unchanged\n",
      "roberta.encoder.layer.11.attention.self.query.weight: Changed\n",
      "roberta.encoder.layer.11.attention.self.query.bias: Unchanged\n",
      "roberta.encoder.layer.11.attention.self.key.weight: Changed\n",
      "roberta.encoder.layer.11.attention.self.key.bias: Unchanged\n",
      "roberta.encoder.layer.11.attention.self.value.weight: Changed\n",
      "roberta.encoder.layer.11.attention.self.value.bias: Unchanged\n",
      "roberta.encoder.layer.11.attention.output.dense.weight: Changed\n",
      "roberta.encoder.layer.11.attention.output.dense.bias: Unchanged\n",
      "roberta.encoder.layer.11.attention.output.LayerNorm.weight: Unchanged\n",
      "roberta.encoder.layer.11.attention.output.LayerNorm.bias: Unchanged\n",
      "roberta.encoder.layer.11.intermediate.dense.weight: Changed\n",
      "roberta.encoder.layer.11.intermediate.dense.bias: Unchanged\n",
      "roberta.encoder.layer.11.output.dense.weight: Changed\n",
      "roberta.encoder.layer.11.output.dense.bias: Unchanged\n",
      "roberta.encoder.layer.11.output.LayerNorm.weight: Unchanged\n",
      "roberta.encoder.layer.11.output.LayerNorm.bias: Unchanged\n",
      "lm_head.bias: Unchanged\n",
      "lm_head.dense.weight: Changed\n",
      "lm_head.dense.bias: Unchanged\n",
      "lm_head.layer_norm.weight: Unchanged\n",
      "lm_head.layer_norm.bias: Unchanged\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from transformers import CamembertForMaskedLM\n",
    "\n",
    "# Fonction d'initialisation des poids\n",
    "def init_weights(module):\n",
    "    if isinstance(module, (nn.Linear, nn.Embedding)):\n",
    "        nn.init.xavier_uniform_(module.weight)\n",
    "    elif isinstance(module, nn.LayerNorm):\n",
    "        nn.init.constant_(module.bias, 0)\n",
    "        nn.init.constant_(module.weight, 1)\n",
    "    if hasattr(module, 'bias') and module.bias is not None:\n",
    "        nn.init.constant_(module.bias, 0)\n",
    "\n",
    "# Fonction pour comparer les poids avant et après réinitialisation\n",
    "def compare_weights(model, init_func):\n",
    "    # Stocker les poids initiaux\n",
    "    initial_weights = {name: param.clone() for name, param in model.named_parameters()}\n",
    "    \n",
    "    # Appliquer la fonction d'initialisation\n",
    "    model.apply(init_func)\n",
    "    \n",
    "    # Comparer les poids après réinitialisation\n",
    "    weight_comparison = {}\n",
    "    changed_count = 0\n",
    "    \n",
    "    for name, param in model.named_parameters():\n",
    "        changed = not torch.equal(initial_weights[name], param)\n",
    "        weight_comparison[name] = changed\n",
    "        if changed:\n",
    "            changed_count += 1\n",
    "    \n",
    "    return weight_comparison, changed_count\n",
    "\n",
    "# Charger le modèle Hugging Face\n",
    "from transformers import CamembertForMaskedLM\n",
    "model = CamembertForMaskedLM.from_pretrained(\"camembert-base\")\n",
    "model.apply(init_weights)\n",
    "\n",
    "# Comparer les poids\n",
    "comparison_results, changed_count = compare_weights(model, init_weights)\n",
    "\n",
    "# Afficher les résultats\n",
    "print(f\"Nombre total de modules : {len(comparison_results)}\")\n",
    "print(f\"Nombre de modules modifiés : {changed_count}\\n\")\n",
    "\n",
    "for name, changed in comparison_results.items():\n",
    "    print(f\"{name}: {'Changed' if changed else 'Unchanged'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle   \n",
    "from datasets import load_from_disk\n",
    "from transformers import CamembertTokenizer\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the mask token function :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_tokens(inputs, tokenizer, mlm_probability=0.15):\n",
    "    \"\"\"Prepare masked tokens for MLM.\"\"\"\n",
    "    labels = inputs.clone()\n",
    "    probability_matrix = torch.full(labels.shape, mlm_probability)\n",
    "    special_tokens_mask = [\n",
    "        tokenizer.get_special_tokens_mask(val, already_has_special_tokens=True) for val in labels.tolist()\n",
    "    ]\n",
    "    probability_matrix.masked_fill_(torch.tensor(special_tokens_mask, dtype=torch.bool), value=0.0)\n",
    "    masked_indices = torch.bernoulli(probability_matrix).bool()\n",
    "    labels[~masked_indices] = -100  # We only compute loss on masked tokens\n",
    "\n",
    "    # Replace 80% of masked tokens with [MASK]\n",
    "    indices_replaced = torch.bernoulli(torch.full(labels.shape, 0.8)).bool() & masked_indices\n",
    "    inputs[indices_replaced] = tokenizer.convert_tokens_to_ids(tokenizer.mask_token)\n",
    "\n",
    "    # Replace 10% of masked tokens with random words\n",
    "    indices_random = torch.bernoulli(torch.full(labels.shape, 0.5)).bool() & masked_indices & ~indices_replaced\n",
    "    random_words = torch.randint(len(tokenizer), labels.shape, dtype=torch.long)\n",
    "    inputs[indices_random] = random_words[indices_random]\n",
    "\n",
    "    return inputs, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens avant masquage : ['<s>', '▁Bonjour', '▁tout', '▁le', '▁monde', '.', '▁Comment', '▁ça', '▁va', '▁aujourd', \"'\", 'hui', '▁?', '</s>']\n",
      "Input IDs avant masquage : tensor([   5, 1285,   66,   16,  164,    9,  841,  136,  198,  405,   11,  265,\n",
      "         106,    6])\n",
      "\n",
      "Tokens après masquage : ['<s>', '▁Bonjour', '<mask>', '▁le', '▁monde', '.', '▁Comment', '▁ça', '▁va', '<mask>', \"'\", '<mask>', '<mask>', '</s>']\n",
      "Input IDs après masquage : tensor([    5,  1285, 32004,    16,   164,     9,   841,   136,   198, 32004,\n",
      "           11, 32004, 32004,     6])\n",
      "Labels : tensor([-100, -100,   66, -100, -100, -100, -100, -100, -100,  405, -100,  265,\n",
      "         106, -100])\n"
     ]
    }
   ],
   "source": [
    "tokenizer = CamembertTokenizer.from_pretrained(\"camembert-base\")\n",
    "# Exemple de phrase\n",
    "text = \"Bonjour tout le monde. Comment ça va aujourd'hui ?\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "# Afficher les tokens et les IDs d'entrée\n",
    "print(\"Tokens avant masquage :\", tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0]))\n",
    "print(\"Input IDs avant masquage :\", inputs[\"input_ids\"][0])\n",
    "\n",
    "# Appliquer la fonction de masquage\n",
    "masked_inputs, labels = mask_tokens(inputs[\"input_ids\"], tokenizer)\n",
    "\n",
    "# Afficher les résultats après masquage\n",
    "print(\"\\nTokens après masquage :\", tokenizer.convert_ids_to_tokens(masked_inputs[0]))\n",
    "print(\"Input IDs après masquage :\", masked_inputs[0])\n",
    "print(\"Labels :\", labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " DATA PREPROCESSING :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenized_oscar_dataset(Dataset):\n",
    "    def __init__(self, raw_tokenised_data):\n",
    "        \"\"\"\n",
    "        Initialiser le dataset avec les données sous forme de dictionnaire.\n",
    "        \"\"\"\n",
    "        self.raw_data = raw_tokenised_data  # Le dictionnaire avec 'input_ids', 'attention_mask', et 'labels'\n",
    "        self.data = {\n",
    "            \"texts\": self.raw_data['text'],\n",
    "            \"input_ids\": self.raw_data['input_ids'],\n",
    "            \"attention_mask\": self.raw_data['attention_mask'],\n",
    "            \"labels\": self.raw_data['labels']\n",
    "        }\n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Retourne le nombre d'exemples dans le dataset.\n",
    "        \"\"\"\n",
    "        return len(self.data['input_ids'])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Retourne un exemple individuel sous forme de dictionnaire.\n",
    "        \"\"\"\n",
    "        return {\n",
    "            'input_ids': torch.tensor(self.data['input_ids'][idx], dtype=torch.long),\n",
    "            'attention_mask': torch.tensor(self.data['attention_mask'][idx], dtype=torch.long),\n",
    "            'labels': torch.tensor(self.data['labels'][idx], dtype=torch.long)\n",
    "        }\n",
    "\n",
    "    \n",
    "def mask_tokens(inputs, tokenizer, mlm_probability=0.15):\n",
    "    \"\"\"Prepare masked tokens for MLM.\"\"\"\n",
    "    labels = inputs.clone()\n",
    "    probability_matrix = torch.full(labels.shape, mlm_probability)\n",
    "    special_tokens_mask = [\n",
    "        tokenizer.get_special_tokens_mask(val, already_has_special_tokens=True) for val in labels.tolist()\n",
    "    ]\n",
    "    probability_matrix.masked_fill_(torch.tensor(special_tokens_mask, dtype=torch.bool), value=0.0)\n",
    "    masked_indices = torch.bernoulli(probability_matrix).bool()\n",
    "    labels[~masked_indices] = -100  # We only compute loss on masked tokens\n",
    "\n",
    "    # Replace 80% of masked tokens with [MASK]\n",
    "    indices_replaced = torch.bernoulli(torch.full(labels.shape, 0.8)).bool() & masked_indices\n",
    "    inputs[indices_replaced] = tokenizer.convert_tokens_to_ids(tokenizer.mask_token)\n",
    "\n",
    "    # Replace 10% of masked tokens with random words\n",
    "    indices_random = torch.bernoulli(torch.full(labels.shape, 0.5)).bool() & masked_indices & ~indices_replaced\n",
    "    random_words = torch.randint(len(tokenizer), labels.shape, dtype=torch.long)\n",
    "    inputs[indices_random] = random_words[indices_random]\n",
    "\n",
    "    return inputs, labels\n",
    "\n",
    "# def preprocess_function(examples, tokenizer):\n",
    "#     # Tokeniser les textes\n",
    "#     tokenized = tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "#     print(tokenized.keys()) \n",
    "#     input_ids = tokenized[\"input_ids\"]\n",
    "#     attention_mask = tokenized[\"attention_mask\"]\n",
    "\n",
    "#     # Appliquer le masquage\n",
    "#     masked_inputs, labels = mask_tokens(input_ids, tokenizer)\n",
    "\n",
    "#     return { \n",
    "#         \"input_ids\": masked_inputs.tolist(),\n",
    "#         \"attention_mask\": attention_mask.tolist(),\n",
    "#         \"labels\": labels.tolist()\n",
    "#     }\n",
    "\n",
    "def preprocess_function(texts, tokenizer, max_length=512):\n",
    "    \"\"\"\n",
    "    Préparer les données pour l'entraînement MLM.\n",
    "    :param texts: Liste de textes.\n",
    "    :param tokenizer: Tokenizer de CamemBERT.\n",
    "    :return: Dictionnaire avec 'input_ids', 'attention_mask', et 'labels'.\n",
    "    \"\"\"\n",
    "    # Tokeniser les textes\n",
    "    tokenized = tokenizer(texts, max_length=max_length, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "    input_ids = tokenized[\"input_ids\"]\n",
    "    attention_mask = tokenized[\"attention_mask\"]\n",
    "\n",
    "    # Appliquer le masquage\n",
    "    masked_inputs, labels = mask_tokens(input_ids, tokenizer)\n",
    "\n",
    "    return { \n",
    "        \"text\": list(texts),\n",
    "        \"input_ids\": masked_inputs.tolist(),\n",
    "        \"attention_mask\": attention_mask.tolist(),\n",
    "        \"labels\": labels.tolist()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path =\"data/oscar.Arrow\"\n",
    "mini_oscar_dataset = load_from_disk(dataset_path)\n",
    "train_texts, val_texts = train_test_split(mini_oscar_dataset['text'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = CamembertTokenizer.from_pretrained('camembert-base')\n",
    "tokenized = tokenizer(train_texts, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "len(tokenized['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = preprocess_function(train_texts, tokenizer)\n",
    "val_data = preprocess_function(val_texts, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to data/tokenized_data/tokenized_train_data.pkl\n",
      "Data saved to data/tokenized_data/tokenized_val_data.pkl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "def save_tokenized_data(data, filename):\n",
    "    os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "    with open(filename, \"wb\") as f:\n",
    "        pickle.dump(data, f)\n",
    "\n",
    "save_tokenized_data(train_data, \"data/tokenized_data/tokenized_train_data.pkl\")\n",
    "save_tokenized_data(val_data, \"data/tokenized_data/tokenized_val_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tokenized_data(filename):\n",
    "    with open(filename, \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "    return data\n",
    "\n",
    "train_data = load_tokenized_data(\"data/tokenized_data/tokenized_train_data.pkl\")\n",
    "val_data = load_tokenized_data(\"data/tokenized_data/tokenized_val_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['text', 'input_ids', 'attention_mask', 'labels'])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data['input_ids']))\n",
    "print(len(val_data['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = load_tokenized_data(\"data/tokenized_data/tokenized_train_data.pkl\")\n",
    "val_data = load_tokenized_data(\"data/tokenized_data/tokenized_val_data.pkl\")\n",
    "\n",
    "# Créer les datasets\n",
    "train_dataset = Tokenized_oscar_dataset(train_data)\n",
    "val_dataset = Tokenized_oscar_dataset(val_data)\n",
    "\n",
    "# Créer les DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=8192, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8192, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 512])\n",
      "torch.Size([8, 512])\n",
      "torch.Size([8, 512])\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_loader))\n",
    "print(batch['input_ids'].shape)\n",
    "print(batch['attention_mask'].shape)\n",
    "print(batch['labels'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 8, Validation samples: 2\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training samples: {len(train_texts)}, Validation samples: {len(val_texts)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 10\n",
       "})"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "tokenized_oscar = load_from_disk(\"data/tokenized_oscar.arrow\")\n",
    "tokenized_oscar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 512])\n",
      "torch.Size([10, 512])\n",
      "torch.Size([10, 512])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 8192\n",
    "\n",
    "raw_tokenized_oscar = load_from_disk(\"data/tokenized_oscar.arrow\")\n",
    "tokenized_oscar = Tokenized_oscar_dataset(raw_tokenized_oscar)    \n",
    "train_loader = DataLoader(tokenized_oscar, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "batch = next(iter(train_loader))\n",
    "print(batch['input_ids'].shape)\n",
    "print(batch['attention_mask'].shape)\n",
    "print(batch['labels'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0, step : 0, loss : 8.133624076843262\n",
      "Epoch : 0, step : 1, loss : 8.17203426361084\n",
      "Epoch : 1, step : 0, loss : 7.944967746734619\n",
      "Epoch : 1, step : 1, loss : 7.848634243011475\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 2\n",
    "learning_rate = 1e-4\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "# loss_fn = torch.nn.CrossEntropyLoss(ignore_index=-100)\n",
    "# loss_fn = F.cross_entropy(ignore_index=-100)\n",
    "history = {'train_loss': []}\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_index, batch in enumerate(train_loader):\n",
    "        # 1. prepare data :\n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask = batch['attention_mask']\n",
    "        labels = batch['labels']\n",
    "        # 2. forward pass :\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(input_ids, attention_mask=attention_mask)['logits']\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), labels.view(-1), ignore_index=-100)\n",
    "        # 3. backward pass :\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f\"Epoch : {epoch}, step : {batch_index}, loss : {loss.item()}\")\n",
    "        history['train_loss'].append(loss.item())\n",
    "    \n",
    "    # Save the model after each epoch\n",
    "    torch.save(model.state_dict(), f\"camembert-base-mlm-{epoch}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAHHCAYAAABXx+fLAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAABf2klEQVR4nO3deVhU5fsG8HtmgAFkU1ZRZFVAxLU0cC0RXDK3Fq1vYpbllpmZgfuSmZZLadn2S8ols1xyy0TNFXdBwX0FFxZBEZRtnDm/P5DJEdABZziz3J/r4rqaM+8585zXkW6fOXNeiSAIAoiIiIjMiFTsAoiIiIhqGgMQERERmR0GICIiIjI7DEBERERkdhiAiIiIyOwwABEREZHZYQAiIiIis8MARERERGaHAYiIiIjMDgMQEenFoEGD4OPjU619p06dColEotuC9OTKlSuQSCSIi4sTuxQiqgIGICIzI5FItPrZuXOn2KWKYtCgQbCzs6v0eYlEgpEjRz7163z77bcMTUQishC7ACKqWUuXLtV4/OuvvyI+Pr7c9uDg4Kd6nR9//BEqlapa+06cOBExMTFP9fo1xdvbG4WFhbC0tKzSft9++y1cXFwwaNAg/RRGRI/FAERkZv73v/9pPD5w4ADi4+PLbX9UQUEBbG1ttX6dqgaCh1lYWMDCwjh+PUkkElhbW4tdBgCgqKgIVlZWkErZ3Cd6Ev4tIaJyOnXqhCZNmuDo0aPo0KEDbG1tMX78eADAX3/9hR49esDT0xNyuRz+/v6YMWMGlEqlxjEevQao7FqZL7/8Ej/88AP8/f0hl8vx7LPP4vDhwxr7VnQNUNlHT+vWrUOTJk0gl8sREhKCLVu2lKt/586deOaZZ2BtbQ1/f398//33eruuqKJrgDIyMvDWW2+hfv36kMvlqFu3Lnr16oUrV64AAHx8fHDy5Ens2rVL/ZFjp06d1PtfunQJr7zyCurUqQNbW1s899xz2LRpU7lzlEgkWLlyJSZOnIh69erB1tYWSUlJkEgkmD9/frlaExISIJFI8Ntvv+l8HoiMjXH8E4uIalxOTg66deuG/v3743//+x/c3d0BAHFxcbCzs8OYMWNgZ2eHHTt2YPLkycjLy8MXX3zxxOOuWLEC+fn5eO+99yCRSDBnzhz07dsXly5demLXaO/evVizZg2GDx8Oe3t7fP311+jXrx/S0tLg7OwMAEhMTETXrl1Rt25dTJs2DUqlEtOnT4erq2uVzj87O7tK4x/Wr18/nDx5Eu+//z58fHyQlZWF+Ph4pKWlwcfHBwsWLMD7778POzs7TJgwAQDU85uZmYnw8HAUFBRg1KhRcHZ2xi+//IKXXnoJf/75J/r06aPxWjNmzICVlRXGjh2L4uJiBAUFoW3btli+fDk+/PBDjbHLly+Hvb09evXqVe1zIzIZAhGZtREjRgiP/iro2LGjAED47rvvyo0vKCgot+29994TbG1thaKiIvW26OhowdvbW/348uXLAgDB2dlZuHXrlnr7X3/9JQAQNmzYoN42ZcqUcjUBEKysrIQLFy6otx0/flwAICxcuFC9rWfPnoKtra1w/fp19bbz588LFhYW5Y5ZkejoaAHAY39GjBhR7ryWLFkiCIIg3L59WwAgfPHFF499nZCQEKFjx47lto8ePVoAIOzZs0e9LT8/X/D19RV8fHwEpVIpCIIg/PvvvwIAwc/Pr9yfyffffy8AEE6fPq3eVlJSIri4uAjR0dFPnAMic8CPwIioQnK5HG+99Va57TY2Nur/zs/PR3Z2Ntq3b4+CggKcOXPmicd97bXXULt2bfXj9u3bAyj92OdJIiIi4O/vr37ctGlTODg4qPdVKpXYtm0bevfuDU9PT/W4gIAAdOvW7YnHL2NtbY34+PgKf57ExsYGVlZW2LlzJ27fvq31a5bZvHkzWrdujXbt2qm32dnZ4d1338WVK1dw6tQpjfHR0dEafyYA8Oqrr8La2hrLly9Xb/vnn3+QnZ39xGu9iMwFPwIjogrVq1cPVlZW5bafPHkSEydOxI4dO5CXl6fx3J07d5543AYNGmg8LgtD2oSFR/ct279s36ysLBQWFiIgIKDcuIq2VUYmkyEiIkLr8Q+Ty+WYPXs2PvroI7i7u+O5557Diy++iIEDB8LDw+OJ+6empqJNmzbltpd9Ky81NRVNmjRRb/f19S031snJCT179sSKFSswY8YMAKUff9WrVw8vvPBCtc6LyNSwA0REFXq0qwAAubm56NixI44fP47p06djw4YNiI+Px+zZswFAq6+9y2SyCrcLgqDXfWvS6NGjce7cOcyaNQvW1taYNGkSgoODkZiYqPPXqujPCQAGDhyIS5cuISEhAfn5+Vi/fj0GDBjAb4gRPcAOEBFpbefOncjJycGaNWvQoUMH9fbLly+LWNV/3NzcYG1tjQsXLpR7rqJt+uTv74+PPvoIH330Ec6fP4/mzZtj7ty5WLZsGQBU+o00b29vnD17ttz2so8Xvb29tXr9rl27wtXVFcuXL0ebNm1QUFCAN998s5pnQ2R6+E8BItJaWQfm4Y5LSUkJvv32W7FK0lD20dW6detw48YN9fYLFy7g77//rpEaCgoKUFRUpLHN398f9vb2KC4uVm+rVasWcnNzy+3fvXt3HDp0CPv371dvu3fvHn744Qf4+PigcePGWtVhYWGBAQMGYNWqVYiLi0NoaCiaNm1avZMiMkHsABGR1sLDw1G7dm1ER0dj1KhRkEgkWLp0qUF9BDV16lRs3boVbdu2xbBhw6BUKrFo0SI0adIESUlJen/9c+fOoXPnznj11VfRuHFjWFhYYO3atcjMzET//v3V41q1aoXFixfj008/RUBAANzc3PDCCy8gJiYGv/32G7p164ZRo0ahTp06+OWXX3D58mWsXr26Sh9hDRw4EF9//TX+/fdf9ceURFSKAYiItObs7IyNGzfio48+wsSJE1G7dm3873//Q+fOnREVFSV2eQBKg8Xff/+NsWPHYtKkSfDy8sL06dNx+vRprb6l9rS8vLwwYMAAbN++HUuXLoWFhQWCgoKwatUq9OvXTz1u8uTJSE1NxZw5c5Cfn4+OHTvihRdegLu7OxISEvDJJ59g4cKFKCoqQtOmTbFhwwb06NGjSrW0atUKISEhOH36NN544w1dnyqRUZMIhvRPNyIiPenduzdOnjyJ8+fPi11KjWrRogXq1KmD7du3i10KkUHhNUBEZHIKCws1Hp8/fx6bN2/WWG7CHBw5cgRJSUkYOHCg2KUQGRx2gIjI5NStWxeDBg2Cn58fUlNTsXjxYhQXFyMxMRENGzYUuzy9S0lJwdGjRzF37lxkZ2fj0qVLBrNgK5Gh4DVARGRyunbtit9++w0ZGRmQy+UICwvDZ599ZhbhBwD+/PNPTJ8+HYGBgfjtt98YfogqwA4QERERmR1eA0RERERmhwGIiIiIzA6vAaqASqXCjRs3YG9vX+nt6omIiMiwCIKA/Px8eHp6PvGmoQxAFbhx4wa8vLzELoOIiIiq4erVq6hfv/5jxzAAVcDe3h5A6QQ6ODjo9NgKhQJbt25FZGQkLC0tdXpsU8O50h7nSnucK+1xrrTHuaoafc1XXl4evLy81P8ffxwGoAqUfezl4OCglwBka2sLBwcH/iV5As6V9jhX2uNcaY9zpT3OVdXoe760uXyFF0ETERGR2WEAIiIiIrPDAERERERmh9cAERGR2VAqlVAoFDo/rkKhgIWFBYqKiqBUKnV+fFNT3fmytLSETCbTSQ0MQEREZPIEQUBGRgZyc3P1dnwPDw9cvXqV94/TwtPMl5OTEzw8PJ56nhmAiIjI5JWFHzc3N9ja2uo8pKhUKty9exd2dnZPvAEfVW++BEFAQUEBsrKyAAB169Z9qhoYgIiIyKQplUp1+HF2dtbLa6hUKpSUlMDa2poBSAvVnS8bGxsAQFZWFtzc3J7q4zD+KRERkUkru+bH1tZW5EpIF8r+HJ/2Wi4GICIiMgu8Nsc06OrPkQGIiIiIzA4DEBERkRnw8fHBggULdHKsnTt3QiKR6O1bdTWBF0ETEREZqE6dOqF58+Y6CS6HDx9GrVq1nr4oE8EARGQCihRK3FeJXQUR1TRBEKBUKmFh8eT/nbu6utZARcaDH4ERGSGFUoUjV25hwbZzeOW7BLT4dAc+S5LhTqHu73BLROIYNGgQdu3aha+++goSiQQSiQRxcXGQSCT4+++/0apVK8jlcuzduxcXL15Er1694O7uDjs7Ozz77LPYtm2bxvEe/QhMIpHgp59+Qp8+fWBra4uGDRti/fr11a539erVCAkJgVwuh4+PD+bOnavx/LfffouGDRvC2toadevWRXR0tPq5P//8E6GhobCxsYGzszMiIiJw7969ateiDXaAiIyAIAg4n3UXe89nY9+FbBy4lIN7JZq3j88pluCLrecw++Xm4hRJZEQEQUChQndLVqhUKhSWKGFRcv+x97WxsZRp/S2mr776CufOnUOTJk0wffp0AMDJkycBADExMfjyyy/h5+eH2rVr4+rVq+jevTtmzpwJuVyOX3/9FT179sTZs2fRoEGDSl9j2rRpmDNnDr744gssXLgQb7zxBlJTU1GnTp0qnD1w9OhRvPrqq5g6dSpee+01JCQkYPjw4XB2dsagQYNw5MgRjBo1CkuXLkV4eDiys7PVAS09PR0DBgzAnDlz0KdPH+Tn52PPnj0QBKFKNVQVAxCRgUq/U4h9F3Kw70I29l7Ixs38Yo3na9taItzfBW0DXFDLUoIPVp3A70euo09LLzznp5+bvRGZikKFEo0n/1Pjr3tqehRsrbT7X6+joyOsrKxga2sLDw8PAMCZM2cAANOnT0eXLl3UY+vUqYNmzZqpH8+YMQNr167F+vXrMXLkyEpfY9CgQRgwYAAA4LPPPsPXX3+NQ4cOoWvXrlU6r3nz5qFz586YNGkSAKBRo0Y4deoUvvjiCwwaNAhpaWmoVasWXnzxRdjb28PLywv+/v4ASgPQ/fv30bdvX3h7ewMAQkNDq/T61cEARGQg8ooUOHDxv8Bz8aZm+1duIUVr3zpoF1AaehrXdYBUWvovSYVCgd93JiEhS4rxa5Kx+YP2sLbUzYKBRGR4nnnmGY3Hd+/exdSpU7Fp0yZ1oCgsLERaWtpjj9O0aVP1f9eqVQsODg7qpSaq4vTp0+jVq5fGtrZt22LBggVQKpXo0qULvL294efnh65duyIyMhKdO3eGg4MDmjVrhs6dOyM0NBRRUVGIjIzEyy+/jNq1a1e5jqpgACISSfF9JRLTctWB5/jVXKge6vhKJUBofSe0C3BG2wAXtGxQ+7Ghpqe3ChcKbXAp+x4W7biAsVGBNXAWRMbJxlKGU9OjdHY8lUqF/Lx82DvYP/EjMF149NtcY8eORXx8PL788ksEBATAxsYGL7/8MkpKSh57HEtLS43HEokEKpXuv1Fhb2+PY8eOYefOndi6dSumTp2KqVOn4vDhw6hTpw7i4+ORkJCArVu3YuHChZgwYQIOHjwIX19fnddShgGIqIaoVALOZOSrA8+hy7fKXYPg51ILbR90eML8nOFoa1nJ0cqztQAm9wjCyJXH8d2ui3ixWV0EeTjo+jSITIJEItH6oyhtqFQq3LeSwdbKQqdrgVlZWUGpfPK1Svv27cOgQYPQp08fAKUdoStXruisjicJDg7Gvn37ytXUqFEj9XpdFhYWiIiIQEREBCZNmoQ6depgx44dePnllyGRSNC2bVu0bdsWkydPhre3N9auXYsxY8borWYGICI9una74EHgyUHChWzk3NP815iLnZU68LQNcEE9J5uner2oEHdENnbH1lOZiFmdjNXDwiGT8vb/RMbKx8cHBw8exJUrV2BnZ1dpd6Zhw4ZYs2YNevbsCYlEgkmTJumlk1OZjz76CM8++yxmzJiB1157Dfv378eiRYvw7bffAgA2btyIS5cuoUOHDqhduzY2btwIlUqFwMBAHDx4ENu3b0dkZCTc3Nxw8OBB3Lx5E8HBwXqtmQGISIdyC0qw/2IO9l4o/bbWlZwCjedtrWRo41sHbQNc0K6hCwLd7XW+PtH0Xk2w/2IOkq7mYun+KxjUVn8tZCLSr7FjxyI6OhqNGzdGYWEhlixZUuG4efPmYfDgwQgPD4eLiws++eQT5OXl1VidLVu2xKpVqzB58mTMmDEDdevWxfTp0zFo0CAAgJOTE9asWYOpU6eiqKgIDRs2xE8//YSQkBCcPXsWu3fvxoIFC5CXlwdvb2/MnTsX3bp102vNDEBET6FIocSRK7ex90I2Ei5mI/n6HTz8zU2ZVILmXk6lgSfABc29nGBlod/bb3k4WmNctyBMWpeCL/45i8gQD3g+ZWeJiMTRqFEj7N+/X2NbWah4mI+PD3bs2KGxbcSIERqPH/1IrKKvmWu7tEWnTp3K7d+vXz/069evwvHt2rXDzp071Y9VKpU6oAUHB2PLli1ava4uMQARVYFSJeDkjTvqDs/hK7dR8sgtmBu52yHcvzTwtPGrA3tr7a/j0ZU3WjfAX4nXcST1NiatS8FP0c9wJWwioocwABE9hiAISM0pUAeehIs55e627O4gR7sAV7Rr6Ixwfxe4O1iLVO1/pFIJZvUNRfev92D7mSxsSk7Hi009xS6LiIzE0KFDsWzZsgqf+9///ofvvvuuhivSPQYgokdk3y1GwsUc7Dtf+m2t67mFGs/byy3wnL+z+n48/q61DLK70tDdHsM7BeCr7ecxdf0ptA9wrdK3yojIfE2fPh1jx46t8DkHB9P4dikDEJm9gpL7OHT5lvrbWqfTNS8ctJRJ0LJB7dLA09AFTes5wkJmHMvoDX/eH5uS03Eh6y4+23was19u+uSdiMjsubm5wc3NTewy9IoBiMzOfaUKJ67fUXd4jqXdhkKpeTFfcF0H9Q0IW/vW0en9QmqS3EKGWX1D8cp3+/H7kavo1cIT4f4uYpdFRCQ64/ytTlQFgiDg4s176hsQHriYg/zi+xpj6jnZqDs84f7OcLGTi1St7j3rUwdvtGmA5QfTMH5NMraM7sBlMsgs1eR9cUh/dPXnyABEJikrrwj7LmZj7/nStbUy8oo0nne0sUS4v7P66+nezrYGeR2PrnzSLQjbTmfiSk4Bvt5+HuO6BoldElGNsbKyglQqxY0bN+Dq6gorKyud/31XqVQoKSlBUVGRTu8EbaqqM1+CIKCkpAQ3b96EVCqFlZXVU9XAAEQm4W7xfRy89N8NCM9l3tV43spCimd9aqsDT4ino1ndIdnB2hLTezXBe0uP4ofdl9CzmSeC65rGhYxETyKVSuHr64v09HTcuHFDL68hCAIKCwthY2Nj0v+Y0pWnmS9bW1s0aNDgqYMmAxAZpZL7KiRdzS29AeGFbCRezYXyoZVEJRIgtJ6jOvC08n78QqLmICrEA11DPLDlZAZiVp/AmuFtzSoEknmzsrJCgwYNcP/+fa3W1qoqhUKB3bt3o0OHDuUWGKXyqjtfMpkMFhYWOgmZDEBkFARBwNnMfOw9X9rhOXj5FgpKNH+J+TjbqgNPmL8znGyfrj1qiqb1CsG+i9k4fu0Ofkm4gsHtuEwGmQ+JRAJLS0u9BBSZTIb79+/D2tqaAUgLhjBfDEBksNLvFOFAlgTb/jiB/ZduI/tuscbzdWpZPQg8pTcg9KpjK1KlxsPdwRox3YIwYW0Kvtx6FpEh7qhfm/NGROZH1Cu1lEolJk2aBF9fX9jY2MDf3x8zZsyocH2SMunp6Xj99dfRqFEjSKVSjB49utyYuLg4SCQSjR9ra/HvzkuPd6dQgS0pGZi0LgUvfLkTHb7cjd8uyrDhRAay7xbDxlKGjo1cMaF7MDaPao8jEyKwcEALvPZsA4afKhjwbAO09qmDghIlJq1LeezfNyIiUyVqB2j27NlYvHgxfvnlF4SEhODIkSN466234OjoiFGjRlW4T3FxMVxdXTFx4kTMnz+/0mM7ODjg7Nmz6se8KM3wFN9X4mjqbfUNCJOv5eKhy3gglQANagno3sofHQLd0KKBE+QW5n0djy5IpRJ81jcU3b/ag3/P3sSGE+l4qRmXySAi8yJqAEpISECvXr3Qo0cPAKWr2f722284dOhQpfv4+Pjgq6++AgD8/PPPlY6TSCTw8PDQbcH0VFQqAafS89T34zl85RaKFJr3c/B3raVeYqKVlwP2/huP7hEB/ExdxwLc7DDi+QDM33YO09afRPsAF9SuxWumiMh8iBqAwsPD8cMPP+DcuXNo1KgRjh8/jr1792LevHlPfey7d+/C29sbKpUKLVu2xGeffYaQkJAKxxYXF6O4+L/rS/LySpdCUCgUUCgUFe5TXWXH0/VxDdXV2wVIuHgLCRdzsP/SLdwu0DxvVzsrhPs7I9y/DsL8nFHX8b+PKs1trp5GdebqnbYNsOH4dVy4eQ8zNp7E7L5N9FWeQeH7SnucK+1xrqpGX/NVleNJBBEvAFCpVBg/fjzmzJkDmUwGpVKJmTNnIjY2Vqv9O3XqhObNm2PBggUa2/fv34/z58+jadOmuHPnDr788kvs3r0bJ0+eRP369csdZ+rUqZg2bVq57StWrICtLa8tqYq7CuB8ngTnciU4e0eCnGLNjx7lUgEBjgIaOQoIdBTgYVP6lXUSx+V84KsUGQRIMLyxEoGOvB6IiIxXQUEBXn/9ddy5c+eJi7aK2gFatWoVli9fjhUrViAkJARJSUkYPXo0PD09ER0dXe3jhoWFISwsTP04PDwcwcHB+P777zFjxoxy42NjYzFmzBj147y8PHh5eSEyMlLnq94qFArEx8ejS5cuJvGxTpFCiSOpuUi4mIOESzk4lZ6PhyO1hVSC5l6OCPcr7fI0re8ISy0XEjW1udKnp5mr7FqnsezgVWzMsMOwl8NN/n5JfF9pj3OlPc5V1ehrvso+wdGGqAHo448/RkxMDPr37w8ACA0NRWpqKmbNmvVUAehRlpaWaNGiBS5cuFDh83K5HHJ5+bWf9HW/CH0fW5+UKgEp1++o77h8JPU2Su5rXscT5GGvvh/Ps751YCd/ureZsc6VGKozV590C8a20zeRdqsQ3+y6gphu5rFMBt9X2uNcaY9zVTW6nq+qHEvUAFRQUFDuVtYymUznC9YplUokJyeje/fuOj2uORAEAVdyCkoDz/lsJFzMRl6R5kKidR2t0S7ABe0alt6A0M2etxwwJvbWlpjRuwmG/HoEP+65hJ7N6iLE01HssoiI9ErUANSzZ0/MnDkTDRo0QEhICBITEzFv3jwMHjxYPSY2NhbXr1/Hr7/+qt6WlJQEoPRC55s3byIpKQlWVlZo3LgxAGD69Ol47rnnEBAQgNzcXHzxxRdITU3FO++8U6PnZ6xu5hcj4WJph2ffhRxczy3UeN7e2gLh/s7qb2v5utTibQaMXJfG7uge6oHNyRmIXZOMtVwmg4hMnKgBaOHChZg0aRKGDx+OrKwseHp64r333sPkyZPVY9LT05GWlqaxX4sWLdT/ffToUaxYsQLe3t64cuUKAOD27dsYMmQIMjIyULt2bbRq1QoJCQnqgESa7hXfx6HLt9Qfa53JyNd43komRSvv2mjXsDTwNPF0gIWW1/GQ8ZjaMwR7zmfjxLU7WLLvMt5p7yd2SUREeiNqALK3t8eCBQvKfYvrYXFxceW2PemLa/Pnz3/sTRLNnUKpwolrudh7Pgf7LmTjWNpt3FdpzmmIp4O6w/OsTx3YWJn2hbEEuDlYY3z3YMSuScbcrecQFeLBO2wTkcniWmBmQBAEXMi6q+7wHLh0C3eLNa/jqV/bBu0fdHjC/JzhbFf+onAyfa8944W1iddx6PItTFiXgl/eepYfbxKRSWIAMlEZd4oeXMNTetflrHzNhUSdbC3R1t9F/W2tBs78lz6VLpMxq28oun21B7vP3cRfSTfQu0U9scsiItI5BiATkVekwMFLt9SB50LWXY3n5RZStPatow48jes6QMqLXKkC/q52eP/5AMyNP4fpG0+hQyNX1OEyGURkYhiAjFTJfRUS026rA8/xa3egfOg6HqkECK3vhHYBzmgb4IKWDWqb/A3uSHfe6+iPjSfScTYzH59uOoV5rzYXuyQiIp1iADISKpWAs5n56sBz8NItFCqUGmP8XGqhbcB/1/E42vJmXFQ9VhZSzOoXin6LE7Dm2HX0aVEP7Ru6il0WEZHOMAAZsOu5hdh3vjTwJFzMRvbdEo3nXeys1IGnbYAL6jnZiFQpmaKWDWojOswHcQlXMGFtCv4Z3YHfBiQik8EAZEByC0qw/2IO9l0svQHh5ex7Gs/bWsnQpuw6noYuCHS35zd0SK/GRgVi68kMpN0qwIJt5xDbPVjskoiIdIIBSERFCiWOpt5Wfz09+fodjYVEZVIJmns5qS9cbu7lBCsL3oCQao6d3AIzejfB278cwU97L6NnM080qcdlMojI+DEA1aDShUTzsO26BL/HHcHR1FwUP7KQaEM3O3XgaeNXB/bWvI6HxNU52B09mtbFphPpiFlzAuuGt+WdwInI6DEA1aD/23sJn20+A0AG4BYAwN1Brg48bQNc4O7AhUTJ8Ezp2Rh7zt1EyvU8LNl3BUM6cJkMIjJuDEA16Dk/Z9jJLeBrW4Le4Y3RMdAN/q52vI6HDJ6bvTUm9AjGJ6uTMTf+LKJCPHjzTCIyauxj16Amno44HNsJ7wSpMPC5Bghw40XMZDxefcYLz/nVQZFChQnrkp+4Jh8RkSFjAKpBUqmE106Q0ZJIJJjVtymsLKTYcz4baxOvi10SEVG18f/GRKQ1X5da+KBzQwDAjI2nkHO3+Al7EBEZJgYgIqqSdzv4IcjDHrcLFPh002mxyyEiqhYGICKqEkuZFJ/3awqJBFibeB27zt0UuyQioipjACKiKmvu5YRB4T4AgAlrk1FQcl/cgoiIqogBiIiqZWxkIOo52eDa7ULMjz8ndjlERFXCAERE1VJLboFPezcBAPzf3stIvnZH5IqIiLTHAERE1fZ8kBt6NvOESgA+WX0CCqXqyTsRERkABiAieiqTX2wMRxtLnErPw//tvSx2OUREWmEAIqKn4movx4QewQCA+fHnkJpzT+SKiIiejAGIiJ7aK63qI9zfGcX3VRi/lstkEJHhYwAioqcmkUjwWZ9QyC2k2HchB6uPcZkMIjJsDEBEpBM+LrUwOqIRAODTTaeQzWUyiMiAMQARkc68094XwXUdkFugwIyNp8Quh4ioUgxARKQzljIpZvcLhVQC/JV0A/+ezRK7JCKiCjEAEZFONa3vhLfa+gIAJq5Nwb1iLpNBRIaHAYiIdG5Ml0ao52SD67mFmMdlMojIADEAEZHO1ZJbYGaf0mUyluy7jONXc8UtiIjoEQxARKQXnQLd0Ks5l8kgIsPEAEREejPpxcZwsrXEmYx8/LjnktjlEBGpMQARkd642MkxsUdjAMBX287jSjaXySAiw8AARER61a9lPbQLcOEyGURkUBiAiEivypbJsLaUIuFiDv44ek3skoiIGICISP8aONviwwfLZMzcdBo387lMBhGJiwGIiGrE2+18EeLpgDuFCkznMhlEJDIGICKqERYyKT7v2xRSCbDh+A38e4bLZBCReBiAiKjGhNZ3xNvtSpfJmLA2GXe5TAYRiYQBiIhq1IddGqF+bRvcuFOEL/85K3Y5RGSmRA1ASqUSkyZNgq+vL2xsbODv748ZM2Y89muy6enpeP3119GoUSNIpVKMHj26wnF//PEHgoKCYG1tjdDQUGzevFlPZ0FEVWFrZYHP+oQCAH7ZfwWJabdFroiIzJGoAWj27NlYvHgxFi1ahNOnT2P27NmYM2cOFi5cWOk+xcXFcHV1xcSJE9GsWbMKxyQkJGDAgAF4++23kZiYiN69e6N3795ISUnR16kQURV0aOSKPi3qQRCA2DXJXCaDiGqcqAEoISEBvXr1Qo8ePeDj44OXX34ZkZGROHToUKX7+Pj44KuvvsLAgQPh6OhY4ZivvvoKXbt2xccff4zg4GDMmDEDLVu2xKJFi/R1KkRURRN7BKP2g2UyftjNZTKIqGaJGoDCw8Oxfft2nDt3DgBw/Phx7N27F926dXuq4+7fvx8REREa26KiorB///6nOi4R6Y6znRyTez5YJmP7eVy6eVfkiojInFiI+eIxMTHIy8tDUFAQZDIZlEolZs6ciTfeeOOpjpuRkQF3d3eNbe7u7sjIyKhwfHFxMYqL/7sxW15eHgBAoVBAoVA8VS2PKjuero9rijhX2jPWueoR4oY1Ac7YcyEHsWtOYOlbz0Aikej1NY11rsTAudIe56pq9DVfVTmeqAFo1apVWL58OVasWIGQkBAkJSVh9OjR8PT0RHR0dI3VMWvWLEybNq3c9q1bt8LW1lYvrxkfH6+X45oizpX2jHGunrcHDkplOHj5NibHbUGYe82sFWaMcyUWzpX2OFdVo+v5Kigo0HqsqAHo448/RkxMDPr37w8ACA0NRWpqKmbNmvVUAcjDwwOZmZka2zIzM+Hh4VHh+NjYWIwZM0b9OC8vD15eXoiMjISDg0O166iIQqFAfHw8unTpAktLS50e29RwrrRn7HNV4n4Fn285h8035Bj1clu42sv19lrGPlc1iXOlPc5V1ehrvso+wdGGqAGooKAAUqnmZUgymQwq1dN9IyQsLAzbt2/X+Ip8fHw8wsLCKhwvl8shl5f/hWtpaam3N7I+j21qOFfaM9a5eqe9PzYlZyL5+h3M3HIO37zeUu+vaaxzJQbOlfY4V1Wj6/mqyrFEvQi6Z8+emDlzJjZt2oQrV65g7dq1mDdvHvr06aMeExsbi4EDB2rsl5SUhKSkJNy9exc3b95EUlISTp36b22hDz74AFu2bMHcuXNx5swZTJ06FUeOHMHIkSNr7NyISHsWMilm9Q2FTCrBphPp2HYq88k7ERE9BVE7QAsXLsSkSZMwfPhwZGVlwdPTE++99x4mT56sHpOeno60tDSN/Vq0aKH+76NHj2LFihXw9vbGlStXAJR+u2zFihWYOHEixo8fj4YNG2LdunVo0qRJjZwXEVVdk3qOeKedL77ffQmT/kpBG786sLfmv6SJSD9EDUD29vZYsGABFixYUOmYuLi4ctsed6foMq+88gpeeeWVp6iOiGra6IhG+DslA2m3CvDlP2cxrRf/0UJE+sG1wIjIYNhYyTCzT2no+fVAKo6mcpkMItIPBiAiMijtG7qiX8v6D5bJOIGS+1wmg4h0jwGIiAzOxB7BcK5lhXOZd/H9rotil0NEJogBiIgMTu1aVuplMhbuuICLXCaDiHSMAYiIDNJLzTzRsZErSpQqxK5JhkpVM3eIJiLzwABERAZJIpHg095NYGMpw6HLt/D7katil0REJoQBiIgMllcdW3wU2QgA8Nnm08jKKxK5IiIyFQxARGTQ3mrri6b1HZFfdB9T1p8UuxwiMhEMQERk0GRSCT7v2xQyqQR/p2Rg68kMsUsiIhPAAEREBq+xpwOGtPcDAEz+6yTyixQiV0RExo4BiIiMwuiIhvB2tkVGXhHmbDkrdjlEZOQYgIjIKFhbyjCrTygAYNnBVBxNvSVyRURkzBiAiMhohAe44JVWpctkxKxORvF9pdglEZGRYgAiIqMyoUcwXOyscD7rLr7beUnscojISDEAEZFRcbK1wuSeIQCAb/69gAtZ+SJXRETGiAGIiIxOz6Z18Xwgl8kgoupjACIioyORSPBpn1DYWslw+Mpt/HY4TeySiMjIMAARkVGq52SDsZGBAIDPN59Bxh0uk0FE2mMAIiKjFR3ug2ZeTsgvvo8p61PELoeIjAgDEBEZrdJlMkJhIZXgn5OZ2JLCZTKISDsMQERk1ILrOuDdDmXLZKQgj8tkEJEWGICIyOiN6twQvi61kJVfjNl/nxG7HCIyAgxARGT0rC1l+OzBMhnLD6bh8BUuk0FEj8cAREQmIczfGa894wUAiFl9gstkENFjMQARkckY3z0YLnZyXLx5D9/+e1HscojIgDEAEZHJcLS1xNSXGgMAvt15AeczuUwGEVWMAYiITEqP0LroHOQGhVJADJfJIKJKMAARkUmRSCSY0bsJalnJcDT1NpYfTBW7JCIyQAxARGRyPJ1s8HFU6TIZs7ecRfqdQpErIiJDwwBERCbpzTAfNPdywt3i+5j810kIAj8KI6L/MAARkUmSSSX4vF/pMhnxp7hMBhFpYgAiIpMV5OGAYZ38AQCT15/EnUIuk0FEpRiAiMikjXg+AH6utXAzvxifc5kMInqAAYiITJq1pQyzHiyT8duhNBziMhlEBAYgIjIDbfycMaB16TIZk/46BYVK5IKISHQMQERkFmK6BcPVXo5L2QWIv8ZffUTmjr8FiMgsONpYYtpLIQCA+BsSnOMyGURmjQGIiMxGtyYe6BzkCpUgwYS/TkHJZTKIzBYDEBGZDYlEgikvBkMuE5B09Q6WHeAyGUTmigGIiMxKXUdr9GxQehX0nC1ncCOXy2QQmSMGICIyO23dBbTwcsS9EiUm/5XCZTKIzJCoAUipVGLSpEnw9fWFjY0N/P39MWPGjCf+Mtq5cydatmwJuVyOgIAAxMXFaTw/depUSCQSjZ+goCA9ngkRGROpBJjZKwSWMgm2nc7C5mQuk0FkbkQNQLNnz8bixYuxaNEinD59GrNnz8acOXOwcOHCSve5fPkyevTogeeffx5JSUkYPXo03nnnHfzzzz8a40JCQpCenq7+2bt3r75Ph4iMSEN3OwzrFAAAmLL+JO4UcJkMInNiIeaLJyQkoFevXujRowcAwMfHB7/99hsOHTpU6T7fffcdfH19MXfuXABAcHAw9u7di/nz5yMqKko9zsLCAh4eHvo9ASIyaiOe98emEzdw8eY9zPr7ND7v11TskoiohojaAQoPD8f27dtx7tw5AMDx48exd+9edOvWrdJ99u/fj4iICI1tUVFR2L9/v8a28+fPw9PTE35+fnjjjTeQlpam+xMgIqMmt5CpQ8/Kw1dx4FKOyBURUU0RtQMUExODvLw8BAUFQSaTQalUYubMmXjjjTcq3ScjIwPu7u4a29zd3ZGXl4fCwkLY2NigTZs2iIuLQ2BgINLT0zFt2jS0b98eKSkpsLe3L3fM4uJiFBcXqx/n5eUBABQKBRQK3bbFy46n6+OaIs6V9jhX2nt0rprXs0f/Z+tj5eFriFl9AhtHhEFuKROzRIPB95X2OFdVo6/5qsrxRA1Aq1atwvLly7FixQqEhISor+nx9PREdHR0tY/7cAepadOmaNOmDby9vbFq1Sq8/fbb5cbPmjUL06ZNK7d969atsLW1rXYdjxMfH6+X45oizpX2OFfae3iumgPYbCnDlZwCfPh/8XixARcLexjfV9rjXFWNrueroKBA67GiBqCPP/4YMTEx6N+/PwAgNDQUqampmDVrVqUByMPDA5mZmRrbMjMz4eDgABsbmwr3cXJyQqNGjXDhwoUKn4+NjcWYMWPUj/Py8uDl5YXIyEg4ODhU59QqpVAoEB8fjy5dusDS0lKnxzY1nCvtca60V9lc2flnYuTK4/g3XYZRvdsiyKN8t9jc8H2lPc5V1ehrvso+wdGGqAGooKAAUqnmZUgymQwqVeX/+goLC8PmzZs1tsXHxyMsLKzSfe7evYuLFy/izTffrPB5uVwOuVxebrulpaXe3sj6PLap4Vxpj3OlvUfn6sXm9bH+RAa2nsrExPWnsWZYOGRSiYgVGg6+r7THuaoaXc9XVY4l6kXQPXv2xMyZM7Fp0yZcuXIFa9euxbx589CnTx/1mNjYWAwcOFD9eOjQobh06RLGjRuHM2fO4Ntvv8WqVavw4YcfqseMHTsWu3btwpUrV5CQkIA+ffpAJpNhwIABNXp+RGRcpvdqAnu5BY5fzcWv+6+IXQ4R6ZGoAWjhwoV4+eWXMXz4cAQHB2Ps2LF47733MGPGDPWY9PR0jW9w+fr6YtOmTYiPj0ezZs0wd+5c/PTTTxpfgb927RoGDBiAwMBAvPrqq3B2dsaBAwfg6upao+dHRMbFw9Ean3QrvWnqF/+cxXUuk0FkskT9CMze3h4LFizAggULKh3z6F2eAaBTp05ITEysdJ+VK1fqoDoiMkevt26Av5Ku4/CV25i0LgX/F/0MJBJ+FEZkargWGBHRQ6RSCWb1DYWVTIodZ7Kw8US62CURkR4wABERPSLAzR7Dn/cHAEzbcBK5BSUiV0REusYARERUgWGd/BHgZofsuyX4bPNpscshIh1jACIiqoDcQobP+4YCAFYduYaEC9kiV0REusQARERUiWd86uB/zzUAAMSuTUaRQilyRUSkKwxARESPMa5rENwd5EjNKcBX28+LXQ4R6QgDEBHRYzhYW2J6ryYAgB92X8KpG9rfap+IDBcDEBHRE0SFeKBriAeUKgGxa05AqRLELomInhIDEBGRFqb1CoG9tQWOX7uDuIQrYpdDRE+JAYiISAvuDtaI7RYMAJi79Syu3S4QuSIiehoMQEREWur/rBda+9RBQYkSE9elQBD4URiRsWIAIiLSklQqwWcPlsnYefYm1h+/IXZJRFRNDEBERFUQ4GaHkS8EAACmbziF2/e4TAaRMWIAIiKqoqEd/dHI3Q4590rw6SYuk0FkjBiAiIiqyMpCill9m0IiAVYfu4a957lMBpGxYQAiIqqGVt618eZz3gCA8WuTUVjCZTKIjAkDEBFRNX0cFQgPB2uk3SrAgu3nxC6HiKqAAYiIqJrsrS0xo3fpMhk/7bmMlOt3RK6IiLTFAERE9BS6NHZHj9C6D5bJSMZ9pUrskohICwxARERPacpLjeFgbYHk61wmg8hYMAARET0lN3trjO9etkzGOVy9xWUyiAwdAxARkQ689qwX2vjWQaFCiQlcJoPI4DEAERHpgEQiway+obCykGL3uZtYl3Rd7JKI6DGqFYCuXr2Ka9euqR8fOnQIo0ePxg8//KCzwoiIjI2fqx1GPVgmY8bG07jFZTKIDFa1AtDrr7+Of//9FwCQkZGBLl264NChQ5gwYQKmT5+u0wKJiIzJux38Eehuj1v3SvDpxlNil0NElahWAEpJSUHr1q0BAKtWrUKTJk2QkJCA5cuXIy4uTpf1EREZFSsLKT7vFwqJBFiTeB27z90UuyQiqkC1ApBCoYBcLgcAbNu2DS+99BIAICgoCOnp6bqrjojICLVoUBvRYT4AgAnrklFQcl/cgoionGoFoJCQEHz33XfYs2cP4uPj0bVrVwDAjRs34OzsrNMCiYiM0dioQHg6WuPqrUIs2HZe7HKI6BHVCkCzZ8/G999/j06dOmHAgAFo1qwZAGD9+vXqj8aIiMyZndzioWUyLnGZDCIDY1GdnTp16oTs7Gzk5eWhdu3a6u3vvvsubG1tdVYcEZEx6xzsjheb1sXGE+n4ZPUJ/DWiLSxkvPsIkSGo1t/EwsJCFBcXq8NPamoqFixYgLNnz8LNzU2nBRIRGbMpPUPgaGOJkzfy8PO+y2KXQ0QPVCsA9erVC7/++isAIDc3F23atMHcuXPRu3dvLF68WKcFEhEZM1d7OSY8WCZjXvw5pOVwmQwiQ1CtAHTs2DG0b98eAPDnn3/C3d0dqamp+PXXX/H111/rtEAiImP3yjP1EebnjCKFCuPXJnOZDCIDUK0AVFBQAHt7ewDA1q1b0bdvX0ilUjz33HNITU3VaYFERMZOIpHgswfLZOy9kI01x7hMBpHYqhWAAgICsG7dOly9ehX//PMPIiMjAQBZWVlwcHDQaYFERKbA16UWPujcEADw6aZTyLlbLHJFROatWgFo8uTJGDt2LHx8fNC6dWuEhYUBKO0GtWjRQqcFEhGZinc7+CHIwx63CxSYwWUyiERVrQD08ssvIy0tDUeOHME///yj3t65c2fMnz9fZ8UREZkSS5kUn/drCokEWJd0A7u4TAaRaKp9QwoPDw+0aNECN27cUK8M37p1awQFBemsOCIiU9PcywlvhfsCACas5TIZRGKpVgBSqVSYPn06HB0d4e3tDW9vbzg5OWHGjBlQqVS6rpGIyKR8FNkI9ZxscO12IeZtPSd2OURmqVoBaMKECVi0aBE+//xzJCYmIjExEZ999hkWLlyISZMm6bpGIiKTUktugU/7lC6T8fO+yzhxLVfcgojMULUC0C+//IKffvoJw4YNQ9OmTdG0aVMMHz4cP/74I+Li4nRcIhGR6Xk+0A0vNfOESgBiVidDoWT3nKgmVSsA3bp1q8JrfYKCgnDr1i2tj6NUKjFp0iT4+vrCxsYG/v7+mDFjxhNvErZz5060bNkScrkcAQEBFYaub775Bj4+PrC2tkabNm1w6NAhresiIqoJk3s2hpOtJU6l5+H/9nKZDKKaVK0A1KxZMyxatKjc9kWLFqFp06ZaH2f27NlYvHgxFi1ahNOnT2P27NmYM2cOFi5cWOk+ly9fRo8ePfD8888jKSkJo0ePxjvvvKPxbbTff/8dY8aMwZQpU3Ds2DE0a9YMUVFRyMrKqtqJEhHpkYvdf8tkzI8/hyvZ90SuiMh8VGs1+Dlz5qBHjx7Ytm2b+h5A+/fvx9WrV7F582atj5OQkIBevXqhR48eAAAfHx/89ttvj+3WfPfdd/D19cXcuXMBAMHBwdi7dy/mz5+PqKgoAMC8efMwZMgQvPXWW+p9Nm3ahJ9//hkxMTHVOWUiIr14uVV9rEu6jn0XcjBhXTKWvd0GEolE7LKITF61OkAdO3bEuXPn0KdPH+Tm5iI3Nxd9+/bFyZMnsXTpUq2PEx4eju3bt+PcudJvQRw/fhx79+5Ft27dKt1n//79iIiI0NgWFRWF/fv3AwBKSkpw9OhRjTFSqRQRERHqMUREhkIikWBm71DILaTYdyEHfx69JnZJRGahWh0gAPD09MTMmTM1th0/fhz/93//hx9++EGrY8TExCAvLw9BQUGQyWRQKpWYOXMm3njjjUr3ycjIgLu7u8Y2d3d35OXlobCwELdv34ZSqaxwzJkzZyo8ZnFxMYqL/7stfV5eHgBAoVBAoVBodS7aKjuero9rijhX2uNcac8Q56qeoxXef94fX8afx8xNp9Hevzac7eRil2WQc2WoOFdVo6/5qsrxqh2AdGHVqlVYvnw5VqxYgZCQEPU1PZ6enoiOjq6xOmbNmoVp06aV275161bY2trq5TXj4+P1clxTxLnSHudKe4Y2V54qoJ6tDNcLFBj+07+IbmQ43woztLkyZJyrqtH1fBUUFGg9VtQA9PHHHyMmJgb9+/cHAISGhiI1NRWzZs2qNAB5eHggMzNTY1tmZiYcHBxgY2MDmUwGmUxW4RgPD48KjxkbG4sxY8aoH+fl5cHLywuRkZE6X9xVoVAgPj4eXbp0gaWlpU6PbWo4V9rjXGnPkOfKp8UdvPz9QRzLkWJ4QCt0bOQqaj2GPFeGhnNVNfqar7JPcLQhagAqKCiAVKp5GZJMJnvs3aTDwsLKXWgdHx+vvhjbysoKrVq1wvbt29G7d28ApXeu3r59O0aOHFnhMeVyOeTy8u1mS0tLvb2R9XlsU8O50h7nSnuGOFctfVwwuK0vftp7GVM2nMHWD91QSy7qr2kAhjlXhopzVTW6nq+qHKtKf7P69u372Odzc3Orcjj07NkTM2fORIMGDRASEoLExETMmzcPgwcPVo+JjY3F9evX8euvvwIAhg4dikWLFmHcuHEYPHgwduzYgVWrVmHTpk3qfcaMGYPo6Gg888wzaN26NRYsWIB79+6pvxVGRGSoxkQ2wpaTGbh2uxBzt57D5J6NxS6JyCRVKQA5Ojo+8fmBAwdqfbyypTOGDx+OrKwseHp64r333sPkyZPVY9LT05GWlqZ+7Ovri02bNuHDDz/EV199hfr16+Onn35SfwUeAF577TXcvHkTkydPRkZGBpo3b44tW7aUuzCaiMjQ2FpZYGafUET/fAhxCZfxUnNPNPdyErssIpNTpQC0ZMkSnb64vb09FixYgAULFlQ6pqK7PHfq1AmJiYmPPfbIkSMr/ciLiMiQdWzkit7NPbEu6QZiVp/AhvfbwVJWrbuWEFEl+DeKiMgATXqxMWrbWuJMRj5+2H1J7HKITA4DEBGRAXK2k2Nij9Lrf77afh6XuUwGkU4xABERGai+LeuhfUMXlNxXYfya5CcuFE1E2mMAIiIyUGXLZFhbSrH/Ug7+OMJlMoh0hQGIiMiANXC2xYcRjQAAMzefxs384ifsQUTaYAAiIjJwb7fzRYinA+4UKjBtw0mxyyEyCQxAREQGzkImxex+TSGTSrDxRDp2nMl88k5E9FgMQERERqBJPUe83c4XADBxbQruFt8XuSIi48YARERkJD6MaASvOja4cacIX/5zVuxyiIwaAxARkZGwsZLhsz6hAIBf9l/BsbTbIldEZLwYgIiIjEj7hq7o26IeBAGIXZ2MkvsqsUsiMkoMQERERmbii41Rp5YVzmbm44fdF8Uuh8goMQARERmZOrWsMOnFYADA1zsu4NLNuyJXRGR8GICIiIxQ7+b10KGRK0ruqxC7JhkqFZfJIKoKBiAiIiNUukxGE9hYynDw8i2sOnJV7JKIjAoDEBGRkfKqY4uPIkuXyfhs82lk5ReJXBGR8WAAIiIyYoPCfRBazxF5Rfcxbf0pscshMhoMQERERsxCJsXn/UIhk0qwKTkd8ae4TAaRNhiAiIiMXIinI95pX7pMxqR1KcgvUohcEZHhYwAiIjIBozs3QoM6tsjIK8IXXCaD6IkYgIiITMDDy2QsPZCKo6lcJoPocRiAiIhMRLuGLujXsn7pMhlrTnCZDKLHYAAiIjIhE3sEw7mWFc5l3sV3u7hMBlFlGICIiExI7VpWmNyzMQBg0Y4LuJDFZTKIKsIARERkYl5q5omOjVxRolRhPJfJIKoQAxARkYmRSCSY2acJbK1kOHTlFlYe5jIZRI9iACIiMkH1a9vio8hAAMCsv08jK4/LZBA9jAGIiMhEDQr3QbP6jsgvuo8p60+KXQ6RQWEAIiIyUTKpBLP6NoVMKsHfKRn452SG2CURGQwGICIiE9bY0wHvdvADAEz+KwV5XCaDCAADEBGRyfugc0P4ONsiM68Yc7acEbscIoPAAEREZOKsLf9bJmPZgTQcuXJL5IqIxMcARERkBsIDXPBKq/oAgJg1ySi+rxS5IiJxMQAREZmJCT2C4WJnhQtZd7F4J5fJIPPGAEREZCacbK0wpWcIAODbfy/iQla+yBURiYcBiIjIjLzYtC5eCHJDiVKFmNVcJoPMFwMQEZEZkUgkmNG7CWpZyXAk9TZWHEoTuyQiUTAAERGZmXpONhgbVbpMxuy/zyDjDpfJIPPDAEREZIYGhvmguZcT8ovvY/JfKWKXQ1TjGICIiMyQTCrB5/1CYSGVYOupTGxJSRe7JKIaxQBERGSmgjwc8F7HsmUyTuJOIZfJIPMhagDy8fGBRCIp9zNixIgKxysUCkyfPh3+/v6wtrZGs2bNsGXLFo0xU6dOLXe8oKCgmjgdIiKj8/4LDeHrUgtZ+cWYzWUyyIyIGoAOHz6M9PR09U98fDwA4JVXXqlw/MSJE/H9999j4cKFOHXqFIYOHYo+ffogMTFRY1xISIjGcffu3av3cyEiMkYPL5Ox4mAaDl3mMhlkHkQNQK6urvDw8FD/bNy4Ef7+/ujYsWOF45cuXYrx48eje/fu8PPzw7Bhw9C9e3fMnTtXY5yFhYXGcV1cXGridIiIjFKYvzNee8YLABC75gSXySCzYDDXAJWUlGDZsmUYPHgwJBJJhWOKi4thbW2tsc3GxqZch+f8+fPw9PSEn58f3njjDaSl8T4XRESPM757MFzs5Lh48x6++ZfLZJDpsxC7gDLr1q1Dbm4uBg0aVOmYqKgozJs3Dx06dIC/vz+2b9+ONWvWQKn8718rbdq0QVxcHAIDA5Geno5p06ahffv2SElJgb29fYXHLS4uRnFxsfpxXl4egNJrjhQK3V4UWHY8XR/XFHGutMe50h7nqmK2lsDkHoEY9fsJLN55AV2DXeFTRw6Ac6UNvq+qRl/zVZXjSQRBMIj7oEdFRcHKygobNmyodMzNmzcxZMgQbNiwARKJBP7+/oiIiMDPP/+MwsLCCvfJzc2Ft7c35s2bh7fffrvCMVOnTsW0adPKbV+xYgVsbW2rd0JEREZGEICfzkqRclsKHzsBHzRRQlpxQ57IIBUUFOD111/HnTt34ODg8NixBhGAUlNT4efnhzVr1qBXr15PHF9UVIScnBx4enoiJiYGGzduxMmTJysd/+yzzyIiIgKzZs2q8PmKOkBeXl7Izs5+4gRWlUKhQHx8PLp06QJLS0udHtvUcK60x7nSHufq8dLvFKHb1/twr0SJid0awjX3NOdKC3xfVY2+5isvLw8uLi5aBSCD+AhsyZIlcHNzQ48ePbQab21tjXr16kGhUGD16tV49dVXKx179+5dXLx4EW+++WalY+RyOeRyebntlpaWensj6/PYpoZzpT3OlfY4VxVr4GKJcV2DMGX9SczfcQnjQjhXVcG5qhpdz1dVjiX6RdAqlQpLlixBdHQ0LCw089jAgQMRGxurfnzw4EGsWbMGly5dwp49e9C1a1eoVCqMGzdOPWbs2LHYtWsXrly5goSEBPTp0wcymQwDBgyosXMiIjJm/3vOGy0aOOFesRJ/XJbCAD4oINI50QPQtm3bkJaWhsGDB5d7Li0tDenp/92evaioCBMnTkTjxo3Rp08f1KtXD3v37oWTk5N6zLVr1zBgwAAEBgbi1VdfhbOzMw4cOABXV9eaOB0iIqMnk0rwed+msJRJkHJbik/W8i7RZHpE/wgsMjKy0n9d7Ny5U+Nxx44dcerUqcceb+XKlboqjYjIbAV62GNcVCN8tvkM1ibeQMLFHMzqG4oXgtzFLo1IJ0TvABERkWEaFOaNUSFK+DjbIjOvGIPjjuCjVcdxp4DdIDJ+DEBERFQpPwdg/fAwvNPOFxIJsPrYNUQu2IUdZzLFLo3oqTAAERHRY9lYyTDxxcb4c2gY/FxqqbtBY1YlsRtERosBiIiItNLKuw42f9Be3Q1ac+w6uszfhe2n2Q0i48MAREREWrO21OwGZeUX4+1f2A0i48MAREREVVbWDRrSnt0gMk4MQEREVC3WljJM6FFBN+h3doPI8DEAERHRUynrBr3bwa+0G5RY2g3adordIDJcDEBERPTUrC1lGN89GH8ODYefa2k36J1fS7tBuQUlYpdHVA4DEBER6Uwr79rYPKq0GyRVd4N2sxtEBocBiIiIdKqsG/THg27QzQfdoA/ZDSIDwgBERER6UdYNeu9BN2jtg25QPLtBZAAYgIiISG+sLWWI7R6MP4f91w0awm4QGQAGICIi0ruWDR50gzqyG0SGgQGIiIhqhLWlDLHdSrtB/g91g0avTGQ3iGocAxAREdWolg1qY9ND3aB1STcQMW83tp7MELs0MiMMQEREVOPKukGrH3SDsu8W492lR/HBykTcvsduEOkfAxAREYmmxYNu0NCO/pBKgL+SbqDL/N34h90g0jMGICIiEpW1pQwx3YKwelg4AtzskH23GO+xG0R6xgBEREQGoUWD2tj4fjsM68RuEOkfAxARERkMa0sZPukahDXD22p0g0b9xm4Q6RYDEBERGZzmXk4a3aD1x2+gy/xd2JLCbhDpBgMQEREZpIe7QQ3d7JB9twRDl5V2g26xG0RPiQGIiIgMWnMvJ2x4pBsUyW4QPSUGICIiMnhl3aC1j3SD3mc3iKqJAYiIiIxGMy8nbBzVDsMfdIM2qLtB6WKXRkaGAYiIiIyK3EKGcQ+6QY3cy7pBxzByxTF2g0hrDEBERGSUmj24NmjE8/6QSSXYeCIdXebtwt/J7AbRkzEAERGR0ZJbyPBxVBDWDg9HI3c75NwrwbDl7AbRkzEAERGR0Wtan90gqhoGICIiMgmVdYNGrDiGnLvFYpdHBoYBiIiITEpZN2jk8wGQSSXYdCIdkfN3YzO7QfQQBiAiIjI5cgsZxkYFYu3wcAS62yPnXgmGsxtED2EAIiIik9W0vhPWv98W77/AbhBpYgAiIiKTJreQ4aPIQKwb3lazG7Sc3SBzxgBERERmIbS+o2Y3KDkdXebvxqYT7AaZIwYgIiIyG2XdoL9GtEWQhz1u3SvBiBWl3aBsdoPMCgMQERGZnSb1HLF+ZDuMeqgbFMlukFlhACIiIrNkZSHFmAq6QcOXH2U3yAwwABERkVlTd4M6N4SFVILNyRmInL8bG0/cELs00iMGICIiMntWFlKM6dII6x7qBo1ckchukAkTNQD5+PhAIpGU+xkxYkSF4xUKBaZPnw5/f39YW1ujWbNm2LJlS7lx33zzDXx8fGBtbY02bdrg0KFD+j4VIiIyARV1g7rM24UNx29AEASxyyMdEjUAHT58GOnp6eqf+Ph4AMArr7xS4fiJEyfi+++/x8KFC3Hq1CkMHToUffr0QWJionrM77//jjFjxmDKlCk4duwYmjVrhqioKGRlZdXIORERkXF7tBt0u0CB939LxHB+U8ykiBqAXF1d4eHhof7ZuHEj/P390bFjxwrHL126FOPHj0f37t3h5+eHYcOGoXv37pg7d656zLx58zBkyBC89dZbaNy4Mb777jvY2tri559/rqnTIiIiE/BoN+jvFHaDTInBXANUUlKCZcuWYfDgwZBIJBWOKS4uhrW1tcY2Gxsb7N27V32Mo0ePIiIiQv28VCpFREQE9u/fr7/iiYjIJD3cDQqu66DuBg1bdgw389kNMmYWYhdQZt26dcjNzcWgQYMqHRMVFYV58+ahQ4cO8Pf3x/bt27FmzRoolUoAQHZ2NpRKJdzd3TX2c3d3x5kzZyo9bnFxMYqL/3sj5+XlASi95kihUDzFWZVXdjxdH9cUca60x7nSHudKe5yr/wS62eLPd1vju92XsHjXZWw5mYGDl3MwuUcQeoR64P79+wA4V9rS13urKseTCAbSx4uKioKVlRU2bNhQ6ZibN29iyJAh2LBhAyQSCfz9/REREYGff/4ZhYWFuHHjBurVq4eEhASEhYWp9xs3bhx27dqFgwcPVnjcqVOnYtq0aeW2r1ixAra2tk9/ckREZDKu3QNWXJDhekHppxVN66jwiq8KDlYiF0YoKCjA66+/jjt37sDBweGxYw2iA5Samopt27ZhzZo1jx3n6uqKdevWoaioCDk5OfD09ERMTAz8/PwAAC4uLpDJZMjMzNTYLzMzEx4eHpUeNzY2FmPGjFE/zsvLg5eXFyIjI584gVWlUCgQHx+PLl26wNLSUqfHNjWcK+1xrrTHudIe56pyg+6r8P3uy/h21yWcuCVFWqEcveoXYVz/zrCyYhJ6En29t8o+wdGGQQSgJUuWwM3NDT169NBqvLW1NerVqweFQoHVq1fj1VdfBQBYWVmhVatW2L59O3r37g0AUKlU2L59O0aOHFnp8eRyOeRyebntlpaWevtLr89jmxrOlfY4V9rjXGmPc1WepSUwJioIUaF1MfaPEzidnodfzstw489T+KxvU7jal/9/CpWn6/dWVY4l+kXQKpUKS5YsQXR0NCwsNPPYwIEDERsbq3588OBBrFmzBpcuXcKePXvQtWtXqFQqjBs3Tj1mzJgx+PHHH/HLL7/g9OnTGDZsGO7du4e33nqrxs6JiIjMQ4inI9aPbItRz/tDKhEQfzoLXebvwl9J1/lNMQMnegdo27ZtSEtLw+DBg8s9l5aWBqn0v4xWVFSEiRMn4tKlS7Czs0P37t2xdOlSODk5qce89tpruHnzJiZPnoyMjAw0b94cW7ZsKXdhNBERkS5YyqR4/wV/WOecxYas2jidkY8PViZhc3I6ZvRuAjd76ycfhGqc6AEoMjKy0pS8c+dOjccdO3bEqVOnnnjMkSNHPvYjLyIiIl2rVwtYPbQNftybhoU7zuOfk5k4ePkWpr0UgpeaeVZ6ixcSh+gfgREREZkKS5kUH0Q0xPqR7dC4rgNyCxT4YGUS3lt6FFn5RWKXRw9hACIiItKxxp4O+GtkW4zp0giWMgm2nspE5PzdvDbIgDAAERER6YGlTIpRnUu7QSGe7AYZGgYgIiIiPQqu64B1IzS7QV3m7ca6RHaDxMQAREREpGePdoPuFCow+vckvMtukGgYgIiIiGpIWTfoowfdoHh2g0TDAERERFSDLGVSvP+gG9Sk3n/doCG/HkVWHrtBNYUBiIiISATBdR2wdvh/3aBtpzPRZf5urE28xm5QDWAAIiIiEklZN2jD+/91gz78/Ti7QTWAAYiIiEhkQR6l3aCxkewG1RQGICIiIgNgKZNi5AsVdYOOsBukBwxAREREBqR8NygLEfN2Yc0xdoN0iQGIiIjIwJR1gza+3x6h9RyRV3QfY1Ydxzu/HEEmu0E6wQBERERkoAI97LF2eDg+jgqEpUyC7Wey0IXdIJ1gACIiIjJgFjIpRjwfgI3vt0fT+uwG6QoDEBERkREI9LDHmmGl3SArmVTdDVp9lN2g6mAAIiIiMhJl3aAN77dTd4M++oPdoOpgACIiIjIylXWD/mQ3SGsMQEREREZIfW3QqP+6QWP/OI63fzmCjDvsBj0JAxAREZERa+Re2g0a17W0G7TjTBa6zGc36EkYgIiIiIychUyK4Z1Ku0HN6jsin92gJ2IAIiIiMhGN3O2xelg4PukapNEN+uPIVXaDHsEAREREZEIsZFIM6+SPTQ91gz7+8wQGxx1mN+ghDEBEREQmqOEj3aB/z95kN+ghDEBEREQmSqMb5OXEbtBDGICIiIhMXEN3e6weGoaYbkGwsvivG7TKjLtBDEBERERmwEImxdCO/tj8UDdo3J8n8FbcYaTfKRS7vBrHAERERGRGAtw0u0E7z95E5PzdZtcNYgAiIiIyMw93g5o/1A0atMR8ukEMQERERGYqwK30m2KxD7pBu87dROS83Vh12PS7QQxAREREZkwmleC9h7tBxfcxbnVpN+hGrul2gxiAiIiIqMJuUNT83fj9cJpJdoMYgIiIiAjAw92g9mjRoLQb9MnqZESbYDeIAYiIiIg0BLjZ4c+h4RjfvbQbtNsEu0EMQERERFSOTCrBux1Ku0EtTbAbxABERERElQpws8MfQ8MxoXsw5A+6QZHzd2PlIePuBjEAERER0WPJpBIM6eCHzR+UdoPuFt9HzJpkDPz5EK4baTeIAYiIiIi04u+q2Q3acz4bUUbaDWIAIiIiIq2ZSjeIAYiIiIiqrKwbNLGHZjfoNyPpBjEAERERUbXIpBK80760G9TKuzbuFt9HrJF0g0QNQD4+PpBIJOV+RowYUek+CxYsQGBgIGxsbODl5YUPP/wQRUVF6uenTp1a7nhBQUE1cTpERERmyd/VDqveCzOqbpCFmC9++PBhKJVK9eOUlBR06dIFr7zySoXjV6xYgZiYGPz8888IDw/HuXPnMGjQIEgkEsybN089LiQkBNu2bVM/trAQ9TSJiIhMXlk36IUgN3z85wkcTb2N2DXJ2Jycjll9Q1G/tq3YJWoQNRm4urpqPP7888/h7++Pjh07Vjg+ISEBbdu2xeuvvw6gtIM0YMAAHDx4UGOchYUFPDw89FM0ERERVcrvQTdoyb7L+OKfs9hzPhtdF+zB+O7BGNDaCxKJROwSARjQNUAlJSVYtmwZBg8eXOnkhIeH4+jRozh06BAA4NKlS9i8eTO6d++uMe78+fPw9PSEn58f3njjDaSlpem9fiIiIipV1g3aMroDnnlwbdD4tcl48/8O4drtArHLAyByB+hh69atQ25uLgYNGlTpmNdffx3Z2dlo164dBEHA/fv3MXToUIwfP149pk2bNoiLi0NgYCDS09Mxbdo0tG/fHikpKbC3t6/wuMXFxSguLlY/zsvLAwAoFAooFArdnOADZcfT9XFNEedKe5wr7XGutMe50h7nqmL1Ha2wbPAz+PVAGubGn8feC6XXBo3t4o/agu7nqyrHkwgGcnVSVFQUrKyssGHDhkrH7Ny5E/3798enn36KNm3a4MKFC/jggw8wZMgQTJo0qcJ9cnNz4e3tjXnz5uHtt9+ucMzUqVMxbdq0cttXrFgBW1vD+sySiIjIGGUVAisuynA5v/RTnsZOKrwbpIIuPxErKCjA66+/jjt37sDBweGxYw0iAKWmpsLPzw9r1qxBr169Kh3Xvn17PPfcc/jiiy/U25YtW4Z3330Xd+/ehVRa8Sd6zz77LCIiIjBr1qwKn6+oA+Tl5YXs7OwnTmBVKRQKxMfHo0uXLrC0tNTpsU0N50p7nCvtca60x7nSHudKO0qVgF8PpGFe/HlEeCowZ1CETucrLy8PLi4uWgUgg/gIbMmSJXBzc0OPHj0eO66goKBcyJHJZABQ6dfs7t69i4sXL+LNN9+s9LhyuRxyubzcdktLS729kfV5bFPDudIe50p7nCvtca60x7l6PEsA73YMQOcgVxzfv1Pn81WVY4l+EbRKpcKSJUsQHR1d7uvqAwcORGxsrPpxz549sXjxYqxcuRKXL19GfHw8Jk2ahJ49e6qD0NixY7Fr1y5cuXIFCQkJ6NOnD2QyGQYMGFCj50VEREQVa1DHFjKRvwwmegdo27ZtSEtLw+DBg8s9l5aWptHxmThxIiQSCSZOnIjr16/D1dUVPXv2xMyZM9Vjrl27hgEDBiAnJweurq5o164dDhw4UO4r90RERGS+RA9AkZGRlX58tXPnTo3HFhYWmDJlCqZMmVLp8VauXKnL8oiIiMgEif4RGBEREVFNYwAiIiIis8MARERERGaHAYiIiIjMDgMQERERmR0GICIiIjI7DEBERERkdhiAiIiIyOwwABEREZHZYQAiIiIis8MARERERGZH9LXADFHZ2mR5eXk6P7ZCoUBBQQHy8vJgaWmp8+ObEs6V9jhX2uNcaY9zpT3OVdXoa77K/r9d2RqjD2MAqkB+fj4AwMvLS+RKiIiIqKry8/Ph6Oj42DESQZuYZGZUKhVu3LgBe3t7SCQSnR47Ly8PXl5euHr1KhwcHHR6bFPDudIe50p7nCvtca60x7mqGn3NlyAIyM/Ph6enJ6TSx1/lww5QBaRSKerXr6/X13BwcOBfEi1xrrTHudIe50p7nCvtca6qRh/z9aTOTxleBE1ERERmhwGIiIiIzA4DUA2Ty+WYMmUK5HK52KUYPM6V9jhX2uNcaY9zpT3OVdUYwnzxImgiIiIyO+wAERERkdlhACIiIiKzwwBEREREZocBiIiIiMwOA5AefPPNN/Dx8YG1tTXatGmDQ4cOPXb8H3/8gaCgIFhbWyM0NBSbN2+uoUrFV5W5iouLg0Qi0fixtrauwWrFs3v3bvTs2ROenp6QSCRYt27dE/fZuXMnWrZsCblcjoCAAMTFxem9TkNQ1bnauXNnufeVRCJBRkZGzRQsklmzZuHZZ5+Fvb093Nzc0Lt3b5w9e/aJ+5nr76vqzJe5/s5avHgxmjZtqr7JYVhYGP7+++/H7iPG+4oBSMd+//13jBkzBlOmTMGxY8fQrFkzREVFISsrq8LxCQkJGDBgAN5++20kJiaid+/e6N27N1JSUmq48ppX1bkCSu8amp6erv5JTU2twYrFc+/ePTRr1gzffPONVuMvX76MHj164Pnnn0dSUhJGjx6Nd955B//884+eKxVfVeeqzNmzZzXeW25ubnqq0DDs2rULI0aMwIEDBxAfHw+FQoHIyEjcu3ev0n3M+fdVdeYLMM/fWfXr18fnn3+Oo0eP4siRI3jhhRfQq1cvnDx5ssLxor2vBNKp1q1bCyNGjFA/ViqVgqenpzBr1qwKx7/66qtCjx49NLa1adNGeO+99/RapyGo6lwtWbJEcHR0rKHqDBcAYe3atY8dM27cOCEkJERj22uvvSZERUXpsTLDo81c/fvvvwIA4fbt2zVSk6HKysoSAAi7du2qdIw5/756lDbzxd9Z/6ldu7bw008/VficWO8rdoB0qKSkBEePHkVERIR6m1QqRUREBPbv31/hPvv379cYDwBRUVGVjjcV1ZkrALh79y68vb3h5eX12H9RmDtzfV89jebNm6Nu3bro0qUL9u3bJ3Y5Ne7OnTsAgDp16lQ6hu+r/2gzXwB/ZymVSqxcuRL37t1DWFhYhWPEel8xAOlQdnY2lEol3N3dNba7u7tXej1BRkZGlcabiurMVWBgIH7++Wf89ddfWLZsGVQqFcLDw3Ht2rWaKNmoVPa+ysvLQ2FhoUhVGaa6deviu+++w+rVq7F69Wp4eXmhU6dOOHbsmNil1RiVSoXRo0ejbdu2aNKkSaXjzPX31aO0nS9z/p2VnJwMOzs7yOVyDB06FGvXrkXjxo0rHCvW+4qrwZPRCAsL0/gXRHh4OIKDg/H9999jxowZIlZGxiwwMBCBgYHqx+Hh4bh48SLmz5+PpUuXilhZzRkxYgRSUlKwd+9esUsxCtrOlzn/zgoMDERSUhLu3LmDP//8E9HR0di1a1elIUgM7ADpkIuLC2QyGTIzMzW2Z2ZmwsPDo8J9PDw8qjTeVFRnrh5laWmJFi1a4MKFC/oo0ahV9r5ycHCAjY2NSFUZj9atW5vN+2rkyJHYuHEj/v33X9SvX/+xY83199XDqjJfjzKn31lWVlYICAhAq1atMGvWLDRr1gxfffVVhWPFel8xAOmQlZUVWrVqhe3bt6u3qVQqbN++vdLPPsPCwjTGA0B8fHyl401FdebqUUqlEsnJyahbt66+yjRa5vq+0pWkpCSTf18JgoCRI0di7dq12LFjB3x9fZ+4jzm/r6ozX48y599ZKpUKxcXFFT4n2vtKr5dYm6GVK1cKcrlciIuLE06dOiW8++67gpOTk5CRkSEIgiC8+eabQkxMjHr8vn37BAsLC+HLL78UTp8+LUyZMkWwtLQUkpOTxTqFGlPVuZo2bZrwzz//CBcvXhSOHj0q9O/fX7C2thZOnjwp1inUmPz8fCExMVFITEwUAAjz5s0TEhMThdTUVEEQBCEmJkZ488031eMvXbok2NraCh9//LFw+vRp4ZtvvhFkMpmwZcsWsU6hxlR1rubPny+sW7dOOH/+vJCcnCx88MEHglQqFbZt2ybWKdSIYcOGCY6OjsLOnTuF9PR09U9BQYF6DH9f/ac682Wuv7NiYmKEXbt2CZcvXxZOnDghxMTECBKJRNi6dasgCIbzvmIA0oOFCxcKDRo0EKysrITWrVsLBw4cUD/XsWNHITo6WmP8qlWrhEaNGglWVlZCSEiIsGnTphquWDxVmavRo0erx7q7uwvdu3cXjh07JkLVNa/sq9qP/pTNT3R0tNCxY8dy+zRv3lywsrIS/Pz8hCVLltR43WKo6lzNnj1b8Pf3F6ytrYU6deoInTp1Enbs2CFO8TWoojkCoPE+4e+r/1Rnvsz1d9bgwYMFb29vwcrKSnB1dRU6d+6sDj+CYDjvK4kgCIJ+e0xEREREhoXXABEREZHZYQAiIiIis8MARERERGaHAYiIiIjMDgMQERERmR0GICIiIjI7DEBERERkdhiAiIiIyOwwABGRUbl58yaGDRuGBg0aQC6Xw8PDA1FRUdi3bx8AQCKRYN26deIWSUQGz0LsAoiIqqJfv34oKSnBL7/8Aj8/P2RmZmL79u3IyckRuzQiMiLsABGR0cjNzcWePXswe/ZsPP/88/D29kbr1q0RGxuLl156CT4+PgCAPn36QCKRqB8DwF9//YWWLVvC2toafn5+mDZtGu7fv69+XiKRYPHixejWrRtsbGzg5+eHP//8U/18SUkJRo4cibp168La2hre3t6YNWtWTZ06EekYAxARGQ07OzvY2dlh3bp1KC4uLvf84cOHAQBLlixBenq6+vGePXswcOBAfPDBBzh16hS+//57xMXFYebMmRr7T5o0Cf369cPx48fxxhtvoH///jh9+jQA4Ouvv8b69euxatUqnD17FsuXL9cIWERkXLgYKhEZldWrV2PIkCEoLCxEy5Yt0bFjR/Tv3x9NmzYFUNrJWbt2LXr37q3eJyIiAp07d0ZsbKx627JlyzBu3DjcuHFDvd/QoUOxePFi9ZjnnnsOLVu2xLfffotRo0bh5MmT2LZtGyQSSc2cLBHpDTtARGRU+vXrhxs3bmD9+vXo2rUrdu7ciZYtWyIuLq7SfY4fP47p06erO0h2dnYYMmQI0tPTUVBQoB4XFhamsV9YWJi6AzRo0CAkJSUhMDAQo0aNwtatW/VyfkRUMxiAiMjoWFtbo0uXLpg0aRISEhIwaNAgTJkypdLxd+/exbRp05CUlKT+SU5Oxvnz52Ftba3Va7Zs2RKXL1/GjBkzUFhYiFdffRUvv/yyrk6JiGoYAxARGb3GjRvj3r17AABLS0solUqN51u2bImzZ88iICCg3I9U+t+vwQMHDmjsd+DAAQQHB6sfOzg44LXXXsOPP/6I33//HatXr8atW7f0eGZEpC/8GjwRGY2cnBy88sorGDx4MJo2bQp7e3scOXIEc+bMQa9evQAAPj4+2L59O9q2bQu5XI7atWtj8uTJePHFF9GgQQO8/PLLkEqlOH78OFJSUvDpp5+qj//HH3/gmWeeQbt27bB8+XIcOnQI//d//wcAmDdvHurWrYsWLVpAKpXijz/+gIeHB5ycnMSYCiJ6WgIRkZEoKioSYmJihJYtWwqOjo6Cra2tEBgYKEycOFEoKCgQBEEQ1q9fLwQEBAgWFhaCt7e3et8tW7YI4eHhgo2NjeDg4CC0bt1a+OGHH9TPAxC++eYboUuXLoJcLhd8fHyE33//Xf38Dz/8IDRv3lyoVauW4ODgIHTu3Fk4duxYjZ07EekWvwVGRISKvz1GRKaL1wARERGR2WEAIiIiIrPDi6CJiADwagAi88IOEBEREZkdBiAiIiIyOwxAREREZHYYgIiIiMjsMAARERGR2WEAIiIiIrPDAERERERmhwGIiIiIzA4DEBEREZmd/wfwH1579uGzYgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_training_history(history):\n",
    "    plt.plot(history['train_loss'], label='train_loss')\n",
    "    plt.title('Training History')\n",
    "    plt.xlabel('Steps')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing loop (test hyper-params) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at camembert-base were not used when initializing CamembertForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing CamembertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CamembertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. data :\n",
    "batch_size = 4096\n",
    "train_data = load_tokenized_data(\"data/tokenized_data/tokenized_train_data.pkl\")\n",
    "val_data = load_tokenized_data(\"data/tokenized_data/tokenized_val_data.pkl\")\n",
    "\n",
    "#  1.1. Créer les datasets\n",
    "train_dataset = Tokenized_oscar_dataset(train_data)\n",
    "val_dataset = Tokenized_oscar_dataset(val_data)\n",
    "\n",
    "#  1.2. Créer les DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# 2. model :\n",
    "from transformers import CamembertForMaskedLM\n",
    "model = CamembertForMaskedLM.from_pretrained(\"camembert-base\")\n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(epoch, model, optimizer, loss, save_dir):\n",
    "    \"\"\"\n",
    "    Sauvegarder l'état actuel du modèle, optimiseur et perte.\n",
    "    \"\"\"\n",
    "    checkpoint = {\n",
    "        \"epoch\": epoch,\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "        \"loss\": loss,\n",
    "    }\n",
    "    save_path = os.path.join(save_dir, f\"checkpoint_epoch_{epoch}.pth\")\n",
    "    torch.save(checkpoint, save_path)\n",
    "    print(f\"Checkpoint saved at {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Validation Loss: 10.3084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/2: 100%|██████████| 2/2 [00:15<00:00,  7.59s/it, loss=10]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training Loss: 9.9156, Time: 16.92 s\n",
      "Epoch 2, Validation Loss: 10.2917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/2: 100%|██████████| 2/2 [00:15<00:00,  7.59s/it, loss=9.6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Training Loss: 9.6472, Time: 16.31 s\n",
      "Checkpoint saved at models/mlm_training/model_checkpoints\\checkpoint_epoch_2.pth\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "max_lr = 6e-4\n",
    "min_lr = max_lr * 0.1  # 10 %\n",
    "warmup_steps = 10\n",
    "\n",
    "save_interval = 40  # Save the model every 40 epochs \n",
    "eval_interval = 40  # Evaluate the model every 40 epochs\n",
    "num_epochs = 420  # Total epochs\n",
    "learning_rate = 1e-4\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), \n",
    "                              lr=learning_rate)\n",
    "history = {'train_loss': [], 'val_loss': []}\n",
    "\n",
    "# Dossier de sauvegarde\n",
    "save_dir = \"models/mlm_training/model_checkpoints\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "############################## Training Loop ################################\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Mettre le modèle en mode entraînement\n",
    "    train_loss = 0.0  # Accumulateur pour la perte par époque\n",
    "\n",
    "    t0 = time.time()\n",
    "    \n",
    "    # once in a while evaluate our validation loss : (only for one step, next we'll consider more steps validation)\n",
    "    if epoch % 40 ==0 or epoch == num_epochs - 1:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss = 0.0\n",
    "            for batch_index, batch in enumerate(val_loader):\n",
    "                # 1. Prepare val data :\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                labels = batch['labels'].to(device)\n",
    "                # 2. Forward pass :\n",
    "                # optimizer.zero_grad() not needed since torch.no_grad is used \n",
    "                logits = model(input_ids, attention_mask=attention_mask)['logits']\n",
    "                loss = F.cross_entropy(logits.view(-1, logits.size(-1)), labels.view(-1), ignore_index=-100)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "            avg_val_loss = val_loss / len(val_loader)\n",
    "            print(f\"Epoch {epoch + 1 }, Validation Loss: {avg_val_loss:.4f}\")\n",
    "            history['val_loss'].append(avg_val_loss)\n",
    "\n",
    "    # Update the parameters of the model :\n",
    "    with tqdm(total=len(train_loader), desc=f\"Epoch {epoch + 1}/{num_epochs}\") as pbar:\n",
    "        for batch_index, batch in enumerate(train_loader):\n",
    "            # 1. Prepare trin data :\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            # 2. Forward pass\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs['logits']\n",
    "            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), labels.view(-1), ignore_index=-100)\n",
    "\n",
    "            # 3. Backward pass et optimisation\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Suivi de la progression\n",
    "            train_loss += loss.item()\n",
    "            pbar.set_postfix({'loss': loss.item()})\n",
    "            pbar.update(1)\n",
    "        \n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "\n",
    "    t1 = time.time()\n",
    "    dt = t1 - t0 # time difference in seconds\n",
    "    print(f\"Epoch {epoch + 1}, Training Loss: {avg_train_loss:.4f}, Epoch time: {dt:.2f} s\")\n",
    "\n",
    "    # Sauvegarder la perte moyenne de l'époque\n",
    "    history['train_loss'].append(avg_train_loss)\n",
    "\n",
    "    # Sauvegarder tous les 40 epochs\n",
    "    if (epoch + 1) % save_interval == 0 or (epoch + 1) == num_epochs:\n",
    "        save_checkpoint(epoch + 1, model, optimizer, avg_train_loss, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at camembert-base were not used when initializing CamembertForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing CamembertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CamembertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Epoch 1/820: 100%|██████████| 1/1 [01:10<00:00, 70.62s/it, loss=10.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Average Loss: 10.3903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/820: 100%|██████████| 1/1 [00:48<00:00, 48.09s/it, loss=10.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Average Loss: 10.2310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/820: 100%|██████████| 1/1 [00:29<00:00, 29.44s/it, loss=10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Average Loss: 10.0313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/820: 100%|██████████| 1/1 [00:29<00:00, 29.84s/it, loss=9.91]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Average Loss: 9.9097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/820: 100%|██████████| 1/1 [00:27<00:00, 27.15s/it, loss=9.79]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Average Loss: 9.7935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/820: 100%|██████████| 1/1 [00:29<00:00, 29.26s/it, loss=9.68]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Average Loss: 9.6839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/820: 100%|██████████| 1/1 [00:27<00:00, 27.45s/it, loss=9.57]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Average Loss: 9.5696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/820:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "train_data = load_tokenized_data(\"data/tokenized_data/tokenized_train_data.pkl\")\n",
    "val_data = load_tokenized_data(\"data/tokenized_data/tokenized_val_data.pkl\")\n",
    "\n",
    "# Créer les datasets\n",
    "train_dataset = Tokenized_oscar_dataset(train_data)\n",
    "val_dataset = Tokenized_oscar_dataset(val_data)\n",
    "\n",
    "# Créer les DataLoaders\n",
    "batch_size = 4096\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "num_epochs = 420  # Total epochs\n",
    "learning_rate = 1e-4\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "history = {'train_loss': []}\n",
    "\n",
    "# Dossier de sauvegarde\n",
    "save_dir = \"models/mlm_training/model_checkpoints\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "def save_checkpoint(epoch, model, optimizer, loss, save_dir):\n",
    "    \"\"\"\n",
    "    Sauvegarder l'état actuel du modèle, optimiseur et perte.\n",
    "    \"\"\"\n",
    "    checkpoint = {\n",
    "        \"epoch\": epoch,\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "        \"loss\": loss,\n",
    "    }\n",
    "    save_path = os.path.join(save_dir, f\"checkpoint_epoch_{epoch}.pth\")\n",
    "    torch.save(checkpoint, save_path)\n",
    "    print(f\"Checkpoint saved at {save_path}\")\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Mettre le modèle en mode entraînement\n",
    "    epoch_loss = 0.0  # Accumulateur pour la perte par époque\n",
    "\n",
    "    # Utiliser tqdm pour la progression\n",
    "    with tqdm(total=len(train_loader), desc=f\"Epoch {epoch + 1}/{num_epochs}\") as pbar:\n",
    "        for batch_index, batch in enumerate(train_loader):\n",
    "            # 1. Préparer les données\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            # 2. Forward pass\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs['logits']\n",
    "            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), labels.view(-1), ignore_index=-100)\n",
    "\n",
    "            # 3. Backward pass et optimisation\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Suivi de la progression\n",
    "            epoch_loss += loss.item()\n",
    "            pbar.set_postfix({'loss': loss.item()})\n",
    "            pbar.update(1)\n",
    "\n",
    "    # Sauvegarder la perte moyenne de l'époque\n",
    "    avg_epoch_loss = epoch_loss / len(train_loader)\n",
    "    history['train_loss'].append(avg_epoch_loss)\n",
    "    print(f\"Epoch {epoch + 1}, Average Loss: {avg_epoch_loss:.4f}\")\n",
    "\n",
    "    # Sauvegarder tous les 50 epochs\n",
    "    if (epoch + 1) % 50 == 0 or (epoch + 1) == num_epochs:\n",
    "        save_checkpoint(epoch + 1, model, optimizer, avg_epoch_loss, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_loader))\n",
    "\n",
    "input_ids = batch['input_ids']\n",
    "attention_mask = batch['attention_mask']\n",
    "labels = batch['labels']\n",
    "# 2. forward pass :\n",
    "optimizer.zero_grad()\n",
    "outputs = model(input_ids, attention_mask=attention_mask)\n",
    "predictions = outputs['logits'].argmax(dim=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
